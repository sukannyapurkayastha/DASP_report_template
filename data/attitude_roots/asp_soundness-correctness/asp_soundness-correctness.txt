reviews	paper_sections	rebuttal_accept-praise	rebuttal_answer	rebuttal_by-cr	rebuttal_concede-criticism	rebuttal_contradict-assertion	rebuttal_done	rebuttal_followup	rebuttal_future	rebuttal_mitigate-criticism	rebuttal_other	rebuttal_refute-question	rebuttal_reject-criticism	rebuttal_social	rebuttal_structuring	rebuttal_summary
As mentioned earlier, the actual conclusion in Section 4.2 is that minimizing the KL-divergence between the parametric policy and the optimal policy by SGD will converge to the optimal policy, which is straightforward and is not what AlphaGo Zero does.	MET_RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree that there is a gap between AGZ and our model.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It will be interesting to study how the error between MCTS and the optimal policy affects the iterative algorithm.
.This is a research direction we think is worth pursuing in the future.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As mentioned in our paper, MCTS converges to the optimal policy for both classical MDPs and stochastic games.
.Hence in this paper, we model the AGZ’s MCTS policy by the optimal policy, and mainly focus on the other two key ingredients of AGZ, self-play and supervised learning.
"
This is actually a direct consequence of any minmax theorem in game theory; the authors decided to credit that result to Yao (I tend to *strongly* disagree with that point as, even if he stated this fact in CS, this result was quite standard several decades before him - anyway.).	MET_RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"On calling it Yao’s Principle: as Reviewer #1 correctly noted, this is an application of the classic von Neumann minimax principle to the “game” between an “algorithm player” and an “input player”.
.We call it Yao’s principle primarily in accordance with tradition in theoretical CS (see https://en.wikipedia.org/wiki/Yao%27s_principle and also https://blog.computationalcomplexity.org/2006/10/favorite-theorems-yao-principle.html, where it is noted that “Yao observed [the result]” and commentators note that it’s called Yao’s principle because this observation has significant consequences for many central problems in TCS).
"	NOOOOOONNNNNEEEE	"We are happy to add text to reflect this.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The abstract mentioned that the proposed algorithm works as an “implicit regularization leading to better classification accuracy than the original model which completely ignores privacy”. But I don’t see clearly from the experimental results how the accuracy compares to a non-private classifier.	MET_RES	NOOOOOONNNNNEEEE	"As shown in Figure 3, the utility of RAN’s Encoder output is higher than that of DNN.
.Here the DNN model stands for the non-private feature extractor followed by a non-private classifier.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response #4: We have added more explanations in Section 3.1 about how “the proposed algorithm works as an implicit regularization leading to better classification accuracy than the original model which completely ignores privacy”.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"and rendering the third claim from the introduction (""We propose an new algorithm with the new metric which demonstrates better results than state-of-the-art algorithms."") completely untrue."	INT_MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2) For the experiment, we will train our experiments longer and modify our network.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Although experiments show that learning such representations are beneficial for low-shot setting of SVHN, it is not clear whether such improvement generalizes to more realistic datasets such as ImageNet.	DAT_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?	DAT_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Having said that, we agree with the reviewer that [Hartford et al. 18] probably cannot handle such tasks by construction. As we mentioned in our response to Reviewer1 we will change the wording of this section to better reflect that this is *not* a failure of Hartford et al. but merely a setting outside their scope due to a different assumption on the symmetry group of the data.
.If the reviewers feel strongly about this experiment, we are open to replace it with a discussion.
.--------------------------------------------------------------------------------------------------------------------------------
"	"A: Our goal in performing the synthetic experiments was to quantify the expressive power that is  gained by adding our basis elements to [Hartford et al. 18].
.We felt it is an informative experiment since [Hartford et al. 18] also discuss applying their model in the jointly exchangeable setting (page 3, second column, top paragraph).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: ”Applying the model of Hartford et al. to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation... Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?”
"	NOOOOOONNNNNEEEE
In the real world, one would not have access to OOD data during training, how is one to pick \lambda in such cases?	DAT_EXP	NOOOOOONNNNNEEEE	"(3) We observed that as \lambda increases, in the validation set, the uncertainty is increasing, while the accuracy is decreasing.
.So
., a simple heuristic that we use is to choose the highest \lambda that allow high validation accuracy (e.g. > 0.97 on MNIST).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We found that this heuristic works very well in our experiments (the results have updated to reflect on this heuristic).
.We have made this procedure clear in the revised manuscript.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The experiments were only done on simple image datasets.	DAT_EXP	NOOOOOONNNNNEEEE	"A: Our method is not specific to the image domain and there is no reason it could not be applied to other input types.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In order to use our method, we only require a corpus of data with partially (at least two) labeled factors of variation and a corpus of data which is sparsely labeled for a downstream task.
.Critically, these two sources of data need not be identical!
.This means that an easy way to acquire a corpus with labeled factors of variation is to use a simulator to generate this data,  as we do in this study.
"	NOOOOOONNNNNEEEE	"The experiments were only done on simple image datasets.
"	NOOOOOONNNNNEEEE
This also becomes apparent in the experiments section, where rotational data augmentation is found to be necessary.	DAT_EXP	NOOOOOONNNNNEEEE	"(Q2) Equivariance property of the Alt-az convolution
.Q3: alt-az convolution is not well defined on the south pole
"	NOOOOOONNNNNEEEE	"A3: Yes, we agree that our original definition of alt-az convolution is not well defined on both north and south poles.
"	"Here is our tentative proof:
.Under the definition of alt-azimuth anisotropic convolution and using the unitary property (5) of rotation operators, we have (assume the number of channels K=1 for simplicity, assume Q and R be both alt-az rotations):
.\begin{equation}
.\begin{aligned}
.& (h \star D_{Q} f) (R)
.\\
.&
.= \int_{S^2}(D_Rh)(\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}Q\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h((Q^{-1}R)^{-1}\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=(h \star f)(Q^{-1}R) = D_{Q}( h \star f)(R)
.\end{aligned}
.\end{equation}
"	"Therefore, in the new revision, we will add the constraints to the definition of alt-az rotation and make it one-to-one corresponds to the set points on $S^2$. See A1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We think we can still have the equivariance property but only for single alt-az rotation.
.Notice the definition of alt-az convolution do not use any composite rotation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This means that for a single alt-az rotation of input spherical image; the output of a convolution layer will rotate in the same way.
.Although the property doesn’t hold if one performs multiple alt-az rotations to the input spherical image, it is still valuable because we assume the different SO(3) orientation of an input 3D shape is from a composite of an azimuthal rotation and an alt-az rotation, the azimuthal rotation is treated by data augmentation and the single alt-az rotation is treated by the network equivariance and invariance.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This is also lacking from the description of the experimental protocol, which does not address the data-splits (how many classes were used for each) and size of the unlabelled test set.	DAT_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In light of the reviews, in the revised version, we have expanded the appendix to give more details on the experimental protocol.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We did provide some details on the first version (in the appendix).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Concern 2: Size of unlabelled test set, data-split information
"	NOOOOOONNNNNEEEE
- How many samples did you use from p(theta|x) during training?	DAT_EXP	NOOOOOONNNNNEEEE	"The results show that the CDN objective produces superior results compared to VI and VIB.
"	NOOOOOONNNNNEEEE	"(2) Thank you very much for the pointer to VIB!
"	NOOOOOONNNNNEEEE	"We have added a section in the updated manuscript to compare the objective of CDNs with that used in VIB and VI for Bayesian neural networks (see new Section 4).
.Furthermore, while we  always used 1 sample during training in the original submission (which indeed makes the CDN an instance of VIB) we now added experiments using 10 samples (see Section 6.4) in an experimental analysis of the different objectives.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. Experimental settings are clear, however, what makes me confused is that the construction for p_{\bar{d}} is straightforward for simple distribution like 2D points dataset, however, it might be intractable for complex high dimensional data such as images.	DAT_EXP	NOOOOOONNNNNEEEE	"In responding to this comment and the comment of Reviewer #1, we perform one more experiment on CelebA to demonstrate that DSGAN can work well even for complicated images.
.The experiment validates that DSGAN still works well to create complement data for complicate images.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">>> Experimental settings are clear, however, what makes me confused is that the construction for $p_{\bar{d}}$ is straightforward for simple distribution like 2D points dataset, however, it might be intractable for complex high dimensional data such as images.
.Figure 10 in Appendix G shows generated images and FID for both methods.
"	"In this experiment, we generate the color images of size 64 $\times$ 64.
.Similar to 1/7 experiments on the MNIST dataset, we let $p_{\bar{d}}$ be the distribution of face images with glasses and without glasses, and let $p_{d}$ be images without glasses.
.We sample 10000 images with glasses and 10000 images without glasses from CelebA, and we set $\alpha$ to 0.5.
.In order to verify the generated image quality of DSGAN, we also train a GAN for comparison.
.GAN is trained with the same amount of training images (but only using face images with glasses since GAN is to learn the distribution of training data).
.In other words, we assume GAN can use complement data as training data directly.
.On the contrary, DSGAN only uses complement data indirectly (the difference between $p_{\bar{d}}$ and $p_d$).
.We can see that our DSGAN can generate images with glasses from the given $p_d$ and $p_{\bar{d}}$, and the FID of DSGAN are comparable to that of GAN.
"
- There is no motivations for the use of $\lambda >1$ neither practical or theoretical since the results are only proven for $\lambda =1$ whereas the experiments are done with \lambda = 5,20 or 30.	RES_EXP	NOOOOOONNNNNEEEE	"Indeed, theoretically we can only prove for $\lambda$ = 1 case.
.Yet we found that larger \lambda brings us more speedup.
.Intuitively speaking, using lambda>1 is essentially a “relax and tighten” step by first relax the constraint to make the problem easier, and then tighten it back to the real constraint.
.The “relax and tighten” idea has been widely used in constrained optimization, and in this paper we adapted this idea into Frank-Wolfe algorithm to make it even faster.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have added further empirical evidence (performance comparison of our method with different \lambda in Figure 1 in the revised paper) to justify it.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3
..
"	NOOOOOONNNNNEEEE
Furthermore, in experiments, the paper does not provide any quantitatively convincing results to suggest the generator in use is a good one.	RES_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response: Measuring the reconstruction accuracy (of goodness of the
.generator)
.is difficult, as each measure has its own flaws.
.For instance,
.Norm measures are sensitive to translations in the image.
"	NOOOOOONNNNNEEEE	"Comment: One of the problems highlighted in the paper regarding existing
.explanation modalities is the use of another black-box to explain the
.decisions of an existing deep network (also somewhat of a black-box) which
.the authors claim their model does not suffer from.
.Comment: The paper does not provide any quantitatively convincing results
.to suggest the generator in use is a good one.
"	NOOOOOONNNNNEEEE
- I'm not sure we can conclude much from the results on fetchSlide (and it would make sense not to use the last set of parameters but the best one encountered during training)	RES_EXP	NOOOOOONNNNNEEEE	"- In the FetchSlide environment, the best-learned policy of CDP outperforms the baselines and PER, as shown in Table 1.
.Yes, we did not use the last set of parameters but used the best one encountered during training, as described in Section 4 “Experiments”: “After training, we use the best-learned policy as the final policy and test it in the environment.
.The testing results are the final mean success rates.“
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
If the test set is not shuffled (by emphasis on first I assume not) these images are from training NIST (cleaner) set and may not include samples of all digits.	DAT	NOOOOOONNNNNEEEE	"This should avoid placing too much emphasis on the cleaner images in the beginning of the MNIST test set.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have now evaluated the adversarial resistance throughout the article for 1000 images randomly selected from the 10000 MNIST test images.
.Fig. 3 and other evaluations have been updated for the new test set.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
One observation from the submission is that the token set may need to very large (from tens of thousands to millions) for the system to work well, making the BERT training computationally expensive (I noticed that the BERT model is trained on 128 GPUs)	DAT	NOOOOOONNNNNEEEE	"Here we focus on a new quantization method evaluated via downstream performance in phone and speech recognition settings by employing models that worked well (and were extensively tuned) in NLP contexts.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree that it would be interesting to perform an in-depth analysis on the embeddings learned by BERT and we will investigate this in future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Our BERT vocabulary sizes (13.5k for the gumbel version and 23k for the k-means version) compare favorably to the setups commonly used in NLP where vocabularies are double or triple of our sizes.
"	NOOOOOONNNNNEEEE	">> 1.
.[...]
.One observation from the submission is that the token set may need to be very large (from tens of thousands to millions) for the system to work well, making the BERT training computationally expensive [...] I think some more motivation or exploration (what kind of information did BERT learn) is needed to understand why that is the case.
"	NOOOOOONNNNNEEEE
3. One concern I have with discrete representation is how robust they are wrt different dataset.	DAT	NOOOOOONNNNNEEEE	"However we note that representations transfer at least well across datasets from the “clean speech” domain: vq-wav2vec and BERT is only trained on Librispeech and never tuned on TIMIT/WSJ.
"	NOOOOOONNNNNEEEE	"We agree that an ablation study on robustness of the embeddings across different datasets would be very interesting.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Here we are mostly focusing on relatively clean data (WSJ, TIMIT, Librispeech) following the original wav2vec paper but we would be interested in exploring robustness in the future.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> 3. One concern I have with discrete representation is how robust they are wrt different dataset.
"	NOOOOOONNNNNEEEE
1. The dataset is adversarially filtered using BERT and GPT, which gives deep learning model a huge disadvantage. After all, the paper says BERT scores 88% before the dataset is attacked.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"While BERT originally achieved high performance on the originally collected dataset, several recent studies [1][2][3][4] have found the presence of annotation artifacts in crowdsourced data that inadvertently leak information about the target label.
.This subsequently leads to overestimation of the performance of AI systems on end tasks.
.Our adversarial filtering (AF) algorithm aims to address the problem of overestimation of performance.
.In spite of targeting GPT/BERT during AF, human performance on the AF resulting dataset is still high.
.The significant gap between human and BERT performance leaves scope for inventing new methods for abductive reasoning.
"	NOOOOOONNNNNEEEE	"Adversarially filtering using BERT and GPT gives deep learning models a disadvantage:
"	NOOOOOONNNNNEEEE
Why does it go to nearly zero around x = 0, while being higher in surrounding regions with more data?	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(a) Thanks for catching this. Indeed this was due to a bug in the toy regression experiment which we have fixed now.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Note: after reading the comments updated by authors, I remain my opinions: even though exact meta-testing data is unseen during training, the domain is seen during training, and therefore it cannot be qualified for being ""meta domain adaptation""."	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- in section 4.3, there is no guarantee that the intersection between the training set and test set is empty.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Yes, in theory that is true, but in practice this is negligible: the total number of possible triplets is about 10^9. So the likelihood that two sets of size 1000 intersect is close to 0.
"	NOOOOOONNNNNEEEE	"- ""in section 4.3, there is no guarantee that the intersection between the training set and the test set is empty.""
"	NOOOOOONNNNNEEEE
Optimizing compression rates should be done on the training set with a separate development set.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out.
.We agree that optimizing compression rates should not use the test set before the best compression scheme is selected.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Optimizing compression rates should be done on the training set with a separate development set.
.We believe that this is the Reviewer 1's core question so would like to justify our results more in detail in this response and try to convince the Reviewer.
.The accuracy results are as shown in the following table.
.----------------------------------------------------------------------------------
.------------------------------  ---------------------------
.---------------------
.----------------------------------------------------------------------------------
"	"In fact, in case of PTB and Wikitext-2 corpus, we already used the provided validation set and measured the test PPW only once after training (Table 2) in the original manuscript.
.From the Table 2, we can see that our proposed scheme maintains the accuracy of the uncompressed baseline network.
.On the other hand, the CIFAR-10 dataset does not include a separate validation set, so we had to use the test set in the retraining process.
.To avoid using the test set in the retraining process as the Reviewer pointed out, we randomly selected 5K validation images among the original 50K training images in CIFAR-10 dataset, and applied our scheme.
.Then, we observed the training and validation accuracy at each training epoch, and measured the test accuracy once after training.
.Note the compression rates are the same as the data in Table 3 in the original manuscript.
.Compression scheme   Validation Error (%)    Test Error (%)
.Baseline
.11.5                         12.2
.Pruning [1]                         11.4                         12.2
.VWM (Ours)
.11.4                         12.4
.The test accuracy in the above table is about 1 % less than the accuracy which we reported in the originally submitted manuscript because the number of training data was decreased as part of the data set is used as a validation set.
.However, the results show that our proposed method does not make the network be overfitted to test data as the Reviewer doubted because the difference between the accuracy for validation set and test set are consistent with the values from the previous works.
.Note that even the uncompressed baseline network exhibits similar accuracy difference between the validation error and the test error compared with the compressed networks.
.Therefore, we believe that our proposed compression method does not suffer from the concerned overfitting problem regardless of the types of neural networks or dataset.
"
The test set should not used before the best compression scheme is selected.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out.
.We agree that optimizing compression rates should not use the test set before the best compression scheme is selected.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The test set should not used before the best compression scheme is selected.
.We believe that this is the Reviewer 1's core question so would like to justify our results more in detail in this response and try to convince the Reviewer.
.The accuracy results are as shown in the following table.
.----------------------------------------------------------------------------------
.------------------------------  ---------------------------
.---------------------
.----------------------------------------------------------------------------------
"	"In fact, in case of PTB and Wikitext-2 corpus, we already used the provided validation set and measured the test PPW only once after training (Table 2) in the original manuscript.
.From the Table 2, we can see that our proposed scheme maintains the accuracy of the uncompressed baseline network.
.On the other hand, the CIFAR-10 dataset does not include a separate validation set, so we had to use the test set in the retraining process.
.To avoid using the test set in the retraining process as the Reviewer pointed out, we randomly selected 5K validation images among the original 50K training images in CIFAR-10 dataset, and applied our scheme.
.Then, we observed the training and validation accuracy at each training epoch, and measured the test accuracy once after training.
.Note the compression rates are the same as the data in Table 3 in the original manuscript.
.Compression scheme   Validation Error (%)    Test Error (%)
.Baseline
.11.5                         12.2
.Pruning [1]                         11.4                         12.2
.VWM (Ours)
.11.4                         12.4
.The test accuracy in the above table is about 1 % less than the accuracy which we reported in the originally submitted manuscript because the number of training data was decreased as part of the data set is used as a validation set.
.However, the results show that our proposed method does not make the network be overfitted to test data as the Reviewer doubted because the difference between the accuracy for validation set and test set are consistent with the values from the previous works.
.Note that even the uncompressed baseline network exhibits similar accuracy difference between the validation error and the test error compared with the compressed networks.
.Therefore, we believe that our proposed compression method does not suffer from the concerned overfitting problem regardless of the types of neural networks or dataset.
"
1. [The claim] One of my concerns for this paper is the assumption of the factorized latent variables from multimodal data.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The factorization of latent space with respect to the modalities provides a way to differentiate observed and unobserved modalities.
.Therefore, VSAE is capable of handling partially-observed data where the missing modalities can be arbitrary.
.In addition, the embeddings are intuitively more meaningful as input to unimodal encoders is now limited to only observed modalities, eliminating the effect of missing modalities.
.When performing imputation/generation, however, we want to capture the dependencies between modalities.
.In other words, unobserved modalities should be imputed based on the information extracted from observed modalities.
.For experiments, we design this by conditioning decoders on all latent variables, essentially accessing information from all observed modalities.
.This is not in contradiction to the factorized latent variable assumption.
.Instead, the encoders try to embed each modalities individually, while decoders learn the dependencies between different modalities.
"	NOOOOOONNNNNEEEE	"(1) Factorized Latent Variables:
"	NOOOOOONNNNNEEEE
First, I consider the tabular features as multi-feature data and less to be the multimodal data.	DAT	NOOOOOONNNNNEEEE	"In general, we believe multi-modal data is more general than conventional image-text or video-text pairs.
.By unifying tabular data also as multi-modal (with each attribute as one modality), we show that VSAE provides us a principled way for imputation, capable of generalizing to more data families.
.Specifically, we conducted experiments on two types of data:
"	NOOOOOONNNNNEEEE	"We apologize for unclear description of experimental settings.
"	NOOOOOONNNNNEEEE	"Upon request, we have included more extensive experiments following [1] on MNIST/FashionMNIST, and [2] on CMU-MOSI/ICT-MMMO.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(2) Multimodal Experiments:
.Results are reported in Table 10 and Table 11 (Appendix C.5).
"	"(1) low-dimensional tabular data, and (2) high-dimensional data (pixel or text) as ""multimodal"" to better define the overall task of learning from partially-observed data.
.As shown, VSAE consistently outperforms baseline models across the added experiments as well.
"
Also, the fact that the accuracy on the Kaggle non-doctored test set is low is simply because the test set is not coming from the same distribution of the training set.	DAT	NOOOOOONNNNNEEEE	"Our results suggests that models converge to solutions that privilege the “simplest” explanation, in an Occam’s razor fashion, which provides an explanation to the “implicit generalization” of deep nets characterized by Zhang et al.
.Our Kaggle experiment’s aim is to emphasize potential failure modes of current architectures/algorithms (one can think of a self-driving car trained on a road with clear lane markings and operating on a road without such markings).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The ability to transfer knowledge to test sets coming from a different distribution is key to building more intelligent and robust systems.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The setup where labeled data (c) also seems a bit unnatural (this also seems to be confirmed by the fact that the authors had to build datasets for the problem).	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. Supervised Setting: We would argue that the setting where labelled data (C) is available is more natural than the unsupervised setting as we aim to learn physical simulators (such as graphics engines) that have a well-defined control variate structure.
.This setup appears in many previous works, e.g. conditional GAN and its derivatives.
.Testing such models on synthetic datasets (i.e. outputs of graphics engines) where one can control the generative variables is a standard practice in the field and allows for better testing.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
A bigger source of uncertainty is likely due to there being a limited amount of data to fit the coefficients to.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
5. One of the anonymous comments on OpenReview is very interesting: samples from a CIFAR model look nothing like SVHN.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This is a very good point.
.See our response to Shengyang Sun’s comment below.
.We see think this phenomenon has to do with concentration of measure and typical sets, but we do not yet have a rigorous explanation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4.  “Samples from a CIFAR model look nothing like SVHN. This seems to call the validity of the anomalous into question. Curious what the authors have to say about this.”
"	NOOOOOONNNNNEEEE
"7.	The study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data."	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"At some point we may be interested in actually investigating the same for real-world data, but we think it's unclear right now what exactly such evaluation data should ideally look like, what problems are most interesting, what details to pay attention to. Artificial data allows us to investigate these questions while avoiding the elaborate and expensive process of obtaining real-world data.
"	"7. The evaluation is supposed to show what an architecture is capable of learning under ""ideal"" conditions.
.It's an interesting question whether/how this changes when gradually shifting towards ""less ideal"" setups.
.An advantage of using a controlled setup like ours is that this is possible to investigate, to some degree at least (for instance, add more types of captions to the training data, not just quantifier statements).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Unfortunately, there is a bit of an identity crisis happening in this paper. There are several choices that do not follow based on the data the paper considers.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense.	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"p_y(y_1 | x, w, (1, 2)) means the first output is assigned to the first ground truth, while p_y(y_1 | x, w, (2, 1)) mean the first output is assigned to the second ground truth.
.These two scenarios are acctally generate very different gradient.
.The same argument can be extended to p_y(y_2 | x, w, (1, 2)) and p_y(y_2 | x, w, (2, 1)).
"	NOOOOOONNNNNEEEE	"- permutation in the likelihood (2) does not make sense:
.In addition to what is explained by Maxwell, I add this clarification:
"	NOOOOOONNNNNEEEE
For example, ADP and ADP-T runtimes were very close on WikiText-103 dataset but very different on Billion Word corpus (Table 3 and 4).	DAT	NOOOOOONNNNNEEEE	"The differences in training time are due to the size of the models: Weight tying saves a lot more parameters for the Billion Word model due to the larger vocab compared to the WikiText-103 models which have a smaller vocab.
.On WikiText-103, tying saves 15% of parameters (Table 3, ADP vs ADP-T, 291M vs 247M) and training time is reduced by about 13%.
.On Billion Word, tying saves 27% of parameters (Table 4) and training time is reduced by about 34%.
.The slight discrepancy may be due to multi-machine training for Billion Word compared to the single machine setup for WikiText-103.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: “ADP and ADP-T runtimes were very close on WikiText-103 dataset but very different on Billion Word corpus (Table 3 and 4)”
"	NOOOOOONNNNNEEEE
Considering the small size of the corpus for the evaluation of a regularization method, the results even seem optimistic - it remains unclear, if this approach would readily scale to larger datasets.	DAT	NOOOOOONNNNNEEEE	"We believe language modeling is a fundamental problem in NLP and our work continues a long stream of papers that have achieved steadily lower perplexities over the past few years.
.We evaluated our approach on two standard datasets that have been used as a benchmark in most of these papers.
.Specifically,  we use a 2-layer LSTM with hidden dimension 1024 and a word embedding dimension of 1024.
.We truncated the vocabulary by keeping approximately 100k words with the highest frequency and used the same validation and test sets as (Yang et al. 2017).
.We obtained a valid/test perplexity of 44.0/42.5 for the model with PDR and 44.3/43.1 for the model without PDR, showing a gain of 0.6 points in the test perplexity.
.Note that we tuned the PDR loss coefficient very coarsely and tuning it further could lead to higher gains.
"	"We will update the manuscript with these additional results and discussion and post it shortly.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As suggested by multiple reviewers, we have conducted further experiments on the Gigaword corpus to test PDR on larger corpora.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
3. Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?	DAT	NOOOOOONNNNNEEEE	"R2: The complexity is linear in the number of classes, since classes are processed independently.
.Furthermore, text filtering is applied before cleaning, which reduces the number of images to be considered for a given class.
.Please also see the response R1 to reviewer1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q2: Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?
"	NOOOOOONNNNNEEEE
In this case, A: PointNet, B: DeepSet	DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It looks like all the results are given on the test set. Did you not do any tuning on the validation data?	DAT	NOOOOOONNNNNEEEE	"Yes, all the parameters were tuned on the validation data.
.All the models were selected according to their validation data evaluation.
.The early stop criterion is also based on the validation data evaluation.
.We consider the model to converge when it cannot improve further on validation data.
.The models never saw the test set during training or tuning, otherwise we would be cheating and these scores would be irrelevant to compare different settings.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* It looks like all the results are given on the test set. Did you not do any tuning on the validation data?
"	NOOOOOONNNNNEEEE
The results only compare with Shim et al. Why only this method? Why would it be expected to be faster than all the other alternatives? Wouldn't similar alternatives like the sparsely gated MoE, D-softmax and adaptive-softmax have chances of being faster?	MET_RWK	NOOOOOONNNNNEEEE	"In terms of baselines, SVD-softmax (NIPS’17) was chosen since it is a recent method that provides a significant inference speedup for softmax.
.Other alternatives, such as D-softmax and adaptive-softmax, focus on training instead of inference speedup.
.Furthermore, as claimed in their papers, they achieve limited speedup (around 5x) in language modeling, which is much worse than ours.
.With regards to Sparsely Gated MoE, it cannot speed up inference, since they select expert with full softmax.
.We would like to emphasize that most existing methods for inference speedup focus on approximating trained softmax layer, which usually suffers a loss on performance.
.Our model allows the adaptive adjustment of the softmax layer, achieves speedup through capturing the two-level overlapped hierarchy during training, which is novel and does not suffer from the performance loss.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- Why would it be expected to be faster than all the other alternatives? Wouldn't similar alternatives like the sparsely gated MoE, D-softmax and adaptive-softmax have chances of being faster?
"	NOOOOOONNNNNEEEE
"The performance of the proposed method is worse than the previous work but they claimed ""state-of-the-art"" results."	MET_RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Defining the best combination of techniques to achieve the highest performance is an interesting direction of future work; our preliminary experiments combining Mean Teacher with manifold regularization have shown some improvements and we will include the results in the final version of the paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"First, with respect to baselines, we have updated the results tables to include the additional baselines mentioned, as well as runs for VAT(+EntMin) with lower numbers of labels on CIFAR-10.
.We have also updated the text to tone down the claims.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"After updating these baselines, we note that our method still achieves state-of-the-art performance in the regime where 1000 and 2000 labels are used for training on CIFAR-10, with and without data augmentation.
.In addition, we note that the highest performance in many of the mentioned baselines (and with VAT) are obtained with a combination of multiple approaches.
.When our method is compared head-to-head against the proposed method in the mentioned papers, it is competitive and sometimes outperforms them, for instance, in experiments on CIFAR-10 with 4000 labels
"	NOOOOOONNNNNEEEE	"With augmentation:
.Adversarial Dropout [1] (11.32) vs ours (11.79 +/- 0.25)
.Without augmentation:
.Improved GAN + SNTG [2] (14.93) vs ours (14.34 +/- 0.17)
"	NOOOOOONNNNNEEEE
"- In the appendix, the statement ""Sarkar (2011) show that a similar statement as in Theorem 2 holds for a very general class of trees"" is confusing to me. The ""general class"", as far as I know, is actually *all* trees, weighted or unweighted."	MET_RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-Statement about “general class of trees” replaced by “all weighted or unweighted trees”.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I wonder the motivation of analyzing generalization of RNNs by the techniques established by Bartlett.	MET_RWK	NOOOOOONNNNNEEEE	"We study seq2seq classification tasks since they have been widely used in real world applications for RNNs.
.To name a few, in speech recognition, [1] hybridizes hidden Markov model with RNNs to label unsegmented sequence data; In computer vision, [2, 3] demonstrate scene labeling with LSTM and RNNs, achieving higher accuracy than baseline methods; In healthcare, [4] proposes a model, Doctor AI, to perform multiple label prediction (one for each disease or medication category).
.In addition, [5, 6] both apply RNNs to real-world healthcare datasets (MIMIC-III, PhysioNet, and ICU data) for mortality prediction and other multiple classifications tasks.
.We establish bounds for classification because it is typical in learning theory and is easy to compare among existing literature.
.On the other hand, our analysis applies in other tasks as long as a suitable Lipschitz loss function is chosen.
.Specifically, Lemma 4 establishes an upper bound for empirical Rademacher complexity of general Lipschitz loss functions (the last line in Appendix A.4).
.By replacing the loss function in Lemma 1, we can derive generalization bounds for various tasks other than classification.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
You should use an existing ES implementation (e.g., from some well-known package) instead of a naive implementation, and as additional baseline also CMA-ES.	MET_RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Again, we apologize for the confusing use of “ES” abbreviation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We believe it will be a valuable future research direction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Evolutionary strategy is not used in the paper.
"	NOOOOOONNNNNEEEE	"We invite the reviewer to re-read our paper, since it seems to have led to a major misunderstanding.
"	"Q3: You should use an existing ES implementation (e.g., from some well-known package) instead of a naive implementation, and as additional baseline also CMA-ES.
"	NOOOOOONNNNNEEEE
Therefore, I don’t find interesting to report how DDGC improve upon “no baseline”, because known methods do even better.	MET_RWK	NOOOOOONNNNNEEEE	"As AnonReviewer 3 mentioned, our main contribution is developing a new inference method which can be used under any pre-trained deep model.
"	NOOOOOONNNNNEEEE	"Nevertheless, we agree with your comments that it is more meaningful to emphasize our improvement over the state-of-the-art training methods.
"	NOOOOOONNNNNEEEE	"In the abstract of the revised draft, we report our improvement over Co-teaching [5] which is the most recent and state-of-the-art training method.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In other words, our goal is not outperforming the performance of prior training methods and complementary to them, i.e., our inference method can improve the performance of any prior training methods (see our common response to all reviewers).
"	NOOOOOONNNNNEEEE	"Q4. Updated abstract and performance evaluation.
"	NOOOOOONNNNNEEEE
While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs.	MET_RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
As the approach uses NF is derived specifically for unstable dynamics, it is not clear to me how adding it would affect the training if the dynamics *is stable*. In this context, I consider that for example, the work by Balduzzi et al. 2018 may be relevant as it describes that the dynamics of games (the Jacobian) has two components, one of which describes the oscillating behavior (Hamiltonian game); whereas most games are a mix of oscillating and non-oscillating dynamics.	MET_RWK	NOOOOOONNNNNEEEE	"A3: As stated above in our response to Q1, we added the new results of applying negative feedback to SN-GAN, which is a state-of-the-art variant of GANs with empirically stable performance.
.In general, as NF is essentially a penalty term that regularizes $D$ to the zero-function, we can expect it to be effective for most dynamics [*3].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also included the suggested related work (Balduzzi et al. 2018) in Section 5.
"	NOOOOOONNNNNEEEE	"Finally, as for the further evaluation (such as multiple seed runs and 2nd-momentum estimates), we agree it is interesting, but it is very demanding in computational resources, and we leave it for a systematic future investigation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q3: How does negative feedback (NF) influence the training of stable dynamics and further evaluation:
"	"Our results (See Table 1 (bottom) in the revision) indeed show that NF can further improve to reach new state-of-the-art results.
"
The justification that the method of Khadka & Tumer (2018) cannot be extended to use CEM, since the RL policies do not comply with the covariance matrix is unclear to me.	MET_RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"After second thoughts, this is absolutely right.
.As the reviewer says, in both this work and Khadka & Tumer, the RL updates lead to policies that may differ a lot from the search distribution and there is no guarantee in this work that the TD3 updates result in policies close to the starting point.
"	NOOOOOONNNNNEEEE	"We corrected the paper according to this new insight.
"	NOOOOOONNNNNEEEE	"A result of these second thoughts is that one could definitely build an ERL algorithm where the evolutionary part is replaced by CEM.
.Unfortunately we did not find enough time to implement and test this algorithm during the rebuttal stage, but we now mention this possibility as an interesting avenue for future work.
"	"But if the RL actor shows good enough performance, this does not prevent from computing a new covariance matrix which includes it.
.The corresponding ellipsoid in the search space may be very large, leading to a widespread next generation, but the process should tend to converge again towards a population of actors where evolutionary and RL actors are closer to each other.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The reviewer also raises doubts about the fact that the method of Khadka & Tumer (2018) cannot be extended to use CEM.
"	NOOOOOONNNNNEEEE
Furthermore, in the beginning of Section 3.1 the authors present their idea on probabilistic hypernetoworks which “maps x to a distribution over parameters instead of specific value \theta.” How is this different from the case that we were considering so far? If we had a point estimate for \theta we would not require to take an expectation in Equation (3) in the first place.	PDI	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(3) Indeed we need the probabilistic version of hypernetworks to implement the model we described in Equation (3).
.We just wanted to point out that this is in contrast to the vanilla  hypernetworks proposed by Ha et al. (2016) [1] and Jia et al.
.(2016) [2] which would produce a point estimate for \theta.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Though the title promises a contribution to an understanding of word embedding compositions in general, they barely expound on the broader implications of their idea in representing elements of language through vectors.	PDI	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I would have liked to see results for both trivial baselines like random ranking as well as more informed baselines where we can estimate transfer potential using say k representation techniques, and then use that to help us understand how well it would do on the other representations.	RWK_EXP	NOOOOOONNNNNEEEE	"Re: (W3) Baselines for transfer learning:
.> The random baseline (i.e a random ordering of candidate task) is compared in figure 3 (and all the plots in the appendix), where we plot the accuracy boost using the best task till now in the produced recommendation of candidate tasks using different methods.
.We can clearly see that the random ordering is much worse compared to informed metrics that use representations.
.Upon your suggestion, we would also add this random baseline in table 2 as well.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
3.  Or simply to a well tuned \lambda, chosen on a per dataset basis? From the text it appears that \lambda is manually selected to trade off accuracy against uncertainty on OOD data.	MET_DAT	NOOOOOONNNNNEEEE	"(3) We observed that as \lambda increases, in the validation set, the uncertainty is increasing, while the accuracy is decreasing.
.So
., a simple heuristic that we use is to choose the highest \lambda that allow high validation accuracy (e.g. > 0.97 on MNIST).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We found that this heuristic works very well in our experiments (the results have updated to reflect on this heuristic).
.We have made this procedure clear in the revised manuscript.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I am wondering this method can be applied to other complex datasets whose latent factors are unknown.	MET_DAT	NOOOOOONNNNNEEEE	"A: Our method is not specific to the image domain and there is no reason it could not be applied to other input types.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In order to use our method, we only require a corpus of data with partially (at least two) labeled factors of variation and a corpus of data which is sparsely labeled for a downstream task.
.Critically, these two sources of data need not be identical!
.This means that an easy way to acquire a corpus with labeled factors of variation is to use a simulator to generate this data,  as we do in this study.
"	NOOOOOONNNNNEEEE	"I am wondering this method can be applied to other complex datasets whose latent factors are unknown.
"	NOOOOOONNNNNEEEE
They start from Equation (4) which is incorrectly denoted as the log-marginal distribution while it is the same conditional distribution introduced in Equation (3) with the extra summation for all the available data points.	MET_DAT	NOOOOOONNNNNEEEE	"(2) In Equation (4) we followed with  p(D | \psi) a standard notation for \sum_n p(y_n | x_n; \psi) (i.e. summation of Equation (3) wrt all data in D) which also can be found e.g. in the work of Graves (2011) [4] and Blundell et al. (2015) [5].
.The objective we introduce for CDNs differs from the ELBO-based objective in VI in the way the logarithm is placed in the first term of the objective: in the ELBO we have a logarithm inside the expectation, while the logarithm is outside the expectation in the CDN objective (note however, that the sample-based approximations get equivalent if only one sample is used).
.Furthermore, in the ELBO we have a fixed value of \lambda = 1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We added a new Section 4 in the revised version of the paper discussing these differences.
.Moreover, we investigated the impact of the different objectives empirically and found that the CDN-based objective led to significantly better results, as shown in the newly added Section 6.4 in the revised manuscript.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It seems to me; the author assumed data from one modality is generated by all the latent factors (see Eq. (11)), then what is the point for assuming the prior of the latent factor is factorized (see Eq. (4) and (5))?	MET_DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The factorization of latent space with respect to the modalities provides a way to differentiate observed and unobserved modalities.
.Therefore, VSAE is capable of handling partially-observed data where the missing modalities can be arbitrary.
.In addition, the embeddings are intuitively more meaningful as input to unimodal encoders is now limited to only observed modalities, eliminating the effect of missing modalities.
.When performing imputation/generation, however, we want to capture the dependencies between modalities.
.In other words, unobserved modalities should be imputed based on the information extracted from observed modalities.
.For experiments, we design this by conditioning decoders on all latent variables, essentially accessing information from all observed modalities.
.This is not in contradiction to the factorized latent variable assumption.
.Instead, the encoders try to embed each modalities individually, while decoders learn the dependencies between different modalities.
"	NOOOOOONNNNNEEEE	"(1) Factorized Latent Variables:
"	NOOOOOONNNNNEEEE
However, I can not agree because you can simply generate poisoned data and train the neural networks on the poisoned data regardless of the underlying approach that is targeted in generating the poisoned data.	MET_DAT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(Q4) Munoz-Gonzalez et al. (2017) showed an experiment using a Convolutional neural network with 450,000 parameters, trained with 1,000 training points and injecting 10 poisoning points.
.In our case, for the experiment with MNIST in Figure 2, we used a deep neural network with more than 40,000,000 parameters, 1,000 training points, injecting up to 400 poisoning points.
.As the reviewer can observe the scale of the experimental evaluation is significantly different.
.On the other side, Paudice et al. (2018a) showed that, in many cases, if we don’t consider appropriate detectability constraints, the attack points generated by optimal attack strategies formulated as bilevel optimization problems can be effectively filtered out with appropriate outlier detection, resulting in blunt attacks.
.This is not the case for pGAN, which is capable of bypassing different defences, including the outlier detection scheme proposed by Paudice et al. (2018a).
.Although defences based on outlier detection can be bypassed, as shown by Koh et al. (2017) (Stronger poisoning attacks break data sanitization defences), the complexity of the bilevel problem significantly increases compared to Munoz-Gonzalez et al. (2017).
.One of the main advantages of pGAN is the possibility of generating poisoning attacks at scale with detectability constraints capable of targeting large deep networks, where strategies relying on bilevel optimization have a limited applicability.
"
"Also, a ""1x"" label seems to be missing in for the full softmax, so that the reference is clearly specified."	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
In a related note, using MF for training BMs have been proposed previously and found to not work due to various reasons:	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- The paper makes use of a result from the David MacKay textbook	RWK	NOOOOOONNNNNEEEE	"Our objective in this section was to provide a empirical lower-bound on the capacity by designing a setup where we can vary the quantity of information contained in a dataset (in our case, N choose n), and evaluate empirically the effect of data augmentation.
.In relation to section 5, we aim at seeing how much a network can remember if it is explicitly trained to remember a given set of images.
.We understand the limitations of MacKay's analysis, which was presented to give a rough theoretical comparison point to our empirical evaluation.
"	"We will clarify this in the paper and improve the discussion along the lines discussed by the reviewer.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree with the reviewer that our analysis of capacity in section 3 does not take into account the magnitude of the weights, nor the dependence on the depth of the network.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“The paper makes use of a result from the David MacKay textbook which defines the capacity of a single layer network to memorize the labelling of $n$ inputs in $d$-dimensional space. [...] It would be great if the paper also made some attempt to consider these connections. Or at least comment on how these factors could be incorporated into a more sophisticated analysis of the capacity of a network.”
"	NOOOOOONNNNNEEEE
- It is not clear why authors did not follow the evaluation protocol of [Achlioptas’17] or [Wu’16] more closely.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3. We followed the same protocol that we trained on ShapeNet55 and tested on ModelNet40 testing set.
.PC-GAN achieves 86.9% accuracy which is better than AAE (84.5%),  3D-GAN (83.3%) and other unsupervised learning approach.
"	NOOOOOONNNNNEEEE	"Please check Table 3 in the revision.
"	NOOOOOONNNNNEEEE
You probably have to limit the operation to a half-sphere (there's some ideas for this in Gu et al).	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"k-addition definiteness in the spherical setting: we have added the formal condition that the k-addition be well-defined, and a proof that for two points this condition indeed recovers x != y / (k ||y||^2) - see Theorem 1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Theorem 5 shows that our proposed left-matrix-multiplication is an intrinsic averaging for Riemannian manifolds of constant curvature, i.e. it does commute with isometries when the matrix A is right-stochastic, which is not the case of right-matrix-multiplication.
.This is a desirable property for Riemannian vector averaging.
.Theorem 6 shows that weighted combinations in the tangent space used in the very recent works of [1,2] (appeared after ICLR submission deadline) is also an intrinsic averaging for Riemannian manifolds of constant sectional curvature, i.e. it does commute with isometries.
"
* The paper states multiple times that VAEAC [Ivanov et al., 2019] cannot handle partially missing data, but I don’t think this is true, since their missing features imputation experiment uses the setup of 50% truly missing features.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In order to establish fair comparison, we used the same backbone network structures and training criteria for all baseline models and our proposed VSAE.
.Therefore, the implementation details differ from the original VAEAC paper.
.We did our best to maintain the optimization details described in all baseline papers.
.Experiments on VAEAC with partially-observed data are also conducted.
"	NOOOOOONNNNNEEEE	"(2) Comparison with VAEAC:
.*VSAE:
.0.455(0.003) on Yeast; 1.312(0.021) on Glass;0.1376(0.0002) on MNIST+MNIST; 0.1198(0.0001) on MNIST+SVHN;
.*VAEAC trained partially:
.0.878(0.006) on Yeast; 1.846(0.037) on Glass;0.1402(0.0001) on MNIST+MNIST; 0.2126(0.0031) on MNIST+SVHN.
"	"Results show that VAEAC under this setting can achieve comparable performance on categorical datasets: 0.245(0.002) on Phishing, 0.399(0.011) on Mushroom while the errors of VSAE are 0.237(0.001) on Phishing,  0.396(0.008) on Mushroom.
.However, on numerical and bimodal datasets, partially trained VAEAC performs worse than VSAE :
"
What is the point that you are trying to make? Also, note that some of the algorithms that you are citing there have indeed applied beyond architecture search, eg. Bayesian optimization is used for gait optimization in robotics, and Genetic algorithms have been used for automatic robot design.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
#3 is so generic that a large part of the previous literature on the topic fall under this category -- not new.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The cited Berrett and Samworth MI test uses a permutation approach to obtaining the test threshold, not an asymptotic approach  (see the results of Section 4 of that paper).	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"8. The itemized part in 5.3, ""...carefully selected baselines: 1.xxx, 2.xxx, 3. xxx, 4. xxx"". However, both 3 and 4 are not baselines!"	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Lee et al. seem to make similar mistakes, and it is likely that their experimental design is also flawed.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Specifically, prior work considered non-missing data during training, while we can't always guarantee that all the modalities are available.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Specifically, the author mentioned Tsai et al. assumed factorized latent variables from the multimodal data, while Tsai et al. actually assumed the generation of multimodal data consists of disentangled modality-specific and multimodal factors.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The factorization of latent space with respect to the modalities provides a way to differentiate observed and unobserved modalities.
.Therefore, VSAE is capable of handling partially-observed data where the missing modalities can be arbitrary.
.In addition, the embeddings are intuitively more meaningful as input to unimodal encoders is now limited to only observed modalities, eliminating the effect of missing modalities.
.When performing imputation/generation, however, we want to capture the dependencies between modalities.
.In other words, unobserved modalities should be imputed based on the information extracted from observed modalities.
.For experiments, we design this by conditioning decoders on all latent variables, essentially accessing information from all observed modalities.
.This is not in contradiction to the factorized latent variable assumption.
.Instead, the encoders try to embed each modalities individually, while decoders learn the dependencies between different modalities.
"	NOOOOOONNNNNEEEE	"(1) Factorized Latent Variables:
"	NOOOOOONNNNNEEEE
It is not even clear that the final compression of the baselines would not be better.	RWK	NOOOOOONNNNNEEEE	"However, SPAMS is a great inspiration for our framework.
.This shows a clear distinction between different methods and an important result: when $\ell_2$ normalizing atoms, dictionary learning may converge to a result for which the ratio of activity between the most activated and the least activated is of the order 2.
.Even if they did show these convincingly, it is not obvious to me that it is valuable."", we have performed the same experiments on more iterations such that we clearly see that baseline stay separate.
"	NOOOOOONNNNNEEEE	"However, we agree that this was not clear in this first revision: atoms which were displayed looked qualitatively similar.
"	NOOOOOONNNNNEEEE	"We have solved this issue thanks to the comments of the anonymous reviewers by now displaying the most and least active atoms.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"First, the goal is not faster computation on a CPU.
.Our (github-shared) code runs in a few dozens of seconds per learning on a standard laptop - but the goal is mainly to be able to test all parameters.
.We have not used SPAMS in this work as we could use the similar methods which are used in the sklearn library.
.It takes a dozens of minutes on a 100 nodes cluster.
.).
.Our motivation is mainly to understand biological vision and hope this would percolate to ML.
.Yes, we obtain faster convergence, but as an epiphenomenon of the better efficiency of our adaptive homeostatic algorithm.
.This result is often overlooked in dictionary learning and is a first novel result of the paper.
.This being said, Figures 1 and 3 now show the clear qualitative advantage of using homeostasis in unsupervised learning.
.This now certainly allow to understand *why* convergence speed is a good indicator ---not for an advantage on the running speed on a classical CPU--- but rather in showing that this allows a more efficient dictionary learning overall.
"	NOOOOOONNNNNEEEE	"Concerning the point "" It is not even clear that the final compression of the baselines would not be better.
"	"(For information, the complete simulations for this paper take approximately 12 hours --which are easily distributed on a cluster as we multiplied the number of independent learning runs using different classes of parameters, cross-validations and types of sparse coding algorithms - in total approx 500 experiments.
"
Finally yet importantly, though a large number of works have been proposed to try to solve this problem especially the catastrophic forgetting, most of these works are heuristic and lack mathematical proof, and thus have no guarantee on new tasks or scenarios.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Other recent works which have demonstrated effective regularization of LSTM LMs have proposed methods that can be used in any LSTM model, but that is not the case here.	RWK	NOOOOOONNNNNEEEE	"Although we proposed Past Decode Regularization (PDR) with language modeling in mind to exploit the symmetry between the input and output vocabulary (and the corresponding word embedding and softmax layer), any model/task that has this symmetry can potentially use a PDR term.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
There has been a large body of work which shows that weaker attacks like membership attacks can be equally damaging, ii) Privacy is a worst-case guarantee.	RWK	NOOOOOONNNNNEEEE	"In the present paper, we chose the “reconstructive error” as the quantification of privacy because it is the most intuitive one to measure the risk of disclosing sensitive background information in the raw data for the given perturbed data (Encoder output).
"	NOOOOOONNNNNEEEE	"We agree that it is essential to justify how the reconstruction error works as a measure of privacy in this paper.
"	NOOOOOONNNNNEEEE	"In the revision, we have added the following justification on privacy quantification in Section 2, Section 4 and Section 5.
"	NOOOOOONNNNNEEEE	"Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a definitely defined application.
.For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN’s Encoder output, and the sensitive patterns founded from the raw data, in the object recognition application.
"	"First, there is no single standard definition of data privacy-preserving problems and corresponding adversary attacks.
.And a fundamental problem in it is the natural tradeoff between privacy and utility, which is affected by different data privacy-preserving methods.
.Our key contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attackers and privacy quantification.
.Second, finding the right measurement for privacy is an open problem in itself.
.To evaluate RAN, one has to pick some quantifications.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also note that the proposed reconstructive adversarial network (RAN), is not an extension of GAN but only borrows GAN’s thoughts on adversarial training several neural networks, for the data privacy-uniquely problem.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The reported FID for CIFAR10 using WGAN-GP is 54.4, which seems to be a bit high.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Also, the authors should compare with few more graphnet + transmission layer (GraphNetST) baselines with the graph layers: $P(X)_i = Ax_i + \sum_{j \in N(x_i, X)} Bx_j + c$ and the same single transmission layer $\mathbf{1}\mathbf{1}^TXB$ in PointNetST.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
PointNet is a specialization of graphnets and GraphNetST should be added as a baseline with reasonable adjacency.	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"* Mor et al. (2018) do actually make use of an adversarial training criterion (referred to as a ""domain confusion loss""), contrary to what is claimed in the introduction."	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"For example, ""The old system of private arbitration courts is off the table"" from DE-EN 2016 Dev doesn't seem like it should benefit from this architecture."	RWK	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, it seems the only Figure showing D’s loss when unconstrained is Figure 26, in which it is hard to notice any significant jump in the loss.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says “losses”.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-Thanks! This was indeed an error, which we’ve corrected in the updated draft.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says “losses”.
"	NOOOOOONNNNNEEEE
A quick glance at Table 1 suggests that the bounds obtained through Theorem 3 are exponential in t and are mostly vacuous.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have clearly indicated that our bound is always polynomial in d and t in the introduction on page 3, which is not vacuous.
.Moreover, both bounds of Theorem 3 are obtained under the same assumptions as in Theorem 2 with additional norm constraints on weight matrices.
.The exponential term stems from the layer wise covering argument rather than the range of the output.
.The bound in Theorem 2 is still polynomial in d and t, since we exploit the parametric form of RNNs and construct the covering by weight matrix coverings.
.Existing literature has shown that keeping the spectral norm of weight matrix U close to 1 stabilizes the training of RNNs.
.This can be achieved by orthogonal initialization and imposing extra constraints or regularization [3-5].
.We further discuss the trade-off between representation and generalization beneath Theorem 2 on page 4: \beta \approx 1 helps balance the generalization and representation of RNNs.
"	NOOOOOONNNNNEEEE	"Vacuous bounds in the regime \beta >1.
"	NOOOOOONNNNNEEEE
Furthermore, Figure 6 and Figure 7 in general show SAVP performing worse than SVG (Denton & Fergus 2018), a VAE model with a significantly less complex generator, including for the metric (VGG cosine similarity) that the authors introduce arguing that PSNR and SSIM do not necessarily indicate prediction quality.	TNF	NOOOOOONNNNNEEEE	"A recent result [1] proves that there is a fundamental tradeoff between accuracy and realism, for all problems with inherent ambiguity.
.In fact, a recent challenge held at ECCV 2018 in such a problem [2] evaluates all algorithms on both of these axes, as neither adequately captures performance.
.Although the SVG generator is simpler than ours, ours is just a simple variation from Ebert et al. (2017).
.Since proposing a strong generator architecture is not the goal of this paper,
.any video generator (including the one from Denton & Fergus (2018)) could be used with our losses.
.Instead, we provide a systematic analysis of the effect of the loss function on this task (which could be applied to any generator).
.It's also worth noting that with a simpler feed-forward posterior and a unit Gaussian prior, our VAE ablation and SVG achieve similar performance on various metrics.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We updated Section 4.4 to indicate that it is to be expected that, although our SAVP model improves on diversity and realism, it also performs worse in accuracy compared to pure VAE models (both our own ablation and SVG).
.We added this clarification to Section 3.4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In the outputs shown in Table 3, the questions generated by the scratchpad encoder often seem to be too general compared to the gold standard, or incorrect.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, the issue still exists in Dreamer, since there seems to be an upper limit of effective horizon length (perhaps around 40, according to Figure 4).	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We address the challenge of long horizons not using long-term model predictions but by learning a value function that estimates the infinite sum of discounted future rewards.
.Figure 4 in our submission shows that this gives Dreamer robustness to the imagination horizon compared to two baselines.
"	NOOOOOONNNNNEEEE	"> However, the issue still exists in Dreamer, since there seems to be an upper limit of effective horizon length (perhaps around 40, according to Figure 4).
.This horizon length is still short compared to the entire horizon length of many MDPs (e.g., 1000).
.I think this point should be discussed in the paper.
.That is, the issue still exists, and Dreamer is less effective with very long horizon.
"	NOOOOOONNNNNEEEE
a) The uncertainties produced by CDN in Figure 2 seems strange.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(a) Thanks for catching this. Indeed this was due to a bug in the toy regression experiment which we have fixed now.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"- p8par1: ""approximate embedding $\alpha(e(\gamma'(...)))$ - $e$ is undefined and should probably be $e'$ (this is also the case in the caption of Fig. 5), and $c'$ should probably be included as well."	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The samples from MNIST in Figure 3 are indeed very blurry, supporting this.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It did also not match any numbers in Tab. 4 of the appendix.	TNF	NOOOOOONNNNNEEEE	"$k=1$
.for both HOF models in Table 1
..
.The small difference in results between HOF-1 in Table 1 and HOF-1 ($k=1$) in Table 4 as well as HOF-3 in Table 1 and HOF-3 ($k=1$) in Table 4 is a matter of different initialization on a later training run.
.We have updated these tables so that the numbers are computed from the same model, rather than separate training runs.
.If we keep the number of compositions fixed while training and test with a larger value of k, we observe that the performance degrades significantly.
.On the other hand, when we use a varying number of compositions (1,2,...,k) at training time, we find that the results do generalize to higher values of k. After several additional compositions (such as k+3, k+4) however, the results start worsening similar to the trend in the fixed k evaluation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have edited the manuscript to clarify this point.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q5: Clarifying values of $k$
"	NOOOOOONNNNNEEEE
For Figure 2, Did you try applying canonicalizations in different orders? Do they give the same results?	TNF	NOOOOOONNNNNEEEE	"A: For our experiments, each training example was bypassed and canonicalized by four different transformations: C_1, C_2, C_1C_2, and C_2C_1.
.So latents are canonicalized in both possible orderings.
.We discuss this point at the bottom of page 4 after equation 6 and will further clarify.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: For Figure 2, Did you try applying canonicalizations in different orders? Do they give the same results?
"	NOOOOOONNNNNEEEE
Table 8 rises some concerns.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Also, since the synthetic image pairs are not multimodal in nature, it is unclear to me for what the messages are conveyed in Figure 3 and 4.	TNF	NOOOOOONNNNNEEEE	"In general, we believe multi-modal data is more general than conventional image-text or video-text pairs.
.By unifying tabular data also as multi-modal (with each attribute as one modality), we show that VSAE provides us a principled way for imputation, capable of generalizing to more data families.
.Specifically, we conducted experiments on two types of data:
"	NOOOOOONNNNNEEEE	"We apologize for unclear description of experimental settings.
"	NOOOOOONNNNNEEEE	"Upon request, we have included more extensive experiments following [1] on MNIST/FashionMNIST, and [2] on CMU-MOSI/ICT-MMMO.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(2) Multimodal Experiments:
.Results are reported in Table 10 and Table 11 (Appendix C.5).
"	"(1) low-dimensional tabular data, and (2) high-dimensional data (pixel or text) as ""multimodal"" to better define the overall task of learning from partially-observed data.
.As shown, VSAE consistently outperforms baseline models across the added experiments as well.
"
(b) a significant clarification of Figure 4.	TNF	NOOOOOONNNNNEEEE	"Specifically, for Wave-U-Net, the green curve indicates the fitting result compared against the noisy target, and the red curve is the result evaluated against the clean signal.
.Therefore, Wave-U-Net fits the noisy target fast but does not produce the clean version of the signal during fitting.
.For Convolution and Dilated Convolution networks, they do fit faster but saturates with low-quality output.
.Harmonic Convolution produces much better results, which is ~3.5 dB higher.
.We highly recommend listening to examples at https://anyms-sbms.github.io to feel the difference.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We rewrote the caption for Fig. 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Clarification on Fig. 4.
"	NOOOOOONNNNNEEEE
When I look at Figure 4abcd, it appears that the Convolution and Dilated Convolutions fit a clean signal faster (it is just not as clean.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Perhaps I am misreading this plot, but it is not obvious to me that this plot supports the claims the authors are making.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Also, Figure 6 is referenced in the text in the context of binary multiplication (""[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6""), but presents results for addition and factorization only."	TNF	NOOOOOONNNNNEEEE	"We have presented results for addition and factorization in the main body of the paper, but refer to readers of the paper to the appendix where we have included a larger set of results.
.The naming of units as “log” “FA1”, “FA2”, etc. are meant to represent the size of the base unit that was merged to create this larger unit, “log” referring to logical units (AND, XOR, etc.), “FA1” being 1 bit full adder, “FA2” being a 2 bit full adder, etc. we have made this clear in the figure caption.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The results were omitted from the main body of the paper for the sake of brevity.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Also, Figure 6 is referenced in the text in the context of binary multiplication (""[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6""), but presents results for addition and factorization only.
"	NOOOOOONNNNNEEEE
- In Table 1, for ImageNet, Shadow Attach does not always generate adversarial examples that have on average larger certified radii than the natural parallel, at least for sigma=0.5 and 1.0. Could the authors explain the reason?	TNF	NOOOOOONNNNNEEEE	"During attack/crafting, we need to make an adversarial example that gets misclassified even after perturbations drawn from a Gaussian distribution centered at zero with scale sigma.
.During evaluation, while the augmentations are drawn from a similar distribution, the realized random variables are not identical to those used for crafting the adversarial perturbation.
.In ImageNet, where the dimensionality is high (224X224X3) and for larger sigmas, to have a relatively dense and representative sampling, we need to sample a lot more perturbations during adversarial example crafting.
.However, in our experiments, we could only sample up to 400 instances per example (the maximum batch-size that could fit on our machine with 4 GPUs is 400).
.This results in having a sparse sample when the standard deviation is higher.
.One can potentially improve these results by using larger batch-sizes (i.e., sampling more) or a more powerful GPU or even a TPU, however we do not have the resources for such experiments at this time.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"[R1: In Table 1, for ImageNet, Shadow Attack does not always generate adversarial examples that have on average larger certified radii than the natural parallel, at least for sigma=0.5 and 1.0. Could the authors explain the reason?]
"	NOOOOOONNNNNEEEE
- In Table 2, it is not clear to me what is the point for comparing errors of the natural images (which measures the misclassification rate of a natural image) and that of the adversarial images (which measures successful attacks rate), and why this comparison helps to support the claim that the attack results in a stronger certificates.	TNF	NOOOOOONNNNNEEEE	"In the original submission, we tried to produce tables that look like the tables in papers that we compare
.to
..
.The randomized smoothing paper reports certified radii and also accuracy (1-error) under various perturbation bounds.
.However, the CROWN-IBP paper and the improved randomized smoothing paper based on adversarial training of smoothed classifiers (SmoothAdv) only report *error rates* using a fixed distance to the decision boundary.
.This is done because, unlike the Randomized Smoothing method, the radii are not directly calculated in the CROWN-IBP method and cannot be accessed directly;  CROWN-IBP takes a fixed radius chosen by the user, and either produces or fails to produce a certificate for that radius.
.This is in contrast to randomized smoothing, which outputs different radii for different images (a larger radius means a stronger certificate).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Please see the (updated) last paragraph of Section 5, which explains this comparison in detail.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"[R1: In Table 2, it is not clear to me what is the point for comparing errors of the natural images (which measures the misclassification rate of a natural image) and that of the adversarial images (which measures successful attacks rate), and why this comparison helps to support the claim that the attack results in a stronger certificates.
.In regards to why we compare the errors on natural images and those of our adversarial images:
"	"In short -  we are comparing the rate at which natural images certify to the rate at which adversarial images certify.
.For the case of large perturbations, we find that our adversarial image produce certificates more often than natural images!
.For small perturbations, our attack still produces certificates reasonably often, although not quite as frequently as natural images.
.This shows that certificates alone cannot be used to reliably discern between natural images, and adversarial images produced by the proposed shadow attack.
"
- Figure 6(a) clearly suggests that the data mean for SVHN and CIFAR are very different, instead of similar.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"While this is not a difference of zero, we don’t see how you could say this “clearly suggests” that the means are “very different.”  In the latest draft, this figure---now Fig 5 (a)---has an x-axis that spans from 0-255.
.Hopefully the overlap in the means in now conspicuous.
"	"We are not sure how you are drawing this conclusion; perhaps from the scale of the x-axis?
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The histogram in Figure 6 (a) (original draft) has an x-axis covering the interval [0.4, 0.55], meaning the maximal difference between a mean in *any pair of dimensions* is 0.15.
.Scaling back to pixel units, 0.15 * 255 = 38.25, meaning that 38.25 pixels is the maximum difference in means.
"	NOOOOOONNNNNEEEE	"5.  “Figure 6(a) [Figure 5(a) in revised draft] clearly suggests that the data mean for SVHN and CIFAR are very different, instead of similar.”
"	NOOOOOONNNNNEEEE
The transfer metrics (MMD and kNN) are opaque to the reader: for instance, in table 1, is a knn score of 43173 qualitatively different than 43180?	TNF	NOOOOOONNNNNEEEE	"We gave references to the papers that introduced such metrics.
.Discussing a set of reference scores should also come with a better explanation of these.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* Incomplete definition of the metrics:
"	NOOOOOONNNNNEEEE
- Why are there missing BLEU scores and the number of parameters in Table 1?	TNF	NOOOOOONNNNNEEEE	"Because those missing numbers (N/A) are not reported in the corresponding literature.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4. Missing BLEU scores & the number of parameters:
"	NOOOOOONNNNNEEEE
Table 1 tries to provide some comparisons on Atari, however number of samples is different for different methods making the comparisons invalid.	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
caption of Fig 1: extractS	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed all the typos as suggested in the revised version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q6.Typos:
"	NOOOOOONNNNNEEEE
typo in absolute in caption of Fig 4	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed all the typos as suggested in the revised version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q6.Typos:
"	NOOOOOONNNNNEEEE
* The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. Why does the MMD version constitute an improvement? Or is it simply more stable to train?	TNF	NOOOOOONNNNNEEEE	"It is more stable to train, it does not require the extra ‘cost’ of an auxiliary network training and it can generalize to many-to-many transfer without requiring as many adversarial networks.
"	NOOOOOONNNNNEEEE	"About the significance of score differences, we agree that it needs more details and comparisons, it was also noted by ""AnonReviewer1"" and we should make alternative tests to scale or give a few more references to the benchmark.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* Why does the MMD version constitute an improvement? Or is it simply more stable to train?
"	NOOOOOONNNNNEEEE
"* The descriptor distributions in Figure 3 don't look like an ""almost exact match"" to me (as claimed in the text)."	TNF	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
In Table 2 I saw some optimizers end up with much lower test accuracy.	TNF	NOOOOOONNNNNEEEE	"2. In appendix B.2 of the paper, we have added the convergence plot for all methods on the CIFAR data sets.
.In some cases the training performance can show some oscillations.
.We emphasize that this is the result of cross-validating the initial learning rate based on the validation set performance: sometimes a better behaved convergence would be obtained on the training set with a lower learning rate.
.However this lower learning rate is not selected because it does not provide the best validation performance (this is consistent with our discussion on the step size in section 6).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"-	In Figure 2.b I’m surprised by the difference obtained in the feature maps for images which seems very similar (only the lighting seems to be different). Is it three consecutive frames?"	TNF	NOOOOOONNNNNEEEE	"Shown at the top row of Figure 2b are not three consecutive frames.
.They are the R, G, B channels of a single frame.
"	NOOOOOONNNNNEEEE	"We apologize for the confusion caused.
"	NOOOOOONNNNNEEEE	"To avoid confusing, we use different colors for them and explained that in the figure.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q4. The top row of Figure 2b is confusing:
"	NOOOOOONNNNNEEEE
-  Is the romantic/ horror flips and their absence the only spurious thing in Figure 4 ?	TNF	NOOOOOONNNNNEEEE	"Indeed, many other words, including “will”, “my”, “has”, “especially”, “life”, “works”, “both”, “it”, “its”, “lives”, “gives”, “own”, “jesus”, “cannot”, “even”, “instead”, “minutes”, “your”, “effort”, “script”, “seems”, and “something”, appear to be spuriously associated with sentiment and are captured by the original-only and revised-only classifiers as highly-weighted features.
., Notably all of these features fall out from the highly-weighted features when our classifier is trained on counterfactually-augmented data.
"	NOOOOOONNNNNEEEE	"We thank the reviewer for pointing out that we should have been more thorough in explaining that while genre is a clear example of such a spurious association, it is far from the only one captured in Figure 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. Could you comment on the differences in your setup in Section 4.1 compared to the VAEAC paper? I’ve noticed that the results you report for this method significantly differ from the original paper, e.g. for VAEAC on Phishing dataset you report PFC of 0.24, whereas the original paper reports 0.394; for Mushroom it’s 0.403 vs. 0.244. I’ve compared the experimental details yet couldn’t find any differences, for example the missing rate is 0.5 in both papers.	RWK_RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Please refer to point (2) for detailed explanation on comparison with VAEAC.
"	"In summary, there are multiple reasons why the performance is not identical with the original VAEAC: (I) the back-bone structures are not the same; (II) training criteria (including batch size, learning rate, etc.) are not the same; and (III)  training/validation/test split is different.
.We would like to emphasize that the aforementioned changes are necessary to establish fair comparison.
"
It is not obvious that shuffling image patches at a particular scale would lead to complete loss of global information, but the paper does show results on SVHN and CIFAR10 for which global information is sufficiently disentangled.	RWK_RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- While the authors mention multiple times that #rhs/#lhs = 1 and 2 are more challenging than #rhs/#lhs=18, they do not sufficiently explain why this is the case anywhere in the paper.	MET	NOOOOOONNNNNEEEE	"Our reasoning is that lower #rhs/lhs are harder because the training admits more spurious solutions in them.
.In such spurious regimes models adapt to the specific lhs-rhs combinations from the training and can not generalize to unseen lhs-rhs combinations (i.e. generalizing from questions about “A” in relation with “B” to “A” in relation to “D” (as in #rhs/lhs=1) is more difficult than generalizing from questions about “A” in relation to “B” and “C” to the same “A” in relation to “D” (as in #rhs/lhs=2).
"	"We will update the paper to be more explicit in explaining these considerations.
"	"We acknowledge that the text of the paper can be improved to explain better why splits with lower #rhs/lhs are generally harder than those with higher #rhs/lhs, and we thank R1 for pointing this
.out
..
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, to state the result of Theorem 4.3, k should be bigger than M c_\eta from the dentition of \tilde{\rho}_k^M, as shown under the equation (4).	MET	NOOOOOONNNNNEEEE	"The result of this theorem holds uniformly for any $k$ (not a fixed $k$).
.Besides, we do not require $k$ bigger than $M c_\eta$ in the definition of $\tilde{\rho}_k^M$. When $k$ is no more than $M c_\eta$, $\tilde{\rho}_k^M$ and $\rho_k^M$ are stochastic processes with same distribution and thus the Wasserstein distance between them is 0.
.And for any $k$ is greater than $M c_\eta$, we have the uniform bound (w.r.t. $k$) as stated in the theorem 4.3.
.We also point out that, as our system is complicated, in taking the limit of $M\to\infty$, we need to ensure that the number of iteration we run is larger than $Mc_\eta$. To be specific, the asymptotic convergence would be
.$$\lim_{k,M \to\infty, \eta \to 0^+} \mathbb{D}_{\text{BL}} (\rho_k, \rho^*)=0$$
.where the joint limit of k and M requires that $k\eta\to\infty$; $\exp(C\alpha^{2}k\eta)\eta^{2}=o(1)$; $(k\eta)/(Mc)=q(1+o(1))$ with $q>1$. Here if $q \leq 1$, we degenerate to Langevin. But when $q>1$ (intuitively that means, when $M$ is large, the number of iterations we run is larger), our dynamics is different from Langevin, which is what we do in the practice.
.Also, we would like to remark that this seemingly strange things is in fact the ‘artifact’ caused by the using of Langevin dynamics at beginning to obtain the $M$ initial samples when we designed the practical implementation of the proposed methods.
.However, it is not really necessary to use Langevin dynamics to get $M$ initial samples, as we can simply using some other initialization distribution and get the $M$ initial samples from that distribution (and by this setting, our dynamics is simply the second phases in Eq (3)).
.All our theory can be easily generalized to this setting using almost identical argument, which can also address your concerns on this issue.
"	"We are sorry for not stating this clearly in the theorem and we have revisited the present of the theorem. We will fix this issue in the next revision.
"	"A1: Thanks for pointing this out.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, to state the result of Theorem 4.3, $k$ should be bigger than $M c_\eta$ from the dentition of $\tilde{\rho}_k^M$, as shown under the equation (4).
"	NOOOOOONNNNNEEEE
The approach is not linked to so called Tandem approach that was/is popular in speech recognition where a generative model (GMM) is trained on top of features extracted by a neural network model.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We clarified this in Section 2 of the revised draft.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As you pointed out, our method is somewhat related to Tandem approach [1] in that both post-process a generative model on top of hidden features extracted by DNNs.
.However, the main purpose of Tandem is not for handling noisy labels.
.In particular, the Tandem approaches utilize the EM algorithm that should be highly influenced by outliers, while our method is specialized to be robust against them.
"	NOOOOOONNNNNEEEE	"Q2. Relation to Tandem approach.
"	NOOOOOONNNNNEEEE
- The proposed approach is a fairly specific form of self-modulation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Can you clarify how you view the relationship between the approaches mentioned above?	MET	NOOOOOONNNNNEEEE	"1. BigGAN performs conditional generation, whilst we primarily focus on unconditional generation.
.BigGAN splits the latent vector z and concatenates it with the label embedding, whereas we transform z using a small MLP per layer, which is arguably more powerful.
.In the conditional case, we apply both additive and multiplicative interaction between the label and z, instead of concatenation as in BigGAN.
.2. Overall BigGAN focusses on scalability to demonstrate that one can train an impressive model for conditional generation.
.Instead, we focus on a single idea, and show that it can be applied very broadly.
.We provide a thorough empirical evaluation across critical design decisions in GANs and demonstrate that it is a robust and practically useful contribution.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing out the connection to this concurrent submission.
.We will discuss the connections in the related work section.
"	"- Relationship to z-conditioning strategy in BigGAN.
.The main differences are as follows:
"	NOOOOOONNNNNEEEE
- important features for the new task should be in similar locations as important features of the old task (for example, one would expect that the proposed approach would negatively affect learning the new task if the important features of the old task were all located in the bottom of the image, while all important features for the new task are in the top)	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Having said that, we acknowledge that more agility to, at least, discover that early on would be beneficial.
.More importantly, a normalization strategy on top of our attention map would help enhance its invariance properties, potentially leading to a more robust treatment of the locations of important features.
"	NOOOOOONNNNNEEEE	"In page 4 in the revised version (footnote 3), we have clarified this and notified its potential for future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-- Continual learning typically assumes a degree of similarity among the tasks.
.If tasks are completely different from each other, then most continual learning frameworks will somehow struggle.
.For example, the standard Split MNIST benchmark is in line with this “locations of important features” assumption.
"	NOOOOOONNNNNEEEE	"R: - ""important features for the new task should be in similar locations ...""
"	NOOOOOONNNNNEEEE
For example, by increasing the amount or size of image regions to be considered, the classifier may accidentally become more robust on an old task.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It is definitely a good idea to analyse the correlation between changes in classification accuracy and in FSM values, thank you. We will rigorously investigate this in future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-- It is true that evaluating the FSM is not necessarily the same as the classification results, which is precisely the reason why we show both in our results.
"	NOOOOOONNNNNEEEE	"R: - FSM vs. Classification performance
"	"As specified in page 2, “Here we propose a new measure ...” - our point in this regard is to propose another (different) manner via which catastrophic forgetting can be estimated, which is not the same as the classification accuracy.
.The goal is that (as we know and agree they are two different measures that might agree or disagree in their judgments on catastrophic forgetting) both can be used to inspect the degree of catastrophic forgetting.
.We have further clarified that in Section 6.2 in the experiments by stressing that the obtained FSM results “along with the classification results” denote the significance of the whole framework in addressing catastrophic forgetting.
"
- The randomized weight is not very practical. Though it may be the standard approach of mean field,	MET	NOOOOOONNNNNEEEE	"However, it is true that most commonly used weight initialization schemes are random.
.For example, He initialization [1] and Xavier initialization [2] strategies are both special cases of the setup considered here.
.We therefore view our theory as a theory of neural networks at initialization.
.(There are, however, initialization schemes that are not random and that are not described by our theory).
"	NOOOOOONNNNNEEEE	"3) It is true that the extent to which randomized weights describe trained networks is unclear.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Why should we use embedding to compare the similarity?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1- There are two reasons that concept and problem embedding are performed in this work.
.Considering concept continuity is an important matter in education.
.Having concept embedding, concept continuity can be reached as is discussed in the last paragraph on page 7 and some other examples are given in table 2.
.By just having the most sophisticated concept extractor, the concept continuity cannot be retrieved.
.Furthermore, problem embedding is used by the recommender system to project the performance of students on the problems they solved onto other problems that they have not solved.
.This way, we have an idea of what problems should be recommended to them and which problems should not by having an evaluation of their ability to solve unseen problems and recommend problems in the boundary of their capacity, not way beyond, and to recommend problems in a way that covers all concepts necessary for students to learn.
.We have observed interesting patterns, e.g. similar problems are more likely to be solved correctly at the same time or wrong at the same time.
.Note that by just having the concepts of problems that are not in numerical form, performance projection may not be feasible and there is a need for using other methods like embedding.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This means that it is not apriori clear if using this solver instead of standard SGD, ADAM is any good.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"That said, we were indeed not able to demonstrate end-to-end gains in vision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Please note that in the NLP benchmark our algorithm finds a better solution and wins in wall-clock time.
"	NOOOOOONNNNNEEEE	"@Update overhead: We argue that per-iteration performance is a worthwhile objective in itself, which is less significant in some scenarios (e.g. costly function evaluation, like in RL, or expensive backprops, like in RNNs).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I find these assumptions too strong for the task of learning disentangled representation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(1) we only require access to meta-labels on the source set
.(2) our goal is not to find disentangled representations; Our goal is transferability so that we can learn on real data with minimal supervision.
"	NOOOOOONNNNNEEEE	"Q: ""...I find these assumptions too strong for the task of learning disentangled representation.""
.A: We wish to emphasize that:
"	NOOOOOONNNNNEEEE
The proposed method is very simple and frames the problem basically as a supervised learning problem.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
They can indeed be subsumed by generalization bounds based on VC theory.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have clearly indicated that our bound is always polynomial in d and t in the introduction on page 3, which is not vacuous.
.Moreover, both bounds of Theorem 3 are obtained under the same assumptions as in Theorem 2 with additional norm constraints on weight matrices.
.The exponential term stems from the layer wise covering argument rather than the range of the output.
.The bound in Theorem 2 is still polynomial in d and t, since we exploit the parametric form of RNNs and construct the covering by weight matrix coverings.
.Existing literature has shown that keeping the spectral norm of weight matrix U close to 1 stabilizes the training of RNNs.
.This can be achieved by orthogonal initialization and imposing extra constraints or regularization [3-5].
.We further discuss the trade-off between representation and generalization beneath Theorem 2 on page 4: \beta \approx 1 helps balance the generalization and representation of RNNs.
"	NOOOOOONNNNNEEEE	"Vacuous bounds in the regime \beta >1.
"	NOOOOOONNNNNEEEE
The bound obtained in Theorem 2 comes rather easily from the bounded assumption on the non-linearity and is this not very interesting.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have clearly indicated that our bound is always polynomial in d and t in the introduction on page 3, which is not vacuous.
.Moreover, both bounds of Theorem 3 are obtained under the same assumptions as in Theorem 2 with additional norm constraints on weight matrices.
.The exponential term stems from the layer wise covering argument rather than the range of the output.
.The bound in Theorem 2 is still polynomial in d and t, since we exploit the parametric form of RNNs and construct the covering by weight matrix coverings.
.Existing literature has shown that keeping the spectral norm of weight matrix U close to 1 stabilizes the training of RNNs.
.This can be achieved by orthogonal initialization and imposing extra constraints or regularization [3-5].
.We further discuss the trade-off between representation and generalization beneath Theorem 2 on page 4: \beta \approx 1 helps balance the generalization and representation of RNNs.
"	NOOOOOONNNNNEEEE	"Vacuous bounds in the regime \beta >1.
"	NOOOOOONNNNNEEEE
- The search space of the proposed method, such as the number of operations in the convolution block, is limited.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We will present the full experiments of semantic segmentation in the future revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The following table shows the performance of our model on the PASCAL VOC 2012 semantic segmentation task, where DSO-NAS-cls represents the architecture searched on ImageNet with block structure sharing and DSO-NAS-seg represents the architecture searched on PASCAL VOC segmentation task.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A1: First, the size of search space is not determined by the number of operations but the number of connections.
.The search space of our method is different from exiting NAS methods in that the number of input of certain operation is not limited.
.Second, the search space without block share is even much larger than existing NAS methods.
.Third, we can trivially extend our DSO-NAS to accommodate more operations such as dilated conv like our ongoing experiments on PASCAL VOC semantic segmentation task, we extend our search space to accommodate 3x3 and 5x5 separable convolution with dilated = 2.
"	NOOOOOONNNNNEEEE	"Q1. “The search space of the proposed method, such as the number of operations in the convolution block, is limited.”
.---------------------------------------------------------------------------------------------------------------------------
.Architecture
.mIOU                     Params(M)
.FLOPS(B)
.---------------------------------------------------------------------------------------------------------------------------
.---------------------------------------------------------------------------------------------------------------------------
"	"DSO-NAS-cls
.72.1
.6.5                               13.0
.---------------------------------------------------------------------------------------------------------------------------
.DSO-NAS-seg(more operations)
.72.7                            6.7                               13.2
.We combine DSO-NAS with Deeplab v3 and search for the architecture of feature extractor with block sharing.
.All above models have been pre-trained on ImageNet classification task first.
.It’s notable that the architecture searched on semantic segmentation task with additional operations achieve better performance in our preliminary experiment, indicating that our DSO-NAS is capable to incorporate additional operations.
"
One question which is not addressed is the reason for only one RBM layer.	MET	NOOOOOONNNNNEEEE	"2. The complete connectivity graph for our Boltzmann machine, as presented in Fig 2, can be interpreted as having two hidden layers.
.The graph has bipartite connectivity between the visible units and the first 128 hidden units and bipartite connectivity between the first 128 hidden units and the second 128 hidden units.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We thank the referee for bringing the article [V] to our attention and we now have acknowledged the prior work properly in our introduction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We are not training Restricted Boltzmann Machines (RBMs), but Boltzmann machines where the hidden units can be fully connected.
"	NOOOOOONNNNNEEEE
Furthermore, If I deploy the learning algorithm on a physical robot, will the temporally consistent exploration cause less wear and tear to the actuators when the robot explores.	MET	NOOOOOONNNNNEEEE	"That temporally consistent exploration is fairly important for physical robots is one of our motivations for this whole project.
.Our ultimate goal is to find a safer and more efficient way for on-policy exploration on physical robots.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the next step we will look for simulator environments with more authentic actuators to see how NADPEx could help solve that.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
My assumption is the visual feature already contains the label information for image captioning.	MET	NOOOOOONNNNNEEEE	"- That may be true to some extent.
.However, we think that explicit label information might still be useful since the visual features (environment) are from Faster RCNN and contain diverse information such as edges, background, color, and size.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4. CIDEr score of captioning
"	NOOOOOONNNNNEEEE
Is the number right?	MET	NOOOOOONNNNNEEEE	"- Yes, the numbers are from their paper.
.One possible explanation for this could be their use of high regularization for a single model instead of ensembling.
.Thus, the performance improvement from training on the train set (evaluating on validation) to training on train+val (evaluating on test-dev) is smaller.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"7. Table 4, accuracies are from Zhang et al. 2018
"	NOOOOOONNNNNEEEE
It adds extra complexity, requires you to do function composition which may be less expressive and takes more coomputation, etc. And to what end?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The function composition doesn't capture that.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree that the current formulation of composition is not equivalent to a generative model.
"	NOOOOOONNNNNEEEE	"We have revised the abstract to clarify this point.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In our work, function composition primarily serves the purpose of demonstrating that the model learns a meaningful subspace of objects (rather than memorizing the training set, as you mentioned).
"	NOOOOOONNNNNEEEE	"""The purpose of generative models is not to interpolate per se; the interpolation is really a sanity check that the model is capturing the underlying distribution rather than just memorizing training examples.
.The function composition doesn't capture that.
.I think the authors should just acknowledge that you can't soundly *sample* from their generative model the way e.g. VAE or GAN allows (their function composition is not a sampling method).
.But I think there are lots of useful things you can do without that capability, e.g. do 3D point cloud completion, go image -> structure, etc. I think this function composition angle should be deemphasized in the title/abstract, but I think the paper stands  reasonably on its own without that.""
"	NOOOOOONNNNNEEEE
2. Besides the computational expensive-ness of the three-step approach (vector quantization, BERT, acoustic model training), the combined model complexity is large because these steps do not share neural network architecture.	MET	NOOOOOONNNNNEEEE	"We did not follow this direction due to two motivations: first, our aim is to contribute a new quantization scheme for audio data that is trained to predict the context in a self-supervised way.
.Second, we wanted to show that good performance can be achieved with discretized audio on actual speech tasks.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Yes, this is an interesting avenue for future work!
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> 2.
.A more economical approach is to use BERT-trained model as initialization for acoustic model training, which is the classical way how RBMs pre-training were used in ASR.
"	NOOOOOONNNNNEEEE
This claim is unfortunately unfounded for a very important reason: the LSTM performance is not at all close to that which can be achieved by LSTMs in general.	MET	NOOOOOONNNNNEEEE	"We spent a considerable amount of time trying to fulfill the reviewer’s request to match state of the art (SOTA) on PTB.
.Still, we pursued two directions.
.First, we tried to reimplement an architecture similar to  Melis et al. 2017.
.However, they did not publish their code, hyperparameters, or weights, requiring re-implementing and re-training from scratch.
.We tried this path, but soon realized we would not be done in time (especially with a hyperparameter search).
.We then tried to weave neuromodulation and differentiable plasticity into the architecture and code base of Merity et al., ICLR 2018 (also tied for SOTA).
.However, while they could simply leverage existing PyTorch implementations of LSTMs (written in extremely fast C++), we had to re-implement LSTMs “by hand” (i.e. as a series of connected layers) in PyTorch to introduce plasticity and neuromodulation.
.As a result, our networks thus ran considerably slower, by more than 10x (not because our method is intrinsically slower, but just for lack of engineering optimizations on our bespoke Python implementations; we confirmed this by observing that a similar “hand-built” reimplementation of simple, non-plastic LSTMs ran similarly slower, while producing results identical to Merity et al.).
.These experiments are thus unfortunately still running.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).
"	NOOOOOONNNNNEEEE	"For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"That said, we still believe the results in the current paper demonstrate the benefits of our techniques on a sizable model, and thus it would benefit the community to allow people to know about, and build upon, these new methods and results.
.The purpose of the present paper is to introduce a novel technique and show that it can produce an advantage in realistic settings, which we believe our PTB task confirms.
.Our claim is that, all other things being equal (especially the number of parameters), a neuromodulated plastic LSTM outperformed a standard LSTM on this particular benchmark task.
.We do **not** want to claim that our results are anywhere near SOTA.
.Additionally, philosophically, If SOTA results are the bar for all papers to be accepted into conferences like ICLR, then those venues will be the exclusive domain of those with either the computation or time (i.e. large-scale resources) to dedicate to such results.
.In that case, many cutting edge ideas will by necessity be excluded from the discussion, as will many research groups.
.Moreover, insisting on papers to be SOTA to be accepted also likely encourages p-hacking and shoddy science to game the results (even if unintentionally), reducing the quality of science our community tries to build on.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Though this may be true, these models still undermine the claim that “neuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task”.	MET	NOOOOOONNNNNEEEE	"We spent a considerable amount of time trying to fulfill the reviewer’s request to match state of the art (SOTA) on PTB.
.Still, we pursued two directions.
.First, we tried to reimplement an architecture similar to  Melis et al. 2017.
.However, they did not publish their code, hyperparameters, or weights, requiring re-implementing and re-training from scratch.
.We tried this path, but soon realized we would not be done in time (especially with a hyperparameter search).
.We then tried to weave neuromodulation and differentiable plasticity into the architecture and code base of Merity et al., ICLR 2018 (also tied for SOTA).
.However, while they could simply leverage existing PyTorch implementations of LSTMs (written in extremely fast C++), we had to re-implement LSTMs “by hand” (i.e. as a series of connected layers) in PyTorch to introduce plasticity and neuromodulation.
.As a result, our networks thus ran considerably slower, by more than 10x (not because our method is intrinsically slower, but just for lack of engineering optimizations on our bespoke Python implementations; we confirmed this by observing that a similar “hand-built” reimplementation of simple, non-plastic LSTMs ran similarly slower, while producing results identical to Merity et al.).
.These experiments are thus unfortunately still running.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).
"	NOOOOOONNNNNEEEE	"For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"That said, we still believe the results in the current paper demonstrate the benefits of our techniques on a sizable model, and thus it would benefit the community to allow people to know about, and build upon, these new methods and results.
.The purpose of the present paper is to introduce a novel technique and show that it can produce an advantage in realistic settings, which we believe our PTB task confirms.
.Our claim is that, all other things being equal (especially the number of parameters), a neuromodulated plastic LSTM outperformed a standard LSTM on this particular benchmark task.
.We do **not** want to claim that our results are anywhere near SOTA.
.Additionally, philosophically, If SOTA results are the bar for all papers to be accepted into conferences like ICLR, then those venues will be the exclusive domain of those with either the computation or time (i.e. large-scale resources) to dedicate to such results.
.In that case, many cutting edge ideas will by necessity be excluded from the discussion, as will many research groups.
.Moreover, insisting on papers to be SOTA to be accepted also likely encourages p-hacking and shoddy science to game the results (even if unintentionally), reducing the quality of science our community tries to build on.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Concerns: I find the claim on deep networks kind of irresponsible.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Second, the conclusion of Theorem 2 seems to be flawed.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Specifically, we agree with the 1) and 2) of your analysis.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"For the first and second comments, we appreciate the detailed example you proposed.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This illustrates that the conclusion of Theorem 2 may be wrong.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Specifically, we agree with the 1) and 2) of your analysis.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"For the first and second comments, we appreciate the detailed example you proposed.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.	MET	NOOOOOONNNNNEEEE	"We find that removing any of them leads to a decrease in performance (Rows 2, 3, 4 of Table 5).
.To provide more than just this quantitative insight, we’ll expand here on how KG-MRC handles coreference to better motivate the modeling choices:
.The construction of graph G_t from G_{t-1} uses co-reference disambiguation of nodes to prevent node duplication and to enforce temporal dependencies.
.We perform coreference disambiguation between location nodes of G_t and G_{t-1} via Eq. 1 (call this inter-graph coreference) and between the location nodes in the same graph Gt (call this intra-graph coreference) via Eq. 2.
.The inter-graph coreference yields new, intermediate representations for the nodes in G_t.
.These are further updated via the intra-graph coreference step.
.Inter-graph Co-ref: One way to think about this is that we construct a new graph G_t at every time step.
.Now the graph G_{t-1} might contain some location nodes which are predicted again at time step ‘t’ (e.g., in Figure 2, leaf node already existed in G_{t-1}).
.Instead of replacing an old node with an entirely new node at ‘t’, we take a recurrent approach and do a gated update that preserves some information stored in the node in previous time steps while adding new information unique to time step ‘t’.
.Intra-graph Co-ref: Inter-graph co-ref isn’t enough since the MRC module makes its span predictions independently.
.This means that, at time step t, the model could predict the same span/location for multiple entities and add all these duplicates to the graph.
.Moreover, a single location might have the same surface form but be from different parts of the paragraph (e.g. “leaf” in the 1st and the 5th sentence of the para in figure 2).
.The operations in Eq. 2 resolve this by performing self-attention (i.e., the predicted locations of all entities are compared to each other).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Based on your comments, we’ve performed additional ablations to measure the impact of the co-reference mechanisms.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.
.This is especially the case in a few places involving coreference:
.1. The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.
.2. The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.
.While these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.
.======
"	NOOOOOONNNNNEEEE
Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?	MET	NOOOOOONNNNNEEEE	"In a nutshell, this is necessary because, after the recurrent and residual graph updates (Eqs 3.1 - 3.3) that propagate information across edges, we may end up with different representations for location nodes corresponding to the same location.
.We don’t want these representations to diverge from each other because of information propagation.
.The graph update step ensures information propagation between entities and location representations.
.Specifically if the current location of entity “e_t” is predicted as “\lambda_t”, the graph update steps ensures that both the entity and location representation gets the same update (via eq 3.2 and 3.3).
.This would have been sufficient if every entity had a unique location.
.But, multiple entities can actually exist in the same location.
.Water - -> leaf
.CO_2 --> leaf
.Here both water and CO_2 exist in the same location, leaf.
.But let’s say that the MRC model picked the “leaf” span from sentence 1 (of the text in Fig 2) for “Water” and from sentence 4 for CO_2.
.In reality, they refer to the same location entity “leaf”.
.Now, due to eq. 3.3, the two embeddings of leaf will get two different residual updates (one would be corresponding to Water and other would be because of CO_2).
.Because of the different updates, the two representations of the same entity might diverge.
.To remedy this, we re-use the coreference matrix “U” we create in eq. (2), which should already have a high attention score corresponding to the two leaf locations.
.Thus we perform a similar operation to the intra-graph update.
"	NOOOOOONNNNNEEEE	"We agree that the coreference pooling in the graph update seems repetitive at first glance.
"	NOOOOOONNNNNEEEE	"We have further clarified the explanation given in the text and included another ablation experiment  (row 4 of Table 5) to confirm its usefulness.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Why does the graph update require coreference pooling again?
.Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?
.=====
.This step does indeed repeat Eq. 2.
.To give you more detail:
.Let’s consider this small graph below
"	NOOOOOONNNNNEEEE
Another modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?	MET	NOOOOOONNNNNEEEE	"The “prefixes” that our model reads at each time step comprise all sentences up to and including the current sentence s_t.
.The motivation for this modeling choice was empirical.
.In our preliminary experiments we evaluated alternative strategies, such as (a) only considering the current sentence s_t, and (b) considering the entire paragraph at every time step.
.We found that operating on prefixes performed best.
.This is in line with the findings of Dalvi et al., 2018, where the Pro-Global model (which uses prefixes) performs better than the Pro-Local model (which operates on single sentences).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Another modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?
.====
"	NOOOOOONNNNNEEEE
Is \eta_{\mathcal{H}} is a better estimation that previous adaptability term in multi-source DA? What is the role of \eta_{\mathcal{H}} in the algorithm design? How to control it in empirical algorithm?	MET	NOOOOOONNNNNEEEE	"- As we explained in Thm.1, \eta_{\mathcal{H}} is a constant measuring how well the model family \mathcal{H} can fit the true models from both domains.
.Estimating this term requires *labelled* target samples, which is usually unavailable in domain adaptation.
.However, when we have access to a handful of labelled target data, we can certainly estimate this term and perform model selection (e.g., choosing neural network models \mathcal{H}) better, meaning that we can find better values for alphas, and so achieve even better adaptation performance.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The paper does not provide very significant evidence that this method is useful.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
-1 The mathematics in section 3.1 is unclear and potentially flawed (more below).	MET	NOOOOOONNNNNEEEE	"2. The details of derivative estimation can be found in Section 3.1 (especially equation 9 and 10 in our updated version.
"	NOOOOOONNNNNEEEE	"We apologize for the confusions in Section 3.1.
.1. About equation 8, indeed there is a typo and should be a ""partial"" sign in front of the ""\delta"" function in the numerator.
"	NOOOOOONNNNNEEEE	"We have reorganized this section, as shown in our updated paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out.
"	"** Clarification on Mathematics in Section 3.1 **
.For your questions:
"	NOOOOOONNNNNEEEE
"-4 Talking about ""agents"" and ""Multi-Agent"" is a somewhat confusing given the slightly different use of the same term in the reinforcement literature. Why not just ""mapping"" or ""network""?"	MET	NOOOOOONNNNNEEEE	"Although with the same term, the ""multi-agent"" or ""agent"" in this paper has no relationship with multi-agent reinforcement learning.
.You are right in that the term ""agent"" in our context refers to ""mapping"" or ""network"".
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"*
.* Term usage of ""multi-agents"" **
.You can check our updated paper with clarification and new experimental results.
"	NOOOOOONNNNNEEEE
"At the very least we need another ""partial"" sign in front of the ""\delta"" function in the numerator."	MET	NOOOOOONNNNNEEEE	"2. The details of derivative estimation can be found in Section 3.1 (especially equation 9 and 10 in our updated version.
"	NOOOOOONNNNNEEEE	"We apologize for the confusions in Section 3.1.
.1. About equation 8, indeed there is a typo and should be a ""partial"" sign in front of the ""\delta"" function in the numerator.
"	NOOOOOONNNNNEEEE	"We have reorganized this section, as shown in our updated paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out.
"	"** Clarification on Mathematics in Section 3.1 **
.For your questions:
"	NOOOOOONNNNNEEEE
So is the REINFORCE estimator used or something? Not that the importance sampling matter is orthogonal.	MET	NOOOOOONNNNNEEEE	"2. The details of derivative estimation can be found in Section 3.1 (especially equation 9 and 10 in our updated version.
"	NOOOOOONNNNNEEEE	"We apologize for the confusions in Section 3.1.
.1. About equation 8, indeed there is a typo and should be a ""partial"" sign in front of the ""\delta"" function in the numerator.
"	NOOOOOONNNNNEEEE	"We have reorganized this section, as shown in our updated paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out.
"	"** Clarification on Mathematics in Section 3.1 **
.For your questions:
"	NOOOOOONNNNNEEEE
As with ensembles, clearly it only helps to have multiple agents (N>2) if the additional agents are distinct from f_1 (again without loss of generality this applies to g as well).	MET	NOOOOOONNNNNEEEE	"We obtained distinct ""agents"" f_i and g_i through multiple independent runs with different random seeds and different input orders of the training samples.
.There are, of course, many other ways to introduce more diversity, including using different optimization strategies, or training with different subsets as you suggested.
"	NOOOOOONNNNNEEEE	"1. You are right.
.But we agree with you that intuitively, more diversity among agents leads to greater improvements.
"	NOOOOOONNNNNEEEE	"2. Following your suggestions, we add a study on the diversity of agents (presented in Appendix A of the updated paper).
"	NOOOOOONNNNNEEEE	"We leave more comprehensive studies on diversity to future work.
"	"All of these can potentially bring further improvements to our framework, yet are not the focus of this work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"** Study on diversity of agents **
.Please kindly refer to Appendix A for more detailed results.
"	"We design three group of agents with different levels of diversity: (E1) Agents with the same network structure trained by independent runs, i.e., what we use in Section 3.3; (E2) Agents with different architectures and independent runs; (E3) Homogeneous agents of different iteration, i.e., the checkpoints obtained at different (but close) iterations from the same run.
.We evaluate the above three settings on IWSLT2014 De<->En dataset.
.The diversity of the above three settings would intuitively be (E2)>(E1)>(E3)
..
.We present full results in Figure 4 (Appendix A), where the BLEU scores with Dual-5 model are:
.--------------------------------------------------------
.E1
.E2             E3
.--------------------------------------------------------
.En -> De
.35.44
.35.56       34.97
.De -> En
.29.52
.29.58       29.28
.--------------------------------------------------------
.From the above results, we can see that diversity among agents indeed plays an important role in our method.
.From the current studies, we show that our algorithm is able to achieve substantial improvement with a reasonable level of diversity.
"
However, the proposed upper bound in the paper involves other parameters, such as the model complexity and the number of training samples.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1). Why minimizing the upper bound in this scenario would help to minimize the loss on the target domain, when the upper bound can be substantially huge? How about just evaluate \alpha by the closeness of the source domain with the target domain?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Minimizing an upper bound is arguably the only viable option *with theoretical generalization guarantee*. It is a common practice in the domain adaptation community (Mansour et al., 2009a, 2009b; Ben-David et al. 2007, 2010; Cortes and Mohri, 2011), and it is essentially the key idea of PAC learning and generalization analysis (Györfi et al., 2006; Schölkopf et al., 2002; Vapnik, 2013).
.Besides, our method *directly* optimizes the upper bound without resorting to heuristics, unlike prior methods.
"	NOOOOOONNNNNEEEE	"1) Upper bound
"	NOOOOOONNNNNEEEE
"Intuitively, these criteria are well motivated, but unfortunately, the combination of all the intuitions (including ""selection network"" with threshold) is not very principled."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"To me this paper is just not good enough - the method essentially i) use ""a professor and two teaching assistants"" to build a ""rule-based concept extractor"" for problems, then ii) map problems into this ""concept space"" and simply treat them as words. There are several problems with this approach."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Moreover, the main difference between math problems and other problems is that there are math expressions; I do not think that using words/concept labels only is enough without touching on the math expressions.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1- We briefly mentioned the way problem embedding with similarity metric is used in the recommendation system in this work, but here is more explanation on that.
.The most similar problem is not necessarily recommended to a student.
.On a high level, if a student performs well on problems, we assume he/she performs well on similar problems as well, so we recommend a dissimilar problem and vice versa.
.More specifically, we project the performance of students on problems they solved onto the problems that they have not solved.
.This way, we have an evaluation of the performance of students on unseen problems.
.A problem is recommended that is within the capacity of students close to their boundary to help them learn, and at the same time recommendation is done so that all the concepts necessary for students are practiced by them.
.An evaluation on real students is presented in part 2 of the comment titled “Response to questions about Prob2Vec” on this page, and we observed that similar problems are more likely to be solved correctly at the same time or wrong at the same time.
.The math expressions are not ignored in our proposed Prob2Vec method.
.In the example given in the last paragraph on page 3 for example, math expressions are used to extract the concept n-choose-k.
.We both use math expressions and text to label problems with appropriate concepts.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Second, the proposed method does not sound scalable - the use of a professor and two teaching assistants to construct the concept extractor, and the use of an expert TA to select a small set of informative words.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2- Prob2Vec only uses expert knowledge for rule-based concept extractor, but does not use selected informative words.
.The effort put for rule-based concept extractor is negligible compared to effort needed for annotation of all problems with their corresponding concepts.
.We both annotated all problems manually and used rule-based concept extractor for annotation.
.In the former method, we observed 100% accuracy in the similarity detection test and observed 96.88% accuracy in the latter method.
.However, the rule-based concept extractor needs much less manual effort than manual problem annotation and is capable to provide us with relatively high level of accuracy we need in our application.
.Note that our method is scalable as long as problems are in the same domain as the rule-based concept extractor is automated for a single domain, but for the case that problems span many different domains, it is the natural complexity of the data set that requires a more sophisticated rule-based concept extractor.
.Furthermore, in most realistic cases for education purposes, problems span a single domain not multiple ones.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Algorithm 1 does not include mitosis, which may have an effect on the resulting approximation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Mitosis training can be considered as executing Algorithm 1 for multiple times with an increasing number of experts and inherited initialization from last round by changing W^e and W^g.
.Also, training with mitosis achieves similar performance as training without it shown in Appendix B, Figure (a).
"	NOOOOOONNNNNEEEE	"- Algorithm 1 does not include mitosis, which may have an effect on the resulting approximation.
"	NOOOOOONNNNNEEEE
This claim is bigger than just CNNs and needs to be studied in a theoretical framework not an empirical one.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Also, one simple way to stop these adversarial cases would be to explore using Sigmoid as opposed to softmax.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We would be appreciated if the reviewer could provide us with the references that showing using only sigmoid could control such a challenging problem of adversaries.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Please note we did not aim to devise a method that is able to reject all adversaries.
.Rather, we attempted to show that a CNN with less over-generalization is able to reject some of the adversaries while correctly classifies many of the remainder, particularly non-transferable attacks.
"	NOOOOOONNNNNEEEE	"The reviewer mentioned: “ Also, one simple way to stop these adversarial cases would be to explore using Sigmoid as opposed to softmax”:
"	NOOOOOONNNNNEEEE
This restriction exists in Dreamer, and the method cannot be applied to discrete control tasks unless approximation techniques such as Gumbel-softmax are used.	MET	NOOOOOONNNNNEEEE	"This was a drop-in replacement for the reparameterization estimator and slightly outperformed a Gumble-softmax actor.
.We find that with this 1 line change, Dreamer solves discrete action tasks of the Atari suite and a 3D DMLab environment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We applied Dreamer to environments with discrete actions using the DiCE estimator (Foerster et al. 2018) locally for the da/dμ and da/dσ derivatives.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> Inapplicability to discrete controls:  One restriction of re-parameterized gradients is that the technique is not applicable to discrete random variables.
.This restriction exists in Dreamer, and the method cannot be applied to discrete control tasks unless approximation techniques such as Gumbel-softmax are used.
.Still, such approximations would make learning more challenging, especially with long-horizon backpropagation.
.This restriction should be noted in the paper.
"	NOOOOOONNNNNEEEE
Dreamer does not use any variance reduction technique, so the gradient estimates could have very large variance.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Dreamer uses reparamterization gradients that already have low variance (Kingma & Welling 2013, Rezende et al. 2014); although see Miller et al. (2017).
.Learning baselines for variance reduction is common for Reinforce estimators as used in A3C and PPO (Mnih et al. 2016, Schulman et al. 2017) but not for reparameterization estimators as used in Dreamer, SVG, and SAC (Heess et al. 2015, Haarnoja et al. 2018).
"	NOOOOOONNNNNEEEE	"> There is no mention about variance of policy gradient estimates.
.Dreamer does not use any variance reduction technique, so the gradient estimates could have very large variance.
"	NOOOOOONNNNNEEEE
The definition of “recovering true factor exactly” need to be given.	MET	NOOOOOONNNNNEEEE	"Therefore, the error drops exponentially with iterations t. In other words, as t —> infinity A_i —> A^*_i for i in [1,m] and x_j —> x^*_j for j in [1,m], where x_j is in R^m.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have added this clarification in Section 1.1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Regarding exact recovery guarantees — NOODL converges geometrically to the true factors.
"	NOOOOOONNNNNEEEE
The descent lemma used by the author is not valid for the stochastic result.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Objectively saying that the author's method is better than CycleGAN is difficult. How does their ensemble method compare to just their single-agent dual method? Is there a noticeable difference there?	MET	NOOOOOONNNNNEEEE	"For image-to-image translation tasks, we further add two quantitative measures: (1) We use the Fréchet Inception Distance (FID) [6], which measures the distance between generated images and real images to evaluate the painting to photos translation.
.(2) We use ""FCN-score"" evaluation on the cityscape dataset following [7].
.Multi-agent dual learning framework can achieve better quantitative results than the baselines.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The standard CycleGAN model (baseline) already leverages both primal and dual mappings, which is equivalent to our “Dual-1” model in NMT experiments, i.e., the dual method with only one pair of agents f_0 and g_0.
.Our model involves two additional pairs of agents (f_1 and g_1, f_2 and g_2) during training.
.Unlike ensemble learning, only one agent (f_0 for forward direction, or g_0 for backward direction) is used during inference.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"** Image Translation Evaluation **
.The results are reported in Table 6 and Table 7 respectively.
.We are not sure what you meant by “How does their ensemble method compare to just their single-agent dual method?
.”
..
"	NOOOOOONNNNNEEEE
"I feel the approach to implicitly assume that the classifiers to be compared are already ""reasonably accurate""; since if not, both classifiers might be easily falsified by certain trivial examples, making the ""disagreed examples"" not as meaningful."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response: Thanks for the constructive suggestion. We agree with the reviewer and will make this assumption explicit in the revised manuscript.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. I feel the approach to implicitly assume that the classifiers to be compared are already ""reasonably accurate""; since if not, both classifiers might be easily falsified by certain trivial examples, making the ""disagreed examples"" not as meaningful. If that is true, I would suggest the authors to make this hidden assumption clearer in the paper
"	NOOOOOONNNNNEEEE
However, since the authors adopted an affinity-aware distance, two incorrect predictions can still be compared based on their semantic tree distances to the true class.	MET	NOOOOOONNNNNEEEE	"In our current subjective assessment environment, we choose to stop labeling images in Case III because it is difficult for humans to select one among 200 classes, especially when they are unfamiliar with the class ontology.
"	"We will revise the writing to make it more rigorous.
"	"We agree with the reviewer that images falling into Case III can be used to distinguish the associated two classifiers using the proposed semantic tree distance.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response: Thanks for pointing it out.
"	"3. One minor comment: for images in ""Case III"", the authors considered them ""contribute little to performance comparison between the two classifiers"" and therefore did not source labels for them.
.However, since the authors adopted an affinity-aware distance, two incorrect predictions can still be compared based on their semantic tree distances to the true class.
"	NOOOOOONNNNNEEEE
The advantage of INN, however, is not crystal clear to me versus other generative methods such as GAN and VAE.	MET	NOOOOOONNNNNEEEE	"It is indeed possible to adapt other network types to the task of predicting conditional posteriors.
.In the present paper, we focus on demonstrating that high-quality posteriors can actually be learned using bi-directional training as facilitated by INNs.
"	"We are currently setting up experiments for detailed analysis of the respective advantages and disadvantages and will report about these results in a future paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> ""The advantage of INN is not crystal clear to me versus other generative methods such as GAN and VAE.""
"	NOOOOOONNNNNEEEE
"-	In section 4, it is unclear why only the maximal activation of the softmax layer is used to characterize a sample? Why not considering the full distribution that should contain richer information? Why just focusing on the output layer and why not using the info available at intermediate layers?"	MET	NOOOOOONNNNNEEEE	"We agree that the full distribution of the softmax layer provides more information, but there is no straightforward way to extend the Kolmogorov-Smirnov distance to multi-dimensional distributions, beyond the two- and three-dimensional cases.
.We focus on confidence as a proxy to the loss, and we assume that the loss is the quantity that should be the most different between training and testing, as the optimization phase explicitly minimizes the loss on the training set.
.Moreover, early experiments showed that using the outputs of intermediate layers provide no improvement for membership inference (on preliminary CIFAR-10 experiments, we obtained respectively 67.7 accuracy with the output layer and 66.5 when using all layers).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“In section 4, it is unclear why only the maximal activation of the softmax layer is used to characterize a sample? Why not considering the full distribution that should contain richer information? Why just focusing on the output layer and why not using the info available at intermediate layers?”
"	NOOOOOONNNNNEEEE
This might be because the Bayes and MAT attacks are too simplistic.	MET	NOOOOOONNNNNEEEE	"We agree that better performance could be obtained by running the initial model for more epochs, but our goal is to stay close to the standard training of Imagenet models, i.e. 90 epochs with an initial learning rate of 0.1, divided by 10 every 30 epochs.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This might be because the Bayes and MAT attacks are too simplistic.
"	"We emphasize that the last line of Table 3 corresponds to the most difficult setup, where the network has been trained with a strong data-augmentation, and we only use the intermediate layers of the network (which amounts to less than 62% of the parameters for e.g. Resnet101), this is why the performance is significantly impacted.
.We experimented with more sophisticated models, and it did not bring any improvement (see shadow models in appendix E, e.g. the performance before the softmax layer is 58.2 for Resnet101 and 60.8 for our method).
"
Again, why not using the distribution of the outputs of all layers? Why focusing only on the output of the last layer?	MET	NOOOOOONNNNNEEEE	"We agree that better performance could be obtained by running the initial model for more epochs, but our goal is to stay close to the standard training of Imagenet models, i.e. 90 epochs with an initial learning rate of 0.1, divided by 10 every 30 epochs.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Again, why not using the distribution of the outputs of all layers? Why focusing only on the output of the last layer?”
"	"We emphasize that the last line of Table 3 corresponds to the most difficult setup, where the network has been trained with a strong data-augmentation, and we only use the intermediate layers of the network (which amounts to less than 62% of the parameters for e.g. Resnet101), this is why the performance is significantly impacted.
.We experimented with more sophisticated models, and it did not bring any improvement (see shadow models in appendix E, e.g. the performance before the softmax layer is 58.2 for Resnet101 and 60.8 for our method).
"
Therefore, it is an overclaim that the KL-divergence bound (2) provides an immediate justification for AGZ’s core learning algorithm.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We will revise accordingly. Instead of ``immediate justification``, we believe this work does provide a first-step, formal framework towards a better theoretical understanding.
.We will also revise the title, perhaps to ``applying AGZ`` so as to make the connection to MDP more clear in our paper.
"	"We also agree with the reviewer that some of our statements might be too strong.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We believe that a rigorous mathematical analysis is crucial to provide a solid foundation for understanding AGZ and similar algorithms.
.This requires developing (i) a precise mathematical model, (ii) a quantitative performance bound within the model.
.Our work takes an important step in this direction by modeling AGZ’s self-play and its supervised learning algorithm accurately.
.In particular, we use the turn-based game model to capture the self-play aspect.
.We develop a quantitative bound in terms of cross-entropy loss in supervised learning, which is the “metric” of choice in AGZ.
.While the cross-entropy loss seems intuitive, using it as a quantitative performance measure requires careful thought.
.For example, in Appendix F (page 19, 2nd paragraph), we discussed a scenario where this intuition is incorrect under a careless measure.
.That is, seemingly “obvious” algorithms can fail in the absence of a rigorous mathematical proof.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Furthermore, the robust MDP view of the AGZ in sequential decision-making problems is not so impressive either.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It isn’t clear why the particular proposals are necessary or to which of the proposed extensions the inflated OOD uncertainties can be attributed:	MET	NOOOOOONNNNNEEEE	"(1) If one uses the same matrix-variate normal distribution that we use for p(\theta | x) as approximate posterior p(\theta) of a BNN in conjunction with the ELBO objective, one arrives at a BNN proposed by Louizos and Welling (2016) [1], i.e. the Variational Matrix Gaussian (VMG).
.We found that VMG’s results (obtained from their original code https://github.com/AMLab-Amsterdam/SEVDL_MGP) are not as good as that for the CDN, as shown in Figure 8 in the appendix.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This is further discussed in the newly added section 6.4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
2. The  objective? The proposed objective,  Eq 5, trades off stochastically approximating the (conditional) marginal likelihood against not deviating too much from p(\theta) =  MN(0, I, I) in the KL sense.	MET	NOOOOOONNNNNEEEE	"We found that the CDN objective leads to superior results, especially in the adversarial examples experiment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have added a new section (Sec. 4) to discuss the differences between the objective used for CDN, when performing variational inference for BNNs, and in the variational information bottleneck (VIB) framework.
.Furthermore, we present an experimental investigation of these different objectives (Sec. 6.4).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
-  Instead of relying on the KL regularizer, a standard approach to learning the model in Eq 3 would be to use well understood MCMC or variational methods that explicitly retain uncertainty in \theta and induce predictive uncertainties.  Were they explored and found to be not effective?	MET	NOOOOOONNNNNEEEE	"We found that the CDN objective leads to superior results, especially in the adversarial examples experiment.
"	NOOOOOONNNNNEEEE	"(2) Thank you for this valuable suggestion!
"	NOOOOOONNNNNEEEE	"We have added a new section (Sec. 4) to discuss the differences between the objective used for CDN, when performing variational inference for BNNs, and in the variational information bottleneck (VIB) framework.
.Furthermore, we present an experimental investigation of these different objectives (Sec. 6.4).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
b) Down weighting the KL term by lambda for the VI techniques unfairly biases the comparison.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(b) We have revised the baselines so that they either use \lambda = 1 or the settings that the original authors recommended.
.We detail this in Appendix F.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, this can be tricky in practice since it requires having an estimate for Q_r(s,a) as a function of the state (in order to ensure that the state-dependent lower bound can indeed be satisfied).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Defining a state-dependent bound is indeed not trivial and requires knowledge of what is feasible in the system, and as such we leave this up to future work.
.In this paper we have made the approximation that the state distribution is stationary and the discount is large enough to assume that the value is more or less constant.
.While this holds for locomotion tasks, this does not apply in e.g. the swingup phase of the cartpole task and as a result the penalty is completely ignored during this phase.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4) State-dependent lower bound
"	NOOOOOONNNNNEEEE
Thus, the trained model will also only be able to handle one test domain, not much different than regular meta-learning models.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It appears that our choice of the title may have resulted in the reviewer qualifying our paper as a form of false advertising.
.We acknowledge this problem and agree with you about a possible misinterpretation.
"	NOOOOOONNNNNEEEE	"We have tried to revise the draft with appropriate renaming of the method to avoid potential misunderstandings.
.In fact, we have mostly changed the name from “Meta Domain Adaptation” to “Meta Learning with Domain Adaptation”, and the rest of the paper is almost identical, which we believe addresses the concerns of false advertising.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, we feel this maybe a bit harsh, as in the technical content of the paper (Abstract, Introduction, etc.), we have been very clear about the motivation and the problem setting, and do not think we did any form of false advertising.
.We also do think that the problem setting we have proposed is an important problem that deserves attention, and has not been studied in the meta-learning paradigm.
.We are glad that you also agree that setting makes sense (“... the combination … is fair”).
.Overall, we think that we have made an important contribution to Meta-Learning literature, by identifying its limitation for few-shot learning under domain shift, and proposed a solution to tackle this problem.
"	NOOOOOONNNNNEEEE	"Concern 1: Concerns with title “Meta Domain Adaptation”
.“…unlike as advertised, the paper does not address
.… “
"	NOOOOOONNNNNEEEE
In short, the meta-learning part stays in the regular few-shot learning module (which is implemented as a prototypical network), and has nothing related to domain adaptation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It appears that our choice of the title may have resulted in the reviewer qualifying our paper as a form of false advertising.
.We acknowledge this problem and agree with you about a possible misinterpretation.
"	NOOOOOONNNNNEEEE	"We have tried to revise the draft with appropriate renaming of the method to avoid potential misunderstandings.
.In fact, we have mostly changed the name from “Meta Domain Adaptation” to “Meta Learning with Domain Adaptation”, and the rest of the paper is almost identical, which we believe addresses the concerns of false advertising.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, we feel this maybe a bit harsh, as in the technical content of the paper (Abstract, Introduction, etc.), we have been very clear about the motivation and the problem setting, and do not think we did any form of false advertising.
.We also do think that the problem setting we have proposed is an important problem that deserves attention, and has not been studied in the meta-learning paradigm.
.We are glad that you also agree that setting makes sense (“... the combination … is fair”).
.Overall, we think that we have made an important contribution to Meta-Learning literature, by identifying its limitation for few-shot learning under domain shift, and proposed a solution to tackle this problem.
"	NOOOOOONNNNNEEEE	"Concern 1: Concerns with title “Meta Domain Adaptation”
.“…unlike as advertised, the paper does not address
.… “
"	NOOOOOONNNNNEEEE
Specifically, what if the few-shot learning component is removed, and the network is trained with standard domain adaptation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is not clear how MULANN can work in this situation and how its performance vary with the noisy signals conveyed in those false pseudolabeled samples.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- can you motivate why you are not using perplexity in section 3.2?	MET	NOOOOOONNNNNEEEE	"We use top-k accuracy, instead of perplexity, because approximating top-k is required for most inference tasks in practice (see [1]).
.Perplexity captures the normalized log-likelihood of all possible words, while top-k accuracy is a better measure for inference speedup for top-k retrieval.
.For example, in some extreme cases, if a word only has a very small probability which makes it unpredictable at all (i.e. couldn’t be retrieved by top-k for any reasonably small k)
., it could still have a huge impact in terms of perplexity, but has a much smaller impact on top-k accuracy, which seems more reasonable given the goal of top-k retrieval.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- Can you motivate why you are not using perplexity in section 3.2?
"	NOOOOOONNNNNEEEE
-The average distortion metric (that’s unfavourable to your method anyway) doesn’t really mean anything as the constraint optimization has no incentive to find a value smaller than the constraint.	MET	NOOOOOONNNNNEEEE	"4. Yes, we could just remove the distortion column in our result.
.We choose to include it because we do not want others to think that we actually trade a lot of distortions (to make problem easy) for speedup in runtime.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- I am not sure what the authors mean by “the Frank-Wolfe gap is affine invariant”. If we scale the input space by a, the gap should be scaled by a^2 - how/why is it invariant?	MET	NOOOOOONNNNNEEEE	"8. It means it is invariant to an affine transformation of the constraint set, i.e., if we choose to re-parameterize of the constraint with some linear or affine transformation M, the original and the new optimization problem will looks the same to the Frank-Wolfe algorithm.
.Please refer to [Jaggi (2013)], [Lacoste-Julien (2016)] for more details.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In remark 4.8 in the end option I and II are inverted by mistake	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"10. Thank you for pointing these typos out, we have addressed it in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In the proof you wrongfully use the term telescope sum twice, there is nothing telescopic about the sum it is just bound by the max value times the length.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"10. Thank you for pointing these typos out, we have addressed it in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Authors claim to identify a fundamental problem with the existing generative models for point clouds, yet Section 2 tries to show that a _specific version_ that uses DeepSet does not satisfy theoretical guarantees. What if we use e.g. a recurrent network instead?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The purpose of the counterexample is only to show that there exists some spurious solutions to GANs with general DeepSets-style discriminator for point clouds.
.We agree that setup we selected is destined to fail, but it was done on purpose to illustrate the presence of spurious solutions.
.A good generator and discriminator would definitely be a solution as well.
.However, solutions during optimization might not always correspond to such good solutions and can also correspond to the demonstrated spurious solutions.
.We found empirically that GAN with simple DeepSet-like discriminator most of the times fails to learn to generate point clouds even after converging, however, it does sometimes results in reasonable generations (although worse than proposed PC-GAN).
.So, we do not consider the argument to be unrealistic as we often observe the degeneracy.
.So the message here is that we need additional constraints for GANs with simple DeepSet-like discriminator to exclude such bad solutions and lead to a more stable training.
.Other architectures like RNN might work, but they are not permutation invariant, which is a desirable property for set data like point clouds.
.More comparisons between using RNN and DeepSets for other tasks on set data can refer to Zaheer et al., (2017).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"- I don't understand why the authors say that their space ""interpolates smoothly"" just because the limit in the curvature is the same from the left and right side."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Proofs that the space ""interpolates smoothly with curvature"": we added formal proofs (see theorems 2 and 3) that all the operations are differentiable, i.e. the gradients are equal from both the left and right at 0, w.r.t. curvature, for the chosen models of hyperbolic and spherical geometry.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- One thing that I didn't see discussed by the authors is that there are subtle difference between hyperbolic and spherical spaces.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"k-addition definiteness in the spherical setting: we have added the formal condition that the k-addition be well-defined, and a proof that for two points this condition indeed recovers x != y / (k ||y||^2) - see Theorem 1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Theorem 5 shows that our proposed left-matrix-multiplication is an intrinsic averaging for Riemannian manifolds of constant curvature, i.e. it does commute with isometries when the matrix A is right-stochastic, which is not the case of right-matrix-multiplication.
.This is a desirable property for Riemannian vector averaging.
.Theorem 6 shows that weighted combinations in the tangent space used in the very recent works of [1,2] (appeared after ICLR submission deadline) is also an intrinsic averaging for Riemannian manifolds of constant sectional curvature, i.e. it does commute with isometries.
"
For example, the weighted midpoint of Def. 3.2 doesn't immediately extend to spherical space (or at least won't be unique).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"k-addition definiteness in the spherical setting: we have added the formal condition that the k-addition be well-defined, and a proof that for two points this condition indeed recovers x != y / (k ||y||^2) - see Theorem 1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Theorem 5 shows that our proposed left-matrix-multiplication is an intrinsic averaging for Riemannian manifolds of constant curvature, i.e. it does commute with isometries when the matrix A is right-stochastic, which is not the case of right-matrix-multiplication.
.This is a desirable property for Riemannian vector averaging.
.Theorem 6 shows that weighted combinations in the tangent space used in the very recent works of [1,2] (appeared after ICLR submission deadline) is also an intrinsic averaging for Riemannian manifolds of constant sectional curvature, i.e. it does commute with isometries.
"
- For the synthetic tree, why is the number of edges 2(|V|-1) rather than |V|-1?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-Synthetic tree: contains |V| - 1 edges.
"	NOOOOOONNNNNEEEE	"We corrected this mistake.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, the implementation details are hazy, and some design choices (which operations, hyperparameters etc.) aren't well justified.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- What are the motivations to use Frank-Wolfe ? Usually this algorithm is used when the constraints are to complicated to have a tractable projection (which is not the case for the L_2 and L_\infty balls) or when one wants to have sparse iterates which do not seem to be the case here.	MET	NOOOOOONNNNNEEEE	"Yet it is also well-known that Frank-Wolfe has quite different optimization behavior compared with PGD even though they have the same order of convergence rate.
.Therefore, it is interesting and important to examine the performance of Frank-Wolfe algorithm for adversarial attack, given the fact that PGD has been shown to be a very effective for adversarial attack.
.In fact, from our work, we found that Frank-Wolfe based methods are generally more efficient than PGD method.
.From another perspective, Frank-Wolfe solves the problem by calling Linear Minimization Oracle (LMO) over the constraint set at each iteration.
.This LMO shares the same intuition as FGSM, which also tries to linearize the neural network loss function to find the adversarial examples.
.In this sense, it is a quite natural attempt to revisit FGSM under the Frank-Wolfe framework.
"	NOOOOOONNNNNEEEE	"1. You are right that Frank-Wolfe would be advantageous over PGD when the constraints are more complicated and adversarial attack may not be such a case.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In Theorem 4.7 an expectation on g(x_a) is missing	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"8. Thank you for pointing out several typos. We have fixed all of them in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Sec 3.3 the argmin is a set, then it is LMO $\in$ argmin.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"8. Thank you for pointing out several typos. We have fixed all of them in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- One drawback is that this method requires the mask during training. How can it be adapted for scenarios where the mask is not present? In other words, we only see multiple modalities as input, but we are not sure which are noisy and which are not?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree that it is very interesting to design a model with partially-observed or even unobserved mask.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, it is beyond the scope of this work and we will consider it in future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In our experiments, the binary mask is always fully-observed as is the nature of partially-observed data.
.A mask simply indicates which  modalities are observed and which are not.
"	NOOOOOONNNNNEEEE	"(4) Require mask during training:
"	NOOOOOONNNNNEEEE
"I am still a bit confused about the difference between ""zero-confidence attacks"" and those that don't fall into that category such as PGD."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The following link is a figure that explains the difference between zero-confidence attack and fix-perturbation attack.
.https://docs.google.com/viewer?url=https://raw.githubusercontent.com/anon181018/iclr2019_rebuttal/master/figure1.pdf
.As can be seen, the zero-confidence attack finds the closest point on the decision boundary; while fix perturbation-attack finds adversarial samples within a fix perturbation.
.Both attacks are equivalent if we only want to compute the attack success rate under a given perturbation level.
.However, we will be better off with zero-confidence attacks if we want to
.1) Compute the margin of each individual example; and
.2) Probe and study the decision boundary of a classifier
.Of course, we can also measure the margin of each example using a fix-perturbation attack, for example PGD, by binary searching over the perturbation levels.
.However, the computation cost will significantly increase.
.Consider, for example, the CIFAR-10 dataset.
.Since for our model, most margins fall within 10, so let’s assume the binary search range is 10 (for adversarially trained models this number will be much higher).
.If we want to achieve a accuracy of 0.1, then we need at least 7 binary search steps.
.In other words, the computation complexity increases by 7 times.
.In fact, CW applies a similar binary search idea to achieve zero-confidence attack, and that is why its computation cost is high.
.The above discussion is not saying that it is impossible to convert PGD to a zero-confidence attack efficiently, but it at least provides a perspective on why zero-confidence attack is challenging, and why the complexity reduction as well as accuracy improvement of MarginAttack is valuable.
"
Since all of these are approximations, and we cannot know how far we are from the true margin, I don't see why these categories help.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The following link is a figure that explains the difference between zero-confidence attack and fix-perturbation attack.
.https://docs.google.com/viewer?url=https://raw.githubusercontent.com/anon181018/iclr2019_rebuttal/master/figure1.pdf
.As can be seen, the zero-confidence attack finds the closest point on the decision boundary; while fix perturbation-attack finds adversarial samples within a fix perturbation.
.Both attacks are equivalent if we only want to compute the attack success rate under a given perturbation level.
.However, we will be better off with zero-confidence attacks if we want to
.1) Compute the margin of each individual example; and
.2) Probe and study the decision boundary of a classifier
.Of course, we can also measure the margin of each example using a fix-perturbation attack, for example PGD, by binary searching over the perturbation levels.
.However, the computation cost will significantly increase.
.Consider, for example, the CIFAR-10 dataset.
.Since for our model, most margins fall within 10, so let’s assume the binary search range is 10 (for adversarially trained models this number will be much higher).
.If we want to achieve a accuracy of 0.1, then we need at least 7 binary search steps.
.In other words, the computation complexity increases by 7 times.
.In fact, CW applies a similar binary search idea to achieve zero-confidence attack, and that is why its computation cost is high.
.The above discussion is not saying that it is impossible to convert PGD to a zero-confidence attack efficiently, but it at least provides a perspective on why zero-confidence attack is challenging, and why the complexity reduction as well as accuracy improvement of MarginAttack is valuable.
"
My main concern is that sampling the target values for the unobserved modalities from the prior would almost necessarily lead to blurry synthetic “ground truth” for these modalities, which in turn means that the model would produce underconfident predictions for them.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Furthermore, it is not obvious to me why these prior samples would be sensible at all, given that all modalities have independent latents by construction.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The crux of the proposed model is the selective proposal distribution.
"	"""Pseudo"" sampling for unobserved modalities during training provides a way to facilitate model training process.
.We evaluated the model under two training settings: (I) optimize the final ELBO without conditional log-likelihood for unobserved modalities x_u; and (II) optimize the final ELBO with  conditional log-likelihood of unobserved modalities.
.This is realized by utilizing the ""pseudo"" sampling described before (and in the paper).
.The results are comparable but the added term in setting II shows benefits on some datasets.
.While setting I is solely based on the observed modalities, the setting II incorporates the unobserved modalities along with the observed ones.
.By using the complete data, the setting II describes the complete ELBO corresponding to the partially observed multimodal data (in consideration).
"	NOOOOOONNNNNEEEE	"(1) Reconstruction from prior during training:
"	NOOOOOONNNNNEEEE
Without any comparisons it’s hard to tell how difficult the tasks under consideration are and what would amount to good performance on the held-out tasks.	MET	NOOOOOONNNNNEEEE	"One might take inspiration from our framework try to use MAML for zero-shot task performance by transforming task representations would require adopting our meta-mapping framework, as well as a number of ideas of our architecture (where do the task representations come from, and how are they used?), and so its not clear to us that this is an appropriate baseline, rather than simply another implementation of our technique.
.Instead, we feel the more appropriate baseline is performing tasks from a natural language description, as many prior zero-shot works have, and so we have moved this result to the main text, as noted above.
"	"However, if our paper is accepted, and you feel that the comparison to MAML for basic meta-learning is useful, we will run MAML on our tasks before the camera-ready submission.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Our main contribution is to propose a meta-mapping framework for zero-shot task performance, and parsimonious method for performing these meta-mappings.
.MAML as such is not a method of zero-shot task performance, it requires examples to learn
.from
..
.We could therefore compare to MAML for our basic-meta-learning results, but those are simply a sanity check.
.We also compare to a variety of baselines, including chance and optimal performance, untransformed representations, and the most correlated task experienced (in the cards domain).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> in Sections 4 and 5 I was hoping to see comparisons to methods like MAML.
.Also, I felt that the proposed approach in Section 5 is very similar to MAML intuitively.
.This makes a comparison with MAML even more desirable. Without any comparisons it’s hard to tell how difficult the tasks under consideration are and what would amount to good performance on the held-out tasks.
"	NOOOOOONNNNNEEEE
3. What are the limitations of the F-pooling? It is good to me that the authors discuss one limitation on the imaginary part of output and I would like to hear more on other potential limitations for this method.	MET	NOOOOOONNNNNEEEE	"3. The limitation of imaginary part is easy to overcome: set the resolution of F-pooling’s output to an odd number or padding it to an odd number when the resolution is an even number.
.In this way, the imaginary part is zero.
.Moreover, the word shift in this paper means circular shift.
.So it is better to use circular padding in convolutional layers.
.However, we find circular padding slower the training speed in PyTorch.
.If we use zero paddings as in most situations, the beneficial of F-pooling is reduced.
.Our current experiments use zero paddings.
.See our general response for what happens when we replace zero paddings with circular padding.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Besides some issues in the technical details, the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.
"	NOOOOOONNNNNEEEE
However, based on the definition of \theta and \tilde{\theta} given in the first sentence of section 2.3, the relation between \theta, \tilde{\theta} and D	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We updated section 2.3 to reflect this more clearly.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, based on the definition of \theta and \tilde{\theta} given in the first sentence of section 2.3, the relation between \theta, \tilde{\theta} and D should be: D <- \theta -> \tilde{\theta} (if it is a generative model) or D -> \theta -> \tilde{\theta} (if a discriminative model).
"	"Response: We are interested in limiting the mutual information I(\theta, D) between our learned parameters \theta and the dataset D.
.However, this is hard to calculate for typical deep models.
.Therefore we introduce a model that forms a Markov chain \theta -> \tilde{\theta} -> D, as shown in Figure 1a.
.Hereby, \tilde{\theta} is a noisy version of the parameters \theta.
.Crucially, the data D is defined to be dependent only on the noise-corrupted version \tilde{\theta}. By choosing a convenient noise process and prior for \theta we can easily control I(\tilde{\theta}, \theta).
.This gives us an upper bound on the mutual information I(D, \theta) between data and parameters, according to the DPI.
"
Either case, I don't think we can have the inequality in eq. (5).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The usefulness of the approach is also lessened by the greater importance of the choice of the optimizer.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"First, we’d like to emphasize that the clique problem studied in the paper is far from being a toy problem.
.All the algorithms are evaluated on the DIMACS clique dataset which was published as part of the second DIMACS challenge which specifically focused on combinatorial optimization.
.Over the years, this dataset has become a standard benchmark for clique finding algorithms, and results on it are regularly published.
.In this respect, this dataset is an important benchmark for clique algorithms very much like CIFAR10 and CIFAR100 are for image classification methods.
.Notably, Cakewalk approaches the performance of the best clique finding algorithms that directly search a graph, and which are tailored to this specific task.
.Note that none of the tested methods were given enough samples even to recover the graph itself, as most graphs have more than 100 nodes, and we’ve allowed only for 100 |V| samples in each execution.
.Next, we wonder how would the reviewer correct the confounds mentioned with regard to the clique experiment.
.Providing a controlled experiment is always challenging, though the elements mentioned by the reviewer were specifically selected as to reduce various confounds.
.The main research question we try to address is whether algorithms that only rely on function evaluations can recover locally optimal solutions.
.Since the objective is the only source of information for such algorithms, an all-or-none kind of objective would not be very useful.
.Instead, the objective is designed in a manner that provides information even for partial solutions, thus allowing the tested algorithms to gradually improve the objective.
.In terms of the sampling distribution, as our focus is on the update step, we decided to use the simplest possible sampling distribution we can think of.
.In such a regime, we can attribute any performance gains to the algorithms themselves, and not to any prior knowledge that is reflected by the structure of some complex sampling distribution.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In order to pre-train the discriminator network, additional (s,a,s') experiences are required, thus it seems difficult to say that it is better for exploration than VIME.	MET	NOOOOOONNNNNEEEE	"- The discriminator uses the same amount of (s,a,s') experience as VIME consumes because the discriminator is fixed after pre-training.
.VIME can only be trained along with the policy.
.VIME cannot be pre-trained, otherwise, it won’t detect novel states.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. I had hard time to understand latent canonicalization.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Do you mean that each latent variable is fixed to a value, such that this factor of variation is disabled? Are the canonicalizers pre-specified using meta-labels? Are they updated/learned during model training?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
More explanation of canonicalization is needed.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
2. The learning of the proposed model relies on meta-data description such that the learning is supervised. Can the method be applicable to situations where no meta-data and no class labels are available?	MET	NOOOOOONNNNNEEEE	"A: as we discuss in the general comments, the method is best suited for problems of interest where a synthetic simulator is available.
.In those cases full access to factors of variation is available as this is used to generate the data.
., The question we focus on is how to best utilize the knowledge of factors of variation to improve the transferability of the learned representation to real data with limited labels.
.We are not focusing on a setting where the source domain has no labels.
.That said, our method does not assume access to all factors for all samples (in fact we only use two factors per sample).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: The learning of the proposed model relies on meta-data description such that the learning is supervised. Can the method be applicable to situations where no meta-data and no class labels are available?
"	NOOOOOONNNNNEEEE
3. How can the proposed method be generalized to non-image data?	MET	NOOOOOONNNNNEEEE	"A: Our method is not specific to the image domain and there is no reason it could not be applied to other input types.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In order to use our method, we only require a corpus of data with partially (at least two) labeled factors of variation and a corpus of data which is sparsely labeled for a downstream task.
.Critically, these two sources of data need not be identical!
.This means that an easy way to acquire a corpus with labeled factors of variation is to use a simulator to generate this data,  as we do in this study.
"	NOOOOOONNNNNEEEE	"Q: How can the proposed method be generalized to non-image data?
"	NOOOOOONNNNNEEEE
However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification.	MET	NOOOOOONNNNNEEEE	"We study seq2seq classification tasks since they have been widely used in real world applications for RNNs.
.To name a few, in speech recognition, [1] hybridizes hidden Markov model with RNNs to label unsegmented sequence data; In computer vision, [2, 3] demonstrate scene labeling with LSTM and RNNs, achieving higher accuracy than baseline methods; In healthcare, [4] proposes a model, Doctor AI, to perform multiple label prediction (one for each disease or medication category).
.In addition, [5, 6] both apply RNNs to real-world healthcare datasets (MIMIC-III, PhysioNet, and ICU data) for mortality prediction and other multiple classifications tasks.
.We establish bounds for classification because it is typical in learning theory and is easy to compare among existing literature.
.On the other hand, our analysis applies in other tasks as long as a suitable Lipschitz loss function is chosen.
.Specifically, Lemma 4 establishes an upper bound for empirical Rademacher complexity of general Lipschitz loss functions (the last line in Appendix A.4).
.By replacing the loss function in Lemma 1, we can derive generalization bounds for various tasks other than classification.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification.
"	NOOOOOONNNNNEEEE
2. The distribution proposed in section 3.2 assumes independence between the elements $x_j$. This seems problematic for some relatively simple problems.	MET	NOOOOOONNNNNEEEE	"Intuitively, if some node i is part of a large clique, then sampling x_i=1 is likely to result in a good objective as there are many nodes that are connected to i, and the chance of not sampling any of them decreases with the clique size.
.In this way, over time the probability for sampling such nodes becomes higher, and the chance of sampling all of them together increases.
.A similar reasoning applies for the k-medoids problem.
.We note that these kind of factorized distributions have a long history of being useful in machine learning.
.In a similar context to the one studied in the paper, such distributions have been studied by Rubinstein in his paper which discusses CE as an algorithm for combinatorial optimization, and in the classical bandit papers Exp3 is applied independently to several dimensions to study game theoretic problems.
.In different contexts, such distributions have also been used as naive mean field approximations in variational inference.
"	NOOOOOONNNNNEEEE	"As the author correctly states, such a distribution will not always be useful, and one can design a problem for which this distribution will lead to a poor local optimum.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Note however that a global maximizer for the objective suggested by the reviewer can be easily found just by random sampling: sampling such a maximizer has the same probably as sampling an odd integer - half.
.Nonetheless, for the clique problem such a distribution can be effective.
"	NOOOOOONNNNNEEEE	"Second, we address the issue of using a sampling distribution that assumes independence between the different dimensions.
"	NOOOOOONNNNNEEEE
Is there any explanation for this?	MET	NOOOOOONNNNNEEEE	"One intuitive explanation for why an algorithm that maintains a ‘memory’ of previous gradient updates like AdaGrad or Adam is required
.is that they protect against sampling biases.
.Consider for example the case when the execution is at the start, and the sampling distribution still has maximum entropy.
.Due to the combinatorial nature of the solution space, the examples that have been sampled thus far create a distorted representation of the solution space.
.In this case we could get that some x_i=j will occur few times, while some other x_k will not receive the value j at all.
.Now if we apply vanilla gradient updates this can skew the sampling distribution in random directions.
.Gradient updates such as those of AdaGrad and Adam on the other hand will lessen the impact of such deviations as the importance of each case is inversely proportional to the number of previous observations.
.As such deviations will inevitably occur whenever we rely on polynomially sized samples to represent a combinatorial solution space, without such corrections a gradient based adaptive sampling algorithm will almost surely fail.
.Furthermore, this reasoning explains why AdaGrad is superior to Adam: AdaGrad corrects against sampling biases that entail all the examples that have been encountered, while Adam does this only within some exponentially moving time window.
.Indeed, this phenomenon is studied in detail in the AdaGrad paper (though without assuming a data distribution), and sparse data like ours (one can say our data points are N indicator vectors of length M) is the first motivating example in their paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Next, we address the question regarding the gradient update types.
.Indeed, as can be seen in tables 1,2 and 4, SGA almost never leads to a locally optimal solution.
"	NOOOOOONNNNNEEEE
It seems like a large assumption that the same learning rate would work for different methods, especially when some of them are normalizing the objective function.	MET	NOOOOOONNNNNEEEE	"Except for the learning rate, all the hyper-parameters were chosen according to the values suggested by the authors of AdaGrad, and Adam.
.The learning rate was chosen as 1/K, with K=100 being the number of examples used to estimate the CDF.
.As our stated goal is to present an algorithm which can be blindly applied with some fixed set of hyper-parameters to any possible objective, one of the goals of the experiments is to show that in such a setting some methods will work, while others will fail.
.Thus, as a controlled experiment for this hypothesis, we first fixed the set of all hyper-parameters for all methods, and then proceeded to apply them to various problems.
.In this setting therefore, tuning the learning rate or any other hyper-parameter for that matter will compromise the validity of our results.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The comparison of different observation representations doesn’t include any analytical component, the empirical component is primarily inconclusive, and the position statements are fairly non-controversial (and not really conclusively supported).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- doesn’t answer the one question regarding observation representation that it set out to evaluate	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- presumably, the sample complexity is ridiculous	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Dealing with highly stochastic environments seems a potential fatal flaw of the assumptions of this method.	MET	NOOOOOONNNNNEEEE	"Our vivid demonstration of this issue in the maze environment has already inspired some recent papers to look into, in particular, by incentivizing episodic reachability (in the interest of preserving anonymity, we don't include references to these, but we will include them in the final version of the paper).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"=> We agree that significant amounts of stochasticity would break the method we used in the paper, and it is an important issue to be addressed by future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R2: ""Dealing with highly stochastic environments seems a potential fatal flaw of the assumptions of this method. However, as I said previously, this is probably a discussion worth having given the popularity and visibility of game-based testbeds""
"	NOOOOOONNNNNEEEE
To start with, the set of rotations R(phi, nu, 0) called the alt-az group in this paper is not a group in the mathematical sense.	MET	NOOOOOONNNNNEEEE	"Q1: “Alt-az” rotation is not a group.
.The Alt-az rotation, according to our definition, is not a group.
.SO(3)  is a group which can be parametrized by a 3-sphere .
.But when we reduce one parameter from it, it is not a group anymore mathematically; the composition of two alt-az rotations becomes a general rotation in SO(3).
"	NOOOOOONNNNNEEEE	"A1: Thank you for pointing this out.
.You are correct.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the new revision, we will use the term alt-az rotation in “quotient SO(3)/SO(2)”  instead of alt-az rotation group.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Moreover, the quotient SO(3)/SO(2) is isomorphic to $S^2$ and to avoid the ill-definition on the two poles (the two degenerate points), we will add a constraint to the alt-az rotation, i.e. $\phi=0, if \theta=0 or \theta=\pi$. This is because, when the altitude rotation is zero or PI, the azimuth rotation is meaningless in a alt-az rotation and is therefore fixed as zero.
.If $\theta=0 or \theta=pi, and “\phi \neq 0$, this rotation belongs to the azimuthal rotation in SO(2) group.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This easy to see, because a composition of rotations of the form Rz(phi) Ry(nu) is not generally of that form.	MET	NOOOOOONNNNNEEEE	"Q1: “Alt-az” rotation is not a group.
.The Alt-az rotation, according to our definition, is not a group.
.SO(3)  is a group which can be parametrized by a 3-sphere .
.But when we reduce one parameter from it, it is not a group anymore mathematically; the composition of two alt-az rotations becomes a general rotation in SO(3).
"	NOOOOOONNNNNEEEE	"A1: Thank you for pointing this out.
.You are correct.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the new revision, we will use the term alt-az rotation in “quotient SO(3)/SO(2)”  instead of alt-az rotation group.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Moreover, the quotient SO(3)/SO(2) is isomorphic to $S^2$ and to avoid the ill-definition on the two poles (the two degenerate points), we will add a constraint to the alt-az rotation, i.e. $\phi=0, if \theta=0 or \theta=\pi$. This is because, when the altitude rotation is zero or PI, the azimuth rotation is meaningless in a alt-az rotation and is therefore fixed as zero.
.If $\theta=0 or \theta=pi, and “\phi \neq 0$, this rotation belongs to the azimuthal rotation in SO(2) group.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This would mean that the layer is actually SO(3)-equivariant, but it has been proven [1], that any rotation equivariant layer between scalar spherical feature maps can be expressed as an azimuthally isotropic convolution.	MET	NOOOOOONNNNNEEEE	"(Q2) Equivariance property of the Alt-az convolution
.Q3: alt-az convolution is not well defined on the south pole
"	NOOOOOONNNNNEEEE	"A3: Yes, we agree that our original definition of alt-az convolution is not well defined on both north and south poles.
"	"Here is our tentative proof:
.Under the definition of alt-azimuth anisotropic convolution and using the unitary property (5) of rotation operators, we have (assume the number of channels K=1 for simplicity, assume Q and R be both alt-az rotations):
.\begin{equation}
.\begin{aligned}
.& (h \star D_{Q} f) (R)
.\\
.&
.= \int_{S^2}(D_Rh)(\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}Q\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h((Q^{-1}R)^{-1}\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=(h \star f)(Q^{-1}R) = D_{Q}( h \star f)(R)
.\end{aligned}
.\end{equation}
"	"Therefore, in the new revision, we will add the constraints to the definition of alt-az rotation and make it one-to-one corresponds to the set points on $S^2$. See A1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We think we can still have the equivariance property but only for single alt-az rotation.
.Notice the definition of alt-az convolution do not use any composite rotation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This means that for a single alt-az rotation of input spherical image; the output of a convolution layer will rotate in the same way.
.Although the property doesn’t hold if one performs multiple alt-az rotations to the input spherical image, it is still valuable because we assume the different SO(3) orientation of an input 3D shape is from a composite of an azimuthal rotation and an alt-az rotation, the azimuthal rotation is treated by data augmentation and the single alt-az rotation is treated by the network equivariance and invariance.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Since the alt-az convolution is not isotropic and maps between scalars on S2, it cannot be equivariant.	MET	NOOOOOONNNNNEEEE	"(Q2) Equivariance property of the Alt-az convolution
.Q3: alt-az convolution is not well defined on the south pole
"	NOOOOOONNNNNEEEE	"A3: Yes, we agree that our original definition of alt-az convolution is not well defined on both north and south poles.
"	"Here is our tentative proof:
.Under the definition of alt-azimuth anisotropic convolution and using the unitary property (5) of rotation operators, we have (assume the number of channels K=1 for simplicity, assume Q and R be both alt-az rotations):
.\begin{equation}
.\begin{aligned}
.& (h \star D_{Q} f) (R)
.\\
.&
.= \int_{S^2}(D_Rh)(\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}\hat{u})f(Q^{-1}\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h(R^{-1}Q\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=\int_{S^2}h((Q^{-1}R)^{-1}\hat{u})f(\hat{u})ds(\hat{u}) \\
.&
.=(h \star f)(Q^{-1}R) = D_{Q}( h \star f)(R)
.\end{aligned}
.\end{equation}
"	"Therefore, in the new revision, we will add the constraints to the definition of alt-az rotation and make it one-to-one corresponds to the set points on $S^2$. See A1.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We think we can still have the equivariance property but only for single alt-az rotation.
.Notice the definition of alt-az convolution do not use any composite rotation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This means that for a single alt-az rotation of input spherical image; the output of a convolution layer will rotate in the same way.
.Although the property doesn’t hold if one performs multiple alt-az rotations to the input spherical image, it is still valuable because we assume the different SO(3) orientation of an input 3D shape is from a composite of an azimuthal rotation and an alt-az rotation, the azimuthal rotation is treated by data augmentation and the single alt-az rotation is treated by the network equivariance and invariance.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
But it is easy to see that eq. 10 will give different results for each of these coordinates, because they correspond to different rotations of the filter about the Z-axis.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
In particular, I believe that any algorithms you compare against, you should optimize both G and theta, since optimizing purely the hardware is unfair.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"By “optimizing both G and theta”, we meant to indicate that the learned controllers can be transferred to the next generation even if the topologies are changed (instead of throwing away old controllers).
.We note that only NGE among all the baselines has the ability to do that.
.Graph neural network formulation is KEY here, enabling it to perform this efficient policy transfer.
.To the best of our knowledge, the traditional methods require re-optimizing theta from scratch for each different topology, which is computationally demanding and breaks the joint-optimization.
.NGE approximately doubles the performance of previous approach (Sims, 1994) as shown in Q1.
"	NOOOOOONNNNNEEEE	"Q2: a) Optimizing both the controller and the hardware has been previously studied in the literature.
.Is it worth using a neural graph?
.b) All algorithms should optimize both G and theta for a fair comparison.
.Please refer to Section 3.1 and Section 3.4 for more details.
"	NOOOOOONNNNNEEEE
This statement is ambiguous and potentially unsupported by evidence. how do you define complex? that can or that did discover?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
#5 is weak, and tell us more about the limitations of random search and naive ES than necessarily a merit of your approach.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"- Sec 2.2: ""(GNNs) are very effective"" effective at what? what is the metric that you consider?"	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"- Sec 3 ""(PS), where weights are reused"" can you already go into more details or refer to later sections?"	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Sec 3.1: the statements about MB and MF algorithms are inaccurate.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Sec 4.1:	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- A.4 makes it sound like eps_t needs to be assumed to be bounded, when all that is required is the bound on eps_0.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"On reviewer’s comments, we have updated A.4., and moved the note about eps_t = O^*(1/log(n)) to the Appendix A.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. On eps_t and A.4. —  Indeed, we don’t need to assume that eps_t is bounded.
.Specifically, using the result of Lemma 7, we have that eps_0 undergoes a contraction at every step, therefore, eps_t <= eps_0.
.For our analysis we fix eps_t = O^*(1/log(n)), which follows from the assumption on eps_0= O^*(1/log(n)) and Lemma 7.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, when there is no defense deployed in the training process, it is not intuitive to see why the proposed attack is more effective and persistent than the centralized attack, given that a smaller trigger usually results in a worse attack performance.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. The classification of base class into super classes seems questionable to me.	MET	NOOOOOONNNNNEEEE	"R1A1(a): Our model has two major components, $C^{sup}$ (for super-class prediction) and $C^{GAT}$ (for graph label prediction).
.During the training phase of our classification, $C^{sup}$, which is a MLP layer, learns the super-class labels of the samples based on GIN’s extracted feature vectors (which represent base class labeled graphs).
.While, $C^{GAT}$ takes as input the “graph of graphs” (supergraph) which models the latent inter-class as well as intra-class information and is constructed in every training batch, along with base-class labels, to learn the associated class distribution.
.Then, during the fine-tuning phase on graphs with novel class labels, the feature extractor’s (GIN) parameters are fixed and $C^{sup}$ is used to infer the super-class label of the novel class labeled graphs.
.Then, the parameters learned by $C^{GAT}$ get updated and further “fine-tuned” for better performance on the novel samples.
.The meta-learning framework, where batches are sampled as “episodes” with N-way K-shot setting, does not perform as well in our few-shot setting on graphs for the following reasons:
.1) We have very limited total number of training classes (in order of 10s), when compared to the image domain (order of 100s and 1000s).
.This limitation hampers learning across tasks and generalization to new unseen tasks.
.2) In each of our batches, we randomly sample a fixed-size of training samples belonging to the set of N labels chosen.
.Therefore, when building our supergraph, we end up with k-NN graphs of “variable size” per super-class, compared to fixed size (K nodes) k-NN graphs that we would have got using episodic learning.
.We suspect this further allows our GAT to learn and generalize better to unseen graphs.
.Furthermore, in [1], the authors use a similar strategy in their “baseline++” method and produce good results.
.Their findings are also in sync with our empirical finding.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R1Q1(a): “The classification of base class into super classes seems questionable to me.
.In the meta-learning language, the author attempts to learn a good representation of graphs
.based on different graph classification tasks generated by a task distribution
..
.In terms of graph classification, the task distribution is supported on the joint distributions (G, Y).”
"	"In addition to our brief overview, you could also find a very neatly detailed summarization of our method in reviewer 2’s comments (paragraphs 1-4).
"
Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R1A1(b): In every batch of graphs during both training and fine-tuning phase, each graph is associated with its corresponding graph label.
.In case of training, its a base-class and in the case of fine-tuning its a novel class
..
.In the case of $C^{GAT}$, the graph is accompanied by a regular class label and in case of $C^{sup}$, the graph is accompanied by a superclass label.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R1Q1(b): Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.”
"	NOOOOOONNNNNEEEE
- I don't see a discussion about the downsides of the method (for example, the large number of triplet comparison examples needed for training; and possible methods to overcome this problem).	MET	NOOOOOONNNNNEEEE	"One of the drawbacks is that our method needs GPUs, while the more traditional algorithms run on CPUs.
.This can be of disadvantage if non-machine learning experts want to use our method.
.However, this is the case for most recent ML methods based on neural nets.
.The number of required triplets is theoretically lower bounded by nd log n, and this is also being confirmed by our experiments (our algorithm, as well as our competitors, break down when they get fewer triplets).
.Therefore, in a setting with passive triplet answers, and without extra information, it is impossible to overcome this problem.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- ""I don't see a discussion about the downsides of the method""
"	NOOOOOONNNNNEEEE
The reparameterization trick does not apply to all continuous random variables, only to such that the reparameterization satisfies certain smoothness conditions.	MET	NOOOOOONNNNNEEEE	"We believe that procedure could be useful for the inference of models like the multi-layer sigmoid belief networks.
.As for the conditional independency, it is actually removed after marginalizing out additional continuous RVs (which could be non-reparameterizable RVs like Gamma).
.Also note that one can strengthen the aforementioned procedure by inserting more additional continuous internal RVs into the inference model to enlarge its (marginal) description power.
"	NOOOOOONNNNNEEEE	"Thanks a lot for pointing out the smoothness conditions for reparameterization; we have carefully revised our paper to remove the misleading statements and to make it clearer when our method (and also the reparameterization trick, Rep) is applicable.
"	NOOOOOONNNNNEEEE	"However, as stated in the last paragraph of Sec. 7.2, we presented in Appendix B.4 a procedure to assist our methods in handling discrete internal RVs.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"For your comments wrt discrete random variables (RVs), unfortunately, we haven’t found a principled way to back-propagate gradient through discrete internal RVs (like in multi-layer sigmoid belief networks).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Discrete variables are supported by the method only in the case that the distribution factors over all discrete variables conditionally on any additional “continuous variables” (to which the reparameterization trick is applicable).	MET	NOOOOOONNNNNEEEE	"We believe that procedure could be useful for the inference of models like the multi-layer sigmoid belief networks.
.As for the conditional independency, it is actually removed after marginalizing out additional continuous RVs (which could be non-reparameterizable RVs like Gamma).
.Also note that one can strengthen the aforementioned procedure by inserting more additional continuous internal RVs into the inference model to enlarge its (marginal) description power.
"	NOOOOOONNNNNEEEE	"Thanks a lot for pointing out the smoothness conditions for reparameterization; we have carefully revised our paper to remove the misleading statements and to make it clearer when our method (and also the reparameterization trick, Rep) is applicable.
"	NOOOOOONNNNNEEEE	"However, as stated in the last paragraph of Sec. 7.2, we presented in Appendix B.4 a procedure to assist our methods in handling discrete internal RVs.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"For your comments wrt discrete random variables (RVs), unfortunately, we haven’t found a principled way to back-propagate gradient through discrete internal RVs (like in multi-layer sigmoid belief networks).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
A Bernoulli(p) random variable is discrete, yet it is reparametrizable as [Z>p] with Z following standard logistic distribution, whose density and cdf is smooth.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The notation of the true distribution as “q” the model as p and the approximate posterior of the model as “q” again is inconsistent.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The notations are chosen for harmony and also to keep consistency with the main literature.
.For example, one can add another expectation wrt the true data distribution q(x) to the ELBO in Eq. (1), that is, E_{q(x)} [ELBO] = E_{q(x) q(z|x)} [log p(x,z) – log q(z|x)]  \propto  - KL[q(x)q(z|x) || p(x,z)].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Equations (5) and (6) require a theorem of differentiating under integral (expectation), such as Leibnitz rule, which in case of (6) requires q_gamma(y)f(y) to be continuous in y and q_gamma(y) continuously differentiable in gamma.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Some assumptions are not explicitly stated.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In light of the reviews, in the revised version, we have expanded the appendix to give more details on the experimental protocol.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We did provide some details on the first version (in the appendix).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Concern 2: Size of unlabelled test set, data-split information
"	NOOOOOONNNNNEEEE
"- The overall method seems to be not very principled, and requires a lot of ""tweaks and tunes"", with additional losses and regularizers, to work."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Also, the definition of mutual information used in this paper uses the inferred distribution q (e.g., in eq. 2), which is somewhat unusual.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We want to emphasize that we do use the standard definition of mutual information.
.Therefore, the bottleneck implied by Eq. 5 is purely a property of the generative model and not influenced by the approximate inference distribution q.
.Eq. 2 is only introduced to provide additional motivation for our approach as it allows to characterize overfitting in variational inference.
.The guarantee derived in section 2.2 ties this quantity back to the mutual information from Eq. 5.
"	NOOOOOONNNNNEEEE	"Also, the definition of mutual information used in this paper uses the inferred distribution q (e.g., in eq. 2), which is somewhat unusual.
"	NOOOOOONNNNNEEEE
Authors should analyze the stability of their method in details.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3. The 20:1 mixture used in practice do not directly correspond to s in theory, because the distances we compute are not scaled.
.For example, if the f_\phi, the discriminator of GAN, is k-Lipschitz, the lower bound estimate should be divided by k.
.However, k is unknown in practice.
.Therefore, we just numerically did a coarse grid search and find the best mixture ratio.
"	NOOOOOONNNNNEEEE	"Also, we try different ratios as we replied to R2 above.
"	"Ratio                   D2F (Distance to Face)
.1:0
.6.03E+00                        3.36E-01
.40:1
.6.06E+00                       3.41E-01
.20:1
.5.77E+00                       3.47E-01
.10:1
.6.85E+00                       3.56E-01
.0 :1
.9.19E+00                       3.67E-01
"
1. The observation that gradients explode in spite of BN is quite counter-intuitive. Can you give an intuitive explanation of why this occurs?	MET	NOOOOOONNNNNEEEE	"1) The intuition for batchnorm can be put in a more general setting.
.If a function f: X -> Y tends to spread out small clusters in the input space almost evenly in the output space, then one can expect that its gradients will be large typically.
.In our case, a batchnorm network can be understood as a function that sends a batch of inputs to a batch of outputs.
.In the appendix, we showed that the correlation between two different batches tend to a constant value independent of the input batches.
.No matter how close two input batches are, the output batches will have the same “distance” from each other -- small movements in the input space leads to large movements in the output space.
.Thus we can expect the gradients to be large as well.
.We have added a new figure to the Appendix to further support this intuition.
.In it, we pass through a linear batchnorm network 2 minibatches.
.Both minibatches contain points on the same circle and 1 point off the circle that is unique to each minibatch.
.While the circle in each minibatch will remain an ellipse as they are propagated through the network, the angle between the planes spanned by them increasingly becomes chaotic with depth.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I think having this in mind, showing the convergence of Theorems 3.2-3.4 is somehow trivial.	MET	NOOOOOONNNNNEEEE	"The novel perspective in this paper is that we consider the PL condition on a different objective, namely the squared gradient norm, rather than on the game objective $g$. This perspective allows us to prove our new bounds, although we still require some nontrivial linear algebra.
.The PL condition also allows us to easily prove our stochastic HGD results.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
5) In Theorem 5.2, the term 1/sqrt(2) is missing from the final bound.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"5) The 1/sqrt(2) should cancel out on both sides of the guarantee in Theorem 5.2 (and eg. in equation 68).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"The use of “blank inputs (referred to as “thinking steps”)” in “Simple LSTM” and “Attentional LSTM"" doesn’t seem to be a standard approach."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We’ve updated the paper to mention this.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"On running the decoding LSTM for a few steps before outputting the answer: we found that it was one of the few (relatively simple) architectural changes to the standard recurrent encoder/decoder setup that significantly helped performance (thus the performance on the standard architecture can be taken to be slightly worse than the numbers reported in the paper for the architecture with “thinking steps”), but we also realize that it is not a widespread architectural change. (Possibly the need for this is less in standard machine translation tasks.) Since your review, we have also ran experiments using the published architecture introduced in “Adaptive Computation Time for Recurrent Neural Networks” (Graves).
.This architecture has an adaptive number of “thinking” steps at every timestep dependent on the input, learnt via gradient descent.
.More specifically we investigated the use of this for both the recurrent encoder and decoder (replacing the single fixed number of “thinking” steps at the start of the decoder).
.After some tuning, its test performance was still around 3% worse than the same architecture without adaptive computation time.
"	"We hope that you will agree that, with your kind feedback, the changes above strengthen the paper's claims and clarity, and that you are willing to reconsider your assessment on these grounds.
"	"Please refer to the updated PDF of the paper to see these changes.
"	NOOOOOONNNNNEEEE
"In the attentional LSTM, the use of “parse LSTM” is also not a standard approach in seq2seq models and doesn’t seem to work well in the experiment (similar result to “Simple LSTM"")."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We’ve updated the paper to mention this.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"On running the decoding LSTM for a few steps before outputting the answer: we found that it was one of the few (relatively simple) architectural changes to the standard recurrent encoder/decoder setup that significantly helped performance (thus the performance on the standard architecture can be taken to be slightly worse than the numbers reported in the paper for the architecture with “thinking steps”), but we also realize that it is not a widespread architectural change. (Possibly the need for this is less in standard machine translation tasks.) Since your review, we have also ran experiments using the published architecture introduced in “Adaptive Computation Time for Recurrent Neural Networks” (Graves).
.This architecture has an adaptive number of “thinking” steps at every timestep dependent on the input, learnt via gradient descent.
.More specifically we investigated the use of this for both the recurrent encoder and decoder (replacing the single fixed number of “thinking” steps at the start of the decoder).
.After some tuning, its test performance was still around 3% worse than the same architecture without adaptive computation time.
"	"We hope that you will agree that, with your kind feedback, the changes above strengthen the paper's claims and clarity, and that you are willing to reconsider your assessment on these grounds.
"	"Please refer to the updated PDF of the paper to see these changes.
"	NOOOOOONNNNNEEEE
Roughly, the theorem states that if for example we fix any matrix B of size e.g. 256 x k and matrix U of size 512 x 256 and then compute U relu(B C) where C is the vector of parameters of size k x 1, AND if k < 2.5 (i.e. if we use at most 2 parameters), then it would be very hard to fit 512 iid gaussian values (i.e. min_C ||U relu(B C) - eta|| where eta ~ N(0, 1)).	MET	NOOOOOONNNNNEEEE	"Regarding the assumptions: The proposition uses the assumption that k^2 log(n_0)  / n <= 1/32.
.Here, the constant 1/32 is not optimal.
.k^2 is essentially the number of parameters of the model, and n is the output dimension.
.The proposition is only interesting if k^2 log(n_0)  / n <= 1/20 even without this assumption (due to the right hand side of the lower bound) therefore this assumption is not restrictive.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
From my experience, aligning embedding spaces is something that usually does not work very well, especially in high dimension.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The role of \sigma seems very redundant given \omega.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
How is this a reasonable assumption?	MET	NOOOOOONNNNNEEEE	"Note that we assume strong convexity of the loss as a function of the output units, not as a function of the weights.
.Hence, our assumption is fairly realistic in the neural net setting.
.The loss function on top of the network output is usually defined as a simple convex function; for instance, in regression, a common choice of loss function is the quadratic loss (i.e, the squared distance between the network output and the true label), which is strongly convex.
.In fact, even without assuming that the loss function is strongly convex and that the output manifold is dense, we are still able to show a fast convergence rate.
.In the updated version of the paper, we show that our algorithm with an oracle converges to stationary point globally with a fast rate, which provides insight into why APO works well.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: The convergence results appear to rely on strong convexity of the loss.
.How is this a reasonable assumption?
"	NOOOOOONNNNNEEEE
Considering the optimization problem involved in the learning process, it is hard to judge whether the effect of such a procedure from the optimization perspective.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">>> As mentioned in the main response, the proposed TPN is not a mere combination of CNN representation learning and label propagation.
.The original label propagation constructs a fixed graph (Eq (1)) to explore the correlation between examples.
.While in our work, we adaptively construct the graph structure for each episode (training task) with a learnable graph construction module (Figure 4, Appendix A).
.This leads to better generalization ability for test tasks.
.In Table 1 and Table 2, the proposed TPN achieved much higher accuracy than the mere combination model (referred to as ""Label Propagation"").
"	NOOOOOONNNNNEEEE	"""(1) There is not much technical contribution. It merely just puts the CNN representation learning and the label propagation together to perform end-to-end learning. Considering the optimization problem involved in the learning process, it is hard to judge whether the effect of such a procedure from the optimization perspective.""
"	NOOOOOONNNNNEEEE
C. Your method involves a hyperparameter to be tuned which affects the shape of the schedule.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In our updated paper we show that APO with a fixed lambda achieves comparable performance to manual learning rate decay schedules.
.While using a schedule for lambda can potentially further improve performance, a simple grid search over fixed lambda values already leads to strong performance, and has the advantage that it is easy to use in practice.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: Does the hyperparameter lambda itself benefit from some scheduling?
"	NOOOOOONNNNNEEEE
This hyperparameter itself benefits from (requires?) some scheduling.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In our updated paper we show that APO with a fixed lambda achieves comparable performance to manual learning rate decay schedules.
.While using a schedule for lambda can potentially further improve performance, a simple grid search over fixed lambda values already leads to strong performance, and has the advantage that it is easy to use in practice.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: Does the hyperparameter lambda itself benefit from some scheduling?
"	NOOOOOONNNNNEEEE
The more interesting question of how to generalize to unseen items (how would that be possible given that items have no representation at all) is not discussed at all and seems not to be realizable, which makes the starting point of such methods (items have no representation) questionable.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Items having no representation is a caveat of the data available rather than that of the method.
.The representationless framework of triplets is relevant to many applications (e.g. crowdsourcing), and the whole field of comparison-based learning works in this framework.
.First, it is not standard practice to discuss the generalization to unseen instances in unsupervised machine learning problems, for example in the literature on clustering. But of course, if generalization exists, it is of advantage.
.We believe that in our case, generalization is realizable.
.One possible approach would be to reserve some extra bits in the binary representation of inputs, and then utilize it to represent new items.
.The network can be trained with extra batches of triplets which involves the new items.
"	NOOOOOONNNNNEEEE	"- Methods, where items have no representation, are questionable
.- How to generalize to unseen items
"	NOOOOOONNNNNEEEE
"-	The paper has a specific form of formulation for abductive reasoning, where there are exactly two observations and one proceeds the other; the explanation happens in between. I can see this helps collect and annotate data, but also limit the form of abductive reasoning and how models should be developed."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We totally agree that in its most general form, there should be any number of observations and models should be required to generate explanatory hypotheses in natural language (as in the alpha-NLG task).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We hope our work will lead to this future line of research.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The simplifying assumptions, mentioned in the paper, allow us to i) formulate the tasks concretely and ii) curate the dataset and evaluate models viably.
.We show that in spite of the assumptions, our dataset presents significant challenges for current models.
"	NOOOOOONNNNNEEEE	"Re. limited form of Abductive Reasoning:
"	NOOOOOONNNNNEEEE
If the compression rate is optimized on the test set, then the compressed model is nothing but a model overfit to the test set.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I am a making a recommendation for reject for this paper with the main reason being that I believe the primary derivations for their method appear flawed.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
--In the main section describing the approach (Section 4), the authors start with a claim that Equation 1 and 2 are equal; I don’t believe 1 and 2 are equal.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(Bounds of KL divergence) Thank you for this good comment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We claimed that the Equation 1 can be maximized indirectly by maximizing Equation 2 which is a lower bound of Equation 1.
.If we understand your primary concern correctly, the concern comes from the bound of KL divergence in Equation 5.
.To prove correctness of our formulation, we can rewrite the pointed term in Equation 5 by using simple bayes rule as follows:
.$$\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\ \mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(c|z)}} = \displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\bigg(\mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(z|c)}} + \mathrm{log}\ \frac{\hat{p}\mathrm{(z)}}{\hat{p}\mathrm{(c)}} \bigg)$$
.Because the $\hat{p}\mathrm{(c)}$ is constant, and $\hat{p}\mathrm{(z)}$ is not included in our optimization, we just optimize $\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\mathrm{log}[\hat{q}\mathrm{(z|c)} / \hat{p}\mathrm{(z|c)}]$. Since the $\hat{q}\mathrm{(z|c)}$ and $\hat{p}\mathrm{(z|c)}$ are both normalized distributions, the $D_{KL}[\hat{q}\mathrm{(z|c)} || \hat{p}\mathrm{(z|c)}]$ is always positive.
.Then, we can conclude that Equation 2 becomes the lower bound for Equation 1.
"
--In Section 4.1, it appears that they are instead making a claim about Equation 2 being a bound for equation 1; but even this derivation appears to have a problem.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(Bounds of KL divergence) Thank you for this good comment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We claimed that the Equation 1 can be maximized indirectly by maximizing Equation 2 which is a lower bound of Equation 1.
.If we understand your primary concern correctly, the concern comes from the bound of KL divergence in Equation 5.
.To prove correctness of our formulation, we can rewrite the pointed term in Equation 5 by using simple bayes rule as follows:
.$$\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\ \mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(c|z)}} = \displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\bigg(\mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(z|c)}} + \mathrm{log}\ \frac{\hat{p}\mathrm{(z)}}{\hat{p}\mathrm{(c)}} \bigg)$$
.Because the $\hat{p}\mathrm{(c)}$ is constant, and $\hat{p}\mathrm{(z)}$ is not included in our optimization, we just optimize $\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\mathrm{log}[\hat{q}\mathrm{(z|c)} / \hat{p}\mathrm{(z|c)}]$. Since the $\hat{q}\mathrm{(z|c)}$ and $\hat{p}\mathrm{(z|c)}$ are both normalized distributions, the $D_{KL}[\hat{q}\mathrm{(z|c)} || \hat{p}\mathrm{(z|c)}]$ is always positive.
.Then, we can conclude that Equation 2 becomes the lower bound for Equation 1.
"
If one were to interpret the second one as the unnormalized distribution on z defined via the likelihood for c given z; even this has an issue because then the expression for KL where we plug the unnormalized density in place of the normalized need not be positive which is something they need to derive their bound.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(Bounds of KL divergence) Thank you for this good comment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We claimed that the Equation 1 can be maximized indirectly by maximizing Equation 2 which is a lower bound of Equation 1.
.If we understand your primary concern correctly, the concern comes from the bound of KL divergence in Equation 5.
.To prove correctness of our formulation, we can rewrite the pointed term in Equation 5 by using simple bayes rule as follows:
.$$\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\ \mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(c|z)}} = \displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\bigg(\mathrm{log}\ \frac{\hat{q}\mathrm{(z|c)}}{\hat{p}\mathrm{(z|c)}} + \mathrm{log}\ \frac{\hat{p}\mathrm{(z)}}{\hat{p}\mathrm{(c)}} \bigg)$$
.Because the $\hat{p}\mathrm{(c)}$ is constant, and $\hat{p}\mathrm{(z)}$ is not included in our optimization, we just optimize $\displaystyle\sum_{\mathrm{z}}\hat{q}\mathrm{(z|c)}\mathrm{log}[\hat{q}\mathrm{(z|c)} / \hat{p}\mathrm{(z|c)}]$. Since the $\hat{q}\mathrm{(z|c)}$ and $\hat{p}\mathrm{(z|c)}$ are both normalized distributions, the $D_{KL}[\hat{q}\mathrm{(z|c)} || \hat{p}\mathrm{(z|c)}]$ is always positive.
.Then, we can conclude that Equation 2 becomes the lower bound for Equation 1.
"
--Another issue is that the regularization lambda should apply to both the terms in the bound but in Equation (7) only appears selectively for one of the two terms.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Actually, Equation 7 consists of three terms.
.Since only the third term is proposed additional regularization, we applied weighting parameter lambda to the third term only.
"	NOOOOOONNNNNEEEE	"(lambda)
"	NOOOOOONNNNNEEEE
--“Redundant weights” seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"If we extend to a more complex dataset such as ImageNet, it will become highly redundant.
.Furthermore, if we consider fully-convolutional architecture (without fully-connected layers), redundancy becomes a serious problem.
.For example, a feature map that has shape of [W x H x dim] becomes [W x H x (dim + the number of classes)].
.In contrast, using discriminative conditional distributions can keep the dimension of the feature map as [W x H x dim] regardless of the number of classes.
"	NOOOOOONNNNNEEEE	"(Redundant weights)
"	NOOOOOONNNNNEEEE
Otherwise, some poorly performed models could lead to near-random or adversarial inter-model discrepancies, failing the proposed approach.	MET	NOOOOOONNNNNEEEE	"From this perspective (and other reasons mentioned in the discussion section), MAD should be viewed as complementary to, rather than a replacement for, the conventional accuracy comparison for image classification.
.When two classifiers perform at a reasonable level and achieve very close accuracy numbers (e.g., VGG16BN and ResNet34 on ImageNet validation set), MAD provides the most efficient way of differentiating the two models by maximizing their discrepancies over a large-scale image set.
.We want to emphasize that MAD is especially useful on image classification tasks where most cutting-edge classifiers achieve very close performance.
.In these situations, the MAD competition ranking, which is obtained by evaluating on corner examples searched from web-scale unlabeled dataset, is more convincing than something like 1% accuracy advantage on the validation set.
.For problem domains where there are few sufficiently accurate models, we may still apply the underlying principle behind MAD to create adaptive test sets such that the strengths and weaknesses of the models are most easily revealed.
.In those scenarios, we conjecture that we need increase k to a reasonably larger number, thus at the cost of efficiency.
"	"We will make this assumption explicit in the revised manuscript.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As also mentioned by Reviewer #2, the proposed MAD implicitly assumes that classifiers in the competition are reasonably accurate.
.Otherwise, the selected counterexamples may be less meaningful.
"	"Regarding comment 1: Thanks for recognizing the merit of our idea.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Another potential issue is that the proposed approach cannot handle training set bias. If all models are biased in similar ways (e.g., toward a particular class or domain), they will not reveal informative discrepancies for the images over which they all make similar mistakes.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As long as two (or multiple) models differ (even in slightly different ways), MAD provides the highly efficient way of spotting such differences by exploring a large-scale unlabelled dataset.
.However, these differences are less likely to be revealed using a fixed and small test set (i.e., they will probably have the same accuracy numbers as models to be compared are very similar and are biased in similar ways).
.For the extreme case that two models are exactly the same (i.e, they are biased in identical ways and make identical prediction errors), both MAD and traditional accuracy-based methods will draw the same conclusion - the two models have the same performance.
.Accuracy-based evaluation methods arrive at this conclusion by comparing model predictions with ground truth labels and outputting the same accuracy numbers.
.In contrast, MAD arrives at the same conclusion without any human labeling since the set S for subjective testing is empty.
.So in this extreme case, both MAD and accuracy fail to compare those two models.
"	"Regarding comment 2: Thanks for the comment.
"	NOOOOOONNNNNEEEE	"In summary, to reliably compare the relative performance of computational models, all evaluation methodologies (including MAD) rely on the assumption that the models to be compared should be diverse to a certain extent, and the proposed MAD makes this assumption more explicit.
.In fact, MAD makes the best use of model discrepancies (even if models are biased in very similar but not identical ways) to rank the model performance.
.As a matter of fact, based on our experiments, we find that state-of-the-art ImageNet classifiers do have their own biases. (See figure 8 in the appendix.)
"
Hence, while I agree with the authors that existing approaches to comparing deep neural network classifiers could be improved, I think the proposed solution is not a good alternative yet.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Comparison to ""SGD BN removed"" is not fair because the initialization is different (application of BN re-initializes weight scales and biases)."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- It seems that the model is not very scalable; while the authors do provide a way of reducing the necessary parameters that the hypernetwork has to predict, minibatching can still be an issue as it is implied that you draw a separate random weight matrix for each datapoint due to the input specific distribution (as shown at Algorithm 1).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(1) While indeed we need more samples of weight matrices than e.g. for applying VI for BNNs for due to the input dependency, we do not believe this makes our method unscalable to real world scenarios.
.Note, that input dependent samples are also needed in the variational training of VAEs (where the number of hidden variables is of course much smaller than the number of weight parameters in our setting).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Is this how you implemented minibatching in practice? How easily is this applied to convolutional architectures?	MET	NOOOOOONNNNNEEEE	"While we present the training algorithm naively in an online version for clearness in Algorithm 1, in practice mini-batching can be done efficiently, due to the availability of batched linear algebra operations, at least in the framework we use (PyTorch), e.g. torch.bmm, broadcasting semantics, etc.
.For convolution layers, we can simply use a different type of mixing distribution, e.g. a fully-factorized multivariate normal instead of matrix-variate normal.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"When you say that full-matrix computation ""requires taking the inverse square root"", I assume you know that is not really correct?"	MET	NOOOOOONNNNNEEEE	"@Inverse square root: We are fully aware of the distinction.
.- Note that iterative solvers like conjugate gradient do not immediately apply here, as we are solving a linear system in M^{1/2}, not M.
.- Krylov subspace iterative solvers suffer from a condition number dependence, incurring a hard tradeoff between iteration complexity and \eps. [1]
.- We actually *did* try polynomial approximations to M^{-1/2} as an alternative to our proposed small-SVD step.
.We saw worse approximation (the condition number dependence kicks in) and worse GPU performance (parallel computation time scales with polynomial degree).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. Re: iterative methods: the preconditioner is a -1/2 power of the Gram matrix, not the inverse.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
As a matter of good implementation, one never takes the inverse of anything.	MET	NOOOOOONNNNNEEEE	"@Inverse square root: We are fully aware of the distinction.
.- Note that iterative solvers like conjugate gradient do not immediately apply here, as we are solving a linear system in M^{1/2}, not M.
.- Krylov subspace iterative solvers suffer from a condition number dependence, incurring a hard tradeoff between iteration complexity and \eps. [1]
.- We actually *did* try polynomial approximations to M^{-1/2} as an alternative to our proposed small-SVD step.
.We saw worse approximation (the condition number dependence kicks in) and worse GPU performance (parallel computation time scales with polynomial degree).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. Re: iterative methods: the preconditioner is a -1/2 power of the Gram matrix, not the inverse.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
There are several issues convolved here: one is ``full-matrix,'' another is that this is really a low-rank approximation to a matrix and so not full matrix, another is that this may or may not be implementable on GPUs.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. GGT does not take the view of a low-rank *approximation*. This is a central point of the paper.
.@Full-matrix terminology: The use of “full-matrix” to distinguish from “diagonal-matrix” is standard, and taken directly from [2].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
There is a great deal of discussion about full-matrix preconditioning, but there is no full matrix here.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"@Full-matrix vs. full-rank: Note that we do not consider the windowed Gram matrix to be an “approximation” of the “full” gram matrix.
.The window is for the purpose of forgetting gradients from the distant past, motivated by (1) our theory, (2) the small-scale synthetic experiments, and (3) the extreme ubiquity of Adam and RMSprop, which do the same.
.Note that we do no approximation on the windowed Gram matrix, the fact that it is low rank is a feature.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is difficult to know what the theory says about the empirical results, given the tweaks discussed in Sec 2.2, and so it is difficult to know what is the benefit of the method versus the tweaks.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"@Tweaks: We don’t believe that any of the tweaks should be so controversial.
.- The \eps parameters are present in *every* adaptive optimizer, for stability.
.The interpolation with SGD is just another take on this.
.- The exponential smoothing of the first moment estimator is a subtler point.
.As we point out in Appendix A.2, in the theory for Adam/AMSgrad [3,4], \beta_1 *degrades* the moment estimation, yet everyone uses momentum in practice.
.Even if this is unconvincing, the performance gap upon removing this tweak is minor, and our empirical results hold without this tweak.
.We are simply offering a heuristic that we have observed to help training unconditionally, just like momentum in Adam.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"You say that you ""informally state the main theorem.""  The level of formality/informality makes it hard to know what is really being said.  You should remove it if it is not worth stating precisely, or state it precisely.  (It's fair to modularize the proof, but as it is it's hard to know what it's saying, except that your method comes with some guarantee that isn't stated.)"	MET	NOOOOOONNNNNEEEE	"@Informal main theorem: By “informal” we truly mean that we are suppressing the smoothness constants (L, M) for readability and space constraints. We are simply adopting the widespread practice of deferring the non-asymptotic mathematical statement to the appendix.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
How would the given graph network compare to this?	MET	NOOOOOONNNNNEEEE	"In general, NGE has significant improvement both quantitatively and qualitatively.
.In environment where global information is needed (for example, walker with multiple rigid body contact), the performance is jeopardized. But in an easier environment, message passing is less needed.
"	NOOOOOONNNNNEEEE	"We thank the reviewer for pointing out the baseline of no message passing in GNN, which we named as ESS-BodyShare.
"	NOOOOOONNNNNEEEE	"In the latest revision, we have 5 baselines from previous research and modern variants, which further showcases the significance of our work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q3: Comparison to more baseline, for example models with no message passing.
.We refer the reviewer to the general response for further information.
.Specifically for ESS-BodyShare baseline:
"	"|
.NGE     | ESS-BodyShare
.fish         |  70.21   |  54.97
.(78.3% of NGE)
.Walker   |
.4157.9 |   2185.1 (52.5% of NGE)
"
Does the controller also start from scratch? If so, why? Also, it is not clear what is the meaning of generations if the graph is fixed, can't it be learned altogether at once?	MET	NOOOOOONNNNNEEEE	"Our aim was to show that in the case where the human-engineered topology needs to be preserved, it is better to co-evolve the attributes and controllers with NGE rather than only training the controllers (controllers are trained from scratch for both NGE and baselines).
.The x-axis was scaled according to the number of updates.
"	NOOOOOONNNNNEEEE	"We apologize for the lack of clarity.
"	NOOOOOONNNNNEEEE	"We revised the x-axis from “generations” to parameter “updates” in the latest revision.
.In the latest revision, we also included the curve where the topologies are allowed to be changed, which leads to better performance, but does not necessarily preserve the initial structure.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q4: Clarification of Figure-4 (Section-4.2)
"	NOOOOOONNNNNEEEE
Could it be that what we are seeing is the attack being denoised?	MET	NOOOOOONNNNNEEEE	"3. We currently do not have a full explanation for the large adversarial resistance, but noise resistance must play a part in it.
.The very strong rejection of Gaussian noise and the observations in Fig. 4 point in this direction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I am puzzled and looking forward to answers to the above questions. I don't yet understand what is the thing that makes this approach appear to work, or why you were able to drop the Bayes inference inversion altogether as done by Schott.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Does such approximation guarantee the policy improvement?	MET	NOOOOOONNNNNEEEE	"Q2: No the mean policy is not used due to the likelihood ratio trick.
.And the approximation of using mean policy is discussed in [3], with a sound deduction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
(6) If the authors jointly and simultaneously optimize \theta and \phi, why a regularization term about q_{\phi}(z)  is missing in Eq 12 while a regularization term about \pi_{\theta|z} does appear in Eq 12?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
There might be other constructions that are more efficient and less restrictive.	MET	NOOOOOONNNNNEEEE	"While not equivalent, as a first step towards this, we did try to examine different levels of idempotency enforcement.
.First, at the reconstruction loss, since pairs of canonicalizers are applied in different order we enforce the the decoded results are similar.
.However, adding a stricter enforcement of similar values before decoding only hurt performance, hinting that the suggested idea of enforcing idempotency at the strictest level may hurt performance further.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A: Structuring the matrix to enforce properties like idempotency is definitely an interesting direction to explore in future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"There might be other constructions that are more efficient and less restrictive.
"	NOOOOOONNNNNEEEE
I don’t follow this argument: this is just part of the classifier. White box attacks are by definition performed with the knowledge of the model, what	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I appreciate the idea of testing full white-box adversarial attacks here. But I don’t understand how it is possible that DDGC is more robust, with higher adversarial test accuracy, than in Table 3.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This aspect of the task seems somewhat contrived, and it makes me wonder whether the striking failure of the non-modulated RNNs depends on this detail.	MET	NOOOOOONNNNNEEEE	"The random zero-inputs make the timing of the cues unpredictable, forcing the network to be driven specifically by the stimuli - as opposed to learning a pre-programmed strategy at each given time step.
.This is merely a convenient choice to make the task more challenging.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Re: ""Why were zero-sequences necessary in Experiment 1? [...] Perhaps the authors could clarify on what a confounding ""time-locked scheduling strategy"" would look like in this task?""
"	NOOOOOONNNNNEEEE
The major concern I have is that the ensemble of MC-Dropout models is not an approximation of the posterior anymore.	MET	NOOOOOONNNNNEEEE	"We had similar doubts about the benefit of adding MC-Dropout to an ensemble.
.Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.
.By better we mean
.Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.
.We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.
.Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))
.2) better calibrated (Fig 6 (left)).
"
Each MC-Dropout model is an approximation of the posterior, but the ensemble of them may not.	MET	NOOOOOONNNNNEEEE	"We had similar doubts about the benefit of adding MC-Dropout to an ensemble.
.Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.
.By better we mean
.Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.
.We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.
.Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))
.2) better calibrated (Fig 6 (left)).
"
Therefore, it is a little misleading to still call it Bayesian active learning.	MET	NOOOOOONNNNNEEEE	"We had similar doubts about the benefit of adding MC-Dropout to an ensemble.
.Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.
.By better we mean
.Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.
.We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.
.Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))
.2) better calibrated (Fig 6 (left)).
"
Also, the ensemble of MC-Dropout models does not have the theoretic support from the Bayesian perspective.	MET	NOOOOOONNNNNEEEE	"We had similar doubts about the benefit of adding MC-Dropout to an ensemble.
.Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.
.By better we mean
.Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.
.We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.
.Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))
.2) better calibrated (Fig 6 (left)).
"
The motivation for the proposed method is to solve the mode collapse problem of MC-Dropout, but using ensemble loses the Bayesian support benefit of MC-Dropout.	MET	NOOOOOONNNNNEEEE	"We had similar doubts about the benefit of adding MC-Dropout to an ensemble.
.Therefore, we contrasted the performance of DEBAL against the plain ensemble method and showed empirically that DEBAL gives rise to better measures of uncertainty.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Even though we have not yet proved the above, we have empirically showed that the benefit of DEBAL over plain ensemble methods consists of a better representation of uncertainty, that is paramount in active learning.
.By better we mean
.Our initial aim was not to compare stochastic ensembles with deterministic or single MC-dropout but to correct for the mode collapse issue in estimating posteriors with MC-dropout.
.We have empirically shown that adding ensembles to this, greatly improves the MC-dropout technique and outperforms the deterministic ensembles as well.
.Finally, as we strive to make our assumptions hold theoretically, we agree that adding theoretical Bayesian support to our method is of great importance if we are to further improve the understanding of Bayesian deep learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) more meaningful and closer to what one would expect (Fig 4 & Fig 6 (right))
.2) better calibrated (Fig 6 (left)).
"
Since this paper select the top-k images in D, if k is large the annotating for S will be very tedious, however if k is relatively small the method seems very sensitive to selected examples, which will make the comparison not totally convincing.	MET	NOOOOOONNNNNEEEE	"We want to however draw the reviewer’s attention to the ablation study and figure 5, if they were accidentally missed in the first reading.
.When we apply MAD to compare imageNet classifiers, we find that the MAD ranking stabilizes very quickly when around k>15.
.We would like to also emphasize that despite the small size of labeled images, MAD successfully tracks the steady progress in image classification, as verified by a reasonable Spearman rank-order correlation coefficient (SRCC) of 0.89 between the accuracy rank on ImageNet validation set and the MAD rank on our test set.
.As also pointed out by Review #2, the selected top-k images provide the strongest examples to let classifiers compete with one another.
.Through this process, their respective strengths, weaknesses as well as biases can be most easily revealed (see figures in the appendix).
"	NOOOOOONNNNNEEEE	"We agree with the reviewer that k is a critical parameter in MAD.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Based on them, we cannot concur with the statement “if k is relatively small the method seems very sensitive to selected examples”.
"	NOOOOOONNNNNEEEE	"Q2: Since this paper select the top-k images in D, if k is large the annotating for S will be very tedious, however if k is relatively small the method seems very sensitive to selected examples, which will make the comparison not totally convincing.
.Response:
"	NOOOOOONNNNNEEEE
My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true.	MET	NOOOOOONNNNNEEEE	"We envisage an optimizer not merely as update equations, but as the conjunction of the update equations, the hyperparameters, and distributions of those hyperparameters.
.Those distributions should be prescribed by the designers of the optimizer.
.This is crucial: For example, if we take Adam with LR between $10^1$ and $10^5$ and claim that Adam is less tunable than others, the evaluation is inherently faulty, as it doesn't capture where the mode of the distribution of LRs for which Adam is expected to work.
.These prescriptions are absent for the optimizers considered in the paper.
.Therefore, we define them from either mathematical reasoning (say learning rate is non-negative, $\beta_1, \beta_2$ in Adam are between (0, 1) and close to 1) or using the calibration step, where we determine those distributions by fitting on the configurations that yielded reasonably good results.
.We choose simple priors for their ease of estimation, though given enough computation, arbitrarily complex priors can be computed and used.
.We fail to see the explicit relationship between our work and the papers you have referenced.
.Specifically [1] only proposes that there is an optimal batch size that is dependent on the momentum parameter.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"a. Prior distributions of hyperparameters
.a. Prior distributions of hyperparameters:
"	NOOOOOONNNNNEEEE
a. In Eq. (3), it surprises me to see the symbol \epsilon without any explanation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
b. In Eq. (6), it also surprises me to see no description of \phi and \psi.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- why do you need a conditional GAN discriminator, if you already model similarity by L1?	MET	NOOOOOONNNNNEEEE	"A:(1) The logic of using both of them has been explained in the answer to the last question.
.(2) The logic has been well-utilized and verified in the image-translation domain. Again please see the details in the answer to the last question.
.Our ablation experiment also demonstrates the similar advantage of using both losses for graph translation than only using L1 loss.
.Specifically, the proposed GT-GAN that uses both loses outperformed the S-Generator that only uses L1 loss on all three datasets by 10% in accuracy on average as shown in Table 2,3 and 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q: Third, and slightly related to the previous point, why do you need a conditional GAN discriminator, if you already model similarity by L1?
"	NOOOOOONNNNNEEEE
Instead here you seem to suggest to use L1 and GAN to do basically the same thing, or with significant overlap anyways.	MET	NOOOOOONNNNNEEEE	"A:(1) The logic of using both of them has been explained in the answer to the last question.
.(2) The logic has been well-utilized and verified in the image-translation domain. Again please see the details in the answer to the last question.
.Our ablation experiment also demonstrates the similar advantage of using both losses for graph translation than only using L1 loss.
.Specifically, the proposed GT-GAN that uses both loses outperformed the S-Generator that only uses L1 loss on all three datasets by 10% in accuracy on average as shown in Table 2,3 and 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Instead, here you seem to suggest using L1 and GAN to do basically the same thing, or with significant overlap anyways.
"	NOOOOOONNNNNEEEE
Please explain the logic for this architectural choice.	MET	NOOOOOONNNNNEEEE	"A:(1) The logic of using both of them has been explained in the answer to the last question.
.(2) The logic has been well-utilized and verified in the image-translation domain. Again please see the details in the answer to the last question.
.Our ablation experiment also demonstrates the similar advantage of using both losses for graph translation than only using L1 loss.
.Specifically, the proposed GT-GAN that uses both loses outperformed the S-Generator that only uses L1 loss on all three datasets by 10% in accuracy on average as shown in Table 2,3 and 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Please explain the logic for this architectural choice.
"	NOOOOOONNNNNEEEE
However, when the weights are set to zero the weight matrix became sparser but still requires the whole weight matrix to be used by the computing resources, as removing some of the weights based on the sorting will not remove a node, only removes some of the connection with that node.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"First, we want to mention that DeepTwist is proposed not only for weight pruning, but also for other compression techniques, such as quantization and low-rank approximation, as we discussed in Section 4.2 and 4.3
.After weight pruning is performed and zero weights are removed, we usually obtain a sparse matrix to represent non-zero weights.
.There are lots of existing sparse matrix computation libraries to support SpMV (sparse matrix-vector multiplication) and so on.
.If a matrix is highly sparse, then we would reduce memory footprint and amount of computations (for example, we can skip zero weights during computation) significantly.
.There have been extensive studies of efficient hardware implementation after weight pruning, and we want you to refer to the paper “EIE: efficient inference engine on compressed deep neural network” or “Deep compression: compressing deep neural networks with pruning, trained quatization and Huffman coding.”
.In this paper, we have not discussed particular sparse matrix implementation methods which are not our focus in this paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Therefore, it is not clear how the proposed framework is helping the model compression techniques.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"First, we want to mention that DeepTwist is proposed not only for weight pruning, but also for other compression techniques, such as quantization and low-rank approximation, as we discussed in Section 4.2 and 4.3
.After weight pruning is performed and zero weights are removed, we usually obtain a sparse matrix to represent non-zero weights.
.There are lots of existing sparse matrix computation libraries to support SpMV (sparse matrix-vector multiplication) and so on.
.If a matrix is highly sparse, then we would reduce memory footprint and amount of computations (for example, we can skip zero weights during computation) significantly.
.There have been extensive studies of efficient hardware implementation after weight pruning, and we want you to refer to the paper “EIE: efficient inference engine on compressed deep neural network” or “Deep compression: compressing deep neural networks with pruning, trained quatization and Huffman coding.”
.In this paper, we have not discussed particular sparse matrix implementation methods which are not our focus in this paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Thus, based on this approach, the reconstruction image may not be optimal with respect to the resolution which might be critical for cryo-EM reconstruction.	MET	NOOOOOONNNNNEEEE	"1) The VAE is hypothesized to produce blurry images when the inference/generative models are not sufficiently expressive for the data modeling task, and in particular due to the typical choice of MSE loss (i.e. Gaussian error model), thus blurring sharp edges in complex natural image data [1,2,3].
.In the case of cryo-EM, the high noise in the images is typically assumed to be Gaussian and therefore using the MSE loss has a denoising effect.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In our experiments, we were able to achieve resolutions up to the ground truth resolution or matching published structures with our architecture and training settings, though we agree with the reviewer that exploring alternative generative models is a promising future direction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Even without the ""train to convergence"" question above, I don't think the authors have demonstrated that their claims on the properties of their algorithms/formulations are generally true."	MET	NOOOOOONNNNNEEEE	"Indeed, we should remind that our adaptive homeostasis allows to be implemented by modifying the norm of each atom of the dictionary (as was done in the original work by Olshausen).
"	"We are in the process of extending this framework to other sparse coding algorithms (LARS and lasso_lars) as plugged in from sklearn without any modification (in theory) to these algorithms.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have now included it in an anonymized format.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Second, we had already done the comparison ""against several costs/algorithms (e.g. l_0 with OMP, l_1 with LARS, etc.), and across various N_0/sparsity penalties"" but we had initially omitted to include this supplementary data (that takes the form of a single jupyter notebook which allows to reproduce all results).
"	NOOOOOONNNNNEEEE	"We also show in the paper the application to a one-layer convolution network and our preliminary results show that we can extend this to a hierarchical network.
"	"This supplementary material contains code to replicate all figures but also additional experiments to test the effect of the different parameters.
.In short, we verified that the results we present are valid over a various number of parameters of the network, like the learning rates (figure 2) but also sparsity and the size of the dictionary (see Response To AnonReviewer3 @ https://openreview.net/forum?id=SyMras0cFQ&noteId=BylQtQPHRX ).
.As in Sandin, 2017 paper we have shown similar results in OMP.
"
However, it does exclude some popular activation families, such as the polynomial activation, which were proven effective in multiple areas.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It's true that there are many activation functions that the result doesn't apply to, and in fact isn't true for.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The selling point isn't the generality of the result, but rather the novelty of the approach and the potential it suggests for future work that would be more general.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- It is not clear whether pushing the catastrophic forgetting problem into the generator is the best approach.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3. We are not simply shifting the forgetting problem into G.
.Our work tackles the problem of class incremental learning.
.As opposed to task-incremental setup and shown in previous work, e.g. [3,4,5], models in class incremental setup (with single-head architecture) require a replay of previously seen categories when learning new ones.
.The reason for using G
.is not having access to samples of previous classes in the “strict” incremental setup and using generated samples instead.
.As pointed out in our work, restricting storage of real samples represents a more realistic setup, since in real-world applications such an “episodic memory” with real samples is often impossible due to memory and privacy restrictions.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
As such, I find it surprising that simply storing instances would do as poorly as stated in this paper which says cannot provide enough diversity.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Furthermore, using generated samples accommodates for better performance than simply storing instances only in case of tasks of relatively low complexity such as MNIST.
.Indeed, such a result has been shown in other works, e.g. [1].
.As explained in Sec. 5.2, this can be attributed to a potentially higher diversity with steady quality of the generated samples.
.Clearly, the performance of the classifier trained on the generated samples highly depends on the complexity of the task and quality of the generated samples.
.Thus, this effect can be observed neither in the SVHN nor the CIFAR10 benchmarks.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"It also seems strange to say that storing instances ""violates the strictly incremental setup"" while generative models do not."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. The approach is not well justified either by theory or practice.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We respectfully disagree with the referee’s conclusions, and will elaborate on the above statements in the following.
.While we disagree, we did however undertake a significant effort to further clarify and provide additional evidence in the revised manuscript, taking into account these comments.
.Regarding the theoretical correctness of deep probabilistic subsampling, in section 3.2 we explain how we incorporate a well-known reparametrization trick, termed the Gumbel-max trick (Gumbel,1954), to sample from a categorical probability distribution.
.Note that this shares similarities with the reparameterization trick used for sampling from trained gaussian distributions in a vanilla variational autoencoder.
.The Gumbel-max reparametrization perturbs the logits of the categorical distribution with Gumbel noise after which, by means of the argmax, the highest value is selected.
.Gumbel (1954) showed that this reparametrization allows sampling from the original categorical distribution.
.Recent state-of-the art work on a relaxation of this trick, termed Gumbel-softmax sampling (Jang et al., 2017) or the concrete distribution (Maddison et al., 2016), allows us to apply this relaxed reparametrization inside a neural network as it enables gradient calculation, which is needed for error backpropagation in the training procedure of the network.
.We would like to ask the reviewer what is believed to be missing from this explanation on the subsampling part of our proposed method.
.Regarding the theoretical basis used for the design of the task network; we took a theoretically principled approach by exploiting a model-driven network architecture for the CIFAR10 reconstruction problem.
.To that end, we unfold the iterations of a proximal gradient scheme (Mardani et al., NeurIPS, 2018), allowing for explicit embedding of the acquisition model (and therewith the learned sampling) in the reconstruction network.
.Regarding the referee’s conclusion that the manuscript lacks comparison to the approaches of (Xie & Ermon (2019); Kool et al. (2019); Plötz & Roth (2018): We would like to point out that these three references all together put forward the Gumbel top-k method.
.Note that the use of the Gumbel top-k method for compressive sampling is also new, and in fact constitutes a specific case (constrained version with shared weights across distributions) of the proposed deep probabilistic subsampling (DPS) framework.
.In the MNIST experiments we already included Gumbel top-k sampling, but we will also add this for the other experiments in the revised manuscript.
.In addition, we added a thorough comparison of the DPS to LOUPE (Bahadir et al, 2019), a recently proposed data-driven method for subsampling.
"	NOOOOOONNNNNEEEE	"Question 1:
"	NOOOOOONNNNNEEEE
Additionally, the Wave-U-Net appears to reach the same accuracy as the Harmonic Convolution with many fewer iterations (while also continuing to get much higher PSNRs).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time.	MET	NOOOOOONNNNNEEEE	"In fact, we intended to model the level proportion as shown in the third part of our generative process on page 4.
.Often, for grouped-data, the level proportion (or topic proportion) is modeled as a group-specific variable.
.Under our non-grouped data setting, for example, two following approaches are possible: 1) as the reviewer mentioned, globally define a level proportion once, take multiple level samplings for each data, and 2) as our modeling, locally define the data-specific level proportion, followed by sampling the level (this is actually auxiliary variable for specifying the Gaussian distribution).
.The reason we chose the latter approach is for modeling more flexible prior.
.The Gaussian mixture distributions exist separately for each level, and we assume the generative process that the mixing coefficient for the level would be different for each data.
.Please consider that the data-instance we handled is a high-dimensional data of a document/an image rather than a word/a pixel.
.The hierarchically Gaussian mixture distributions are learned for different levels, and here assuming a common level proportion for all data forcefully limits the expressive power of the model.
.Also, for preventing the overfitting, we placed the common prior, Dirichlet(\alpha), on the data-specific level proportion, which can be considered as one of the regularization terms.
.[A2] Also, I would like to explain the reviewer’s comment as the formulae.
.The prior we suggested is this: \sum_{\zeta, l} nCRP(\zeta_n) * \eta_{nl} * Normal(-) ( please refer to the Figure 3(a).).
.Moreover, the point that the reviewer pointed out is on \eta_{nl}, i.e., ‘the reason for designing \eta as \eta_{nl}, why \eta is data-specific variable?
.’
..
.There are similar works, which previously published [1-3].
.They designed data-specific mixing coefficients of Gaussian mixture models, for improving more flexibility like ours.
.Under the newly proposed Gaussian mixture models from the above papers, the cluster assignment of data is sampled once from the data-specific mixing coefficient, where there is no theoretical problem as a fully Bayesian formalization.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"[A1] Thank you for the very constructive comments.
.[A3] We were very impressed with the mathematical detail of the reviewer’s comment and thanked you to the reviewer again. If the reviewer agrees with our argument, we will reflect the argument in our paper.
"	"[Q] A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time.
"	NOOOOOONNNNNEEEE
Moreover, the equation J_DIM seems to be wrong since it contains g_\omega twice while I think (but maybe I am wrong) that it has also to be defined by g_\psi.	MET	NOOOOOONNNNNEEEE	"- We added a motivation for mixing two different terms in the objective function.
.Our DIM is primarily designed to improve sentence and span representations.
.We combine it with MLM which is designed for learning (contextual) word representations, since our overall goal is to create better representations for both the sentence and each word in the sentence.
.We also note that Deep InfoMax for learning image representations mixes multiple terms in their objective function.
.We only take one of the terms from the full objective function and mix it with MLM.
.Regarding equation I_{DIM}, it is supposed to contain two g_{\omega} and no g_{\psi} as we use one network for encoding both the sentence and n-grams.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This is not a typo.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
One other limitation seems to be that Theorem 1 requires using a step size which seems to be much smaller than what one may hope to use in practice. Can you comment on this?	MET	NOOOOOONNNNNEEEE	"We think that it is a gap, for which people in the community haven't have any good remedies yet.
.Almost all of the theoretical works in nonconvex optimization and deep learning require a small step size (e.g. works of natural tangent kernel, works of showing the global convergence for a two layer neural net).
.Nevertheless, we want to note that the step size $\eta = O(\epsilon^5)$ in our paper is of the same order as the closely related work (Daneshmand et al. 2018) of escaping saddle points.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"=== Regarding to the small step size ===
"	NOOOOOONNNNNEEEE
It is a minor weak point that the algorithm can work only when the abstract state is obtained by the RAM state.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We discuss our usage of prior knowledge in greater detail in the section titled “Prior Knowledge” in our response to Reviewer 2.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"To clarify, in our experiments, we outperform previous non-demonstration state-of-the-art approaches that use a comparable amount of prior knowledge.
"	NOOOOOONNNNNEEEE	"Reviewer 3 points out the strong state-of-the-art performance of our approach as a strength and mentions prior knowledge (our use of RAM state information) as a minor weakness.
"	NOOOOOONNNNNEEEE
In some RL tasks, it is not allowed to access the RAM state.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We discuss our usage of prior knowledge in greater detail in the section titled “Prior Knowledge” in our response to Reviewer 2.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"To clarify, in our experiments, we outperform previous non-demonstration state-of-the-art approaches that use a comparable amount of prior knowledge.
"	NOOOOOONNNNNEEEE	"Reviewer 3 points out the strong state-of-the-art performance of our approach as a strength and mentions prior knowledge (our use of RAM state information) as a minor weakness.
"	NOOOOOONNNNNEEEE
The algorithm assumptions are strong.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The authors state that proposed framework can be added to any baseline model, but miss to clearly mention the limitations.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"The sentence reads ""... and helps develop intuitions about behaviors observed in more general settings."" Given the restrictive nature of your set-up I find it very hard to believe that this extends to more general settings."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have edited the corresponding sentence to make it less assertive.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
PS: After discussion, I think the motivation of the method is not clear to understand why the proposed method works.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- While the authors suggest that a latent model over the input distribution needs to be trained only once and is applicable off-the-shelf for any further contrastive explanations regarding any network operating on the same dataset -- learning such a model of the input space is an overhead in itself.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response: Overhead calculations of some form are almost impossible to
.avoid.
.Whether this is an overly large computational burdon will depend
.on the problem, although we believe the GAN or VAE need only be trained once
.per domain.
"	NOOOOOONNNNNEEEE	"Comment: Learning such a model of the input space is an overhead in itself.
"	NOOOOOONNNNNEEEE
- Typographical Errors: Section 3.1 repeats the use of D for a discriminator as well as the input distribution.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed the typos.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response:  Thank you.
"	"Comment: typographical errors...
"	NOOOOOONNNNNEEEE
Procedure 1 and Procedure 2 share the same titles -- which is slightly misleading.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed the typos.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Response:  Thank you.
"	"Comment: typographical errors...
"	NOOOOOONNNNNEEEE
Since, there is no clear metric to evaluate contrastive explanations -- human studies to judge the class-discriminativeness (or trust) of the proposed approach would have made the paper stronger.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is not well explained in the paper how this proxy correlates with the Learning progress criteria.	MET	NOOOOOONNNNNEEEE	"First, it does not contain learner-subjective information, but this is partly mitigated through the joint use of with prioritised replay that over-samples high error experience.
.Another potential mechanism by which the episodic return can be indicative of future learning is because an improved policy tends to be preceded by some higher-return episodes -- in general, there is a lag between best-seen performance and reliably reproducing it.
.Second, the fitness is based on absolute returns not differences in returns as suggested by Equation 1; this makes no difference to the relative orderings of z (and the resulting probabilities induced by the bandit), but it has the benefit that the non-stationarity takes a different form: a difference-based metric will appear stationary if the policy performance keeps increasing at a steady rate, but such a policy must be changing significantly to achieve that progress, and therefore the selection mechanism should keep revisiting other modulations.
.In contrast, our absolute fitness naturally has this effect when paired with a non-stationary bandit.
"	"We have also updated the paper to highlight that our proposed proxy is to be understood as an initial, simple, working instance, with a lot of remaining future work that could extend and refine it.
.>
"	"We acknowledge that f departs from LP in a number of ways.
"	NOOOOOONNNNNEEEE	"Thank you for this suggestion, we have now clarified this connection in Section 3.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> The proposed proxy is simply the empirical episodic return.
.It is not well explained in the paper how this proxy correlates with the Learning progress criteria.
.The proxy seems to encourage selecting modulations that lead to generate most rewarding trajectories.
.How this proxy incentives the agent to explore poorly-understood regions?
.In other terms, how this proxy help to tradeoff between exploration and exploitation ?
"	NOOOOOONNNNNEEEE
- The way the authors adapt the modulation z (or at least its description in the paper) seems not technically sounded for me.	MET	NOOOOOONNNNNEEEE	"The distribution of f(z) does change as a function of the parameter change and thus as a function of time.
.This is precisely the kind of non-stationarity that our adaptive mechanism has to deal
.with
..
.This is also the reason behind the adaptive window used in this work.
.In a sense, one can see the size of the window as a proxy for the effective time horizon at which things can be seen as stationary in the learning.
.The window over which we integrate evidence is chosen to make the best recommendation; thus every time we deviate too much from the sample distribution captured within it, we consider this as a sign of non-stationarity and shrink the window.
.This is by no means optimal, nor do we claim it is, but it seems to be a reliable enough proxy to outperform candidates that do assume stationarity (as portrayed by the comparison in Figure 16).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> The way the authors adapt the modulation z (or at least its description in the paper) seems not technically sounded for me
.[...]
"	NOOOOOONNNNNEEEE
It is not clear how those observations can affect practical algorithms and this is something I hope the author can address.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We added an illustrative example in the introduction to give an intuitive understanding of invariance, stability and their relationship.
"	"We currently thinking about an experiment to better illustrate the intuition of our theory and would appreciate any suggestions.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We would appreciate further suggestions.
"	"- Q: Illustrative experiments:
"	NOOOOOONNNNNEEEE
However, in this way, when more and more tasks come, the generator will become larger and larger.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3. To avoid confusion of the proposed method to utilize techniques of DGR[3] in order to prevent forgetting in the G, we kindly ask the reviewer to refer to our response (2) to the Reviewer 1.
.In the proposed work we adopt the generative replay not in order to avoid storing previous samples, but in order to prevent forgetting in the discriminator (which is used as a final classification model).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The proposed method is also heuristic and lacks promising guarantee.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"As pointed out by the reviewer and is true for many machine learning method, there is no guarantee that the proposed method will work for any task or scenario.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"6. No guarantee to work for any task or scenario.
"	NOOOOOONNNNNEEEE
First, the mechanism provided has no mathematical justification--it seems fairly arbitrary.	MET	NOOOOOONNNNNEEEE	"We argue that to estimate the integral of the loss function L(τ) of the RL agent efficiently, we need to draw samples τ from the buffer in regions which have a high probability, p(τ), but also where L|(τ)| is large.
.Since, p(τ) is a uniform distribution, i.e., the agent replays trajectories at random, we only need to draw samples which has large errors L|(τ)|.
.The result can be highly efficient, meaning the agent needs less samples than sampling from the uniform distribution p(τ).
.The CDP framework finds the samples that have large errors based on the ‘surprise’ of the trajectory.
.Any density estimation method that can approximate the trajectory density can provide a more efficient proposal distribution q(τ) than the uniform distribution p(τ).
.The sampling mechanism should have a property of oversampling trajectories with larger errors/‘surprise’.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- We added a mathematical justification paragraph in Section 3.3 “An Importance Sampling Perspective”.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I have a substantial concern that this method might end up assigning a high likelihood of resampling trajectories where something unusual happened, not because of the agent's actions, but because of the world having made a very unusual stochastic transition.	MET	NOOOOOONNNNNEEEE	"We argue that to estimate the integral of the loss function L(τ) of the RL agent efficiently, we need to draw samples τ from the buffer in regions which have a high probability, p(τ), but also where L|(τ)| is large.
.Since, p(τ) is a uniform distribution, i.e., the agent replays trajectories at random, we only need to draw samples which has large errors L|(τ)|.
.The result can be highly efficient, meaning the agent needs less samples than sampling from the uniform distribution p(τ).
.The CDP framework finds the samples that have large errors based on the ‘surprise’ of the trajectory.
.Any density estimation method that can approximate the trajectory density can provide a more efficient proposal distribution q(τ) than the uniform distribution p(τ).
.The sampling mechanism should have a property of oversampling trajectories with larger errors/‘surprise’.
.- To mitigate the influence of very unusual stochastic transitions, we use the ranking instead of the density directly.
.The reason is that the rank-based variant is more robust because it is not affected by outliers nor by density magnitudes.
.Furthermore, its heavy-tail property also guarantees that samples will be diverse
.(Schaul et al., 2015b).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, the assumption is too strong.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
third paragraph: Your claim of invariance to time rescaling is technically correct, but I am not convinced that a model can learn the correct omega values for an arbitrary rescaling (e.g. if the period is smaller than the time unit).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
(5) The authors override the CW distance: first in Theorem 3.1 they define it as a distance between two finite point clouds, and later in Theorem 3.2 they redefine it as a distance between a point cloud and the Gaussian distribution.	MET	NOOOOOONNNNNEEEE	"This is true.
"	NOOOOOONNNNNEEEE	"As the reviewer accurately and carefully noticed, we have not formally proved that cw-distance is a true distance, and that the definition is introduced partially: first for two clouds of points, then a distribution and a cloud.
"	NOOOOOONNNNNEEEE	"We have added a respective proof in Appendix, Section A, where also the precise mathematical construction of the general form of Cramer-Wold metric is presented.
.We have also added the comment at the beginning of Section 3 of the paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We hope clarifies our unintentionally imprecise original approach.
"	"POINTS 4 AND 5
"	NOOOOOONNNNNEEEE
The loss term is motivated by the idea that we want the output distribution to retain some information about the context, but why should that be the case?	MET	NOOOOOONNNNNEEEE	"The observed bigrams in a language are not random and the distribution of the second word given the first word in a bigram is not uniform.
.Similarly, the distribution of the first word given the second word will be far from uniform.
.A RNN based language model models the first dependence (and more long range ones) and our proposed PDR tries to model the second one.
.In a unidirectional language model, we cannot look into the future tokens and hence we use the output distribution as a proxy for the ""true second word"" and decode the distribution of the first word.
.Thus the PDR term can be thought of as biasing the language model to retain more information about the distribution of the first word given the second word in a bigram.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, the proposed technique does not seem to be handling the problem foundationally well.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
-The proposed technique seems to include very heavy feature engineering and several ad-hoc practical steps--that is far from the motivation of using NN in tabular data.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are not sure why you conclude this point.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"TabNN is a fully end-to-end learning approach with no need of an extra feature engineering step.
.And as stated in the paper, the design of TabNN follows two principles: \emph{to explicitly leverages expressive feature combinations} and \emph{to reduce model complexity}. We cannot agree there are ad-hoc parts in the proposed model. Could you explain this with more details?
"	NOOOOOONNNNNEEEE	"2. Heavy feature engineering and ad-hoc practical steps
"	NOOOOOONNNNNEEEE
- Sim(delta) should be Dissim(delta) which measures the dissimilarity between channels.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Good point! We have updated this in the revised document, and we think it enhanced clarity.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"[R1: Sim(delta) should be Dissim(delta) which measures the dissimilarity between channels.
"	NOOOOOONNNNNEEEE
The paper positions itself generally as dealing with arbitrary transformations T, but really is	MET	NOOOOOONNNNNEEEE	"The generalization is relatively straightforward and was not too surprising given the APG theory.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“The paper positions itself generally as dealing with arbitrary transformations T, but really is about angular transformations (e.g. Definition 3.1).
"	NOOOOOONNNNNEEEE
It is not clear to me if NF would improve stability/performances in general games.	MET	NOOOOOONNNNNEEEE	"A3: As stated above in our response to Q1, we added the new results of applying negative feedback to SN-GAN, which is a state-of-the-art variant of GANs with empirically stable performance.
.In general, as NF is essentially a penalty term that regularizes $D$ to the zero-function, we can expect it to be effective for most dynamics [*3].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also included the suggested related work (Balduzzi et al. 2018) in Section 5.
"	NOOOOOONNNNNEEEE	"Finally, as for the further evaluation (such as multiple seed runs and 2nd-momentum estimates), we agree it is interesting, but it is very demanding in computational resources, and we leave it for a systematic future investigation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q3: How does negative feedback (NF) influence the training of stable dynamics and further evaluation:
"	"Our results (See Table 1 (bottom) in the revision) indeed show that NF can further improve to reach new state-of-the-art results.
"
- Page 3, Eq. 5: as D and G are functions of time here, eq 5 should maybe be written in more detail to include t	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, as far as I can tell, there is no difference between applying such a hierarchy to the MARL case and to the single agent problem.	MET	NOOOOOONNNNNEEEE	"Many multi-agent problems have been studies using simple robot models (point-mass, etc), where more complex and realistic models have used the problem because significantly more challenging.
.However, often, an assumption can be made that the robots in the environment share similar morphology.
.We propose a method that uses a form of goal-conditioned RL to learn task agnostic low-level policies that can simplify the share control structure across robots.
.In most HRL methods, the lower level can be viewed as part of the environment, yet this restructuring of the environment enables faster and more capable learning.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I also understand that HRL can reduce the number of parameters, but I don't see how structured exploration reduces the number of parameters.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
And lastly, I also can see how parameter sharing can simplify the learning, but I still don't see how it would allow agents to estimate the behaviour change of other agents easier.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
My concern here is that beta might be affecting the result more than the proposed training algorithm.	MET	NOOOOOONNNNNEEEE	"In our experiments, we found that the disentanglement of global and local information is very robust to different values of beta.
.In experiment 1.2 we use beta=1.0 which is the same as using the original VAE objective.
.However, beta does affect the quality of the generative samples (blurriness).
.For experiment 1.1, different beta produce similar disentanglement results, we use beta=20 to produce the figures as it created nicest looking samples.
.We uses beta=40 for all clustering experiments which had been searched from beta=\{1, 10, 20, 30, 40, 50, 60\} for the best digit identity clustering results.
.Thanks to reviewer3, we incorporated this information into the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
How do performance and model size trade off?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R)     A new experiment added to the paper shows the accuracy degradation vs model compression
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"3) How do performance and model size trade off?
"	NOOOOOONNNNNEEEE
How were the number of layers and kernels chosen?	MET	NOOOOOONNNNNEEEE	"R)We started with the original topology replacing convolutional kernels by the Adaptive kernels, then we reduced kernel by kernel, retraining the model each time to match the accuracy (with small drop).
.But our proposal is not the topology is the new type of filters, so many topologies can be improved using this type of filters, for instance an Adaptive ResNet.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4) How were the number of layers and kernels chosen?
"	NOOOOOONNNNNEEEE
Was the 5x10x20x10 topology used for MNIST the only topology tried?	MET	NOOOOOONNNNNEEEE	"R)We tested many, and we think that we can continue reducing the model, but our purpose is not to present a topology, our purpose was to show the advantages of Adaptive convolutions, having a model 66X smaller, 2X less MAC operations and trained 2X faster give us the clue that many researchers can explore on their own topologies and get benefits of it.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"5) Was the 5x10x20x10 topology used for MNIST the only topology tried?
"	NOOOOOONNNNNEEEE
It seems reasonable to suspect that the phenomenon may be due to a common cause in all three model types.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1.  “Why investigate a component specific to just flow-based models (the volume term)? It seems reasonable to suspect that the phenomenon may be due to a common cause in all three model types.”
"	NOOOOOONNNNNEEEE
Negative aspects: One major concern I have with the paper is the notion of privacy considered.	MET	NOOOOOONNNNNEEEE	"In the present paper, we chose the “reconstructive error” as the quantification of privacy because it is the most intuitive one to measure the risk of disclosing sensitive background information in the raw data for the given perturbed data (Encoder output).
"	NOOOOOONNNNNEEEE	"We agree that it is essential to justify how the reconstruction error works as a measure of privacy in this paper.
"	NOOOOOONNNNNEEEE	"In the revision, we have added the following justification on privacy quantification in Section 2, Section 4 and Section 5.
"	NOOOOOONNNNNEEEE	"Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a definitely defined application.
.For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN’s Encoder output, and the sensitive patterns founded from the raw data, in the object recognition application.
"	"First, there is no single standard definition of data privacy-preserving problems and corresponding adversary attacks.
.And a fundamental problem in it is the natural tradeoff between privacy and utility, which is affected by different data privacy-preserving methods.
.Our key contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attackers and privacy quantification.
.Second, finding the right measurement for privacy is an open problem in itself.
.To evaluate RAN, one has to pick some quantifications.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also note that the proposed reconstructive adversarial network (RAN), is not an extension of GAN but only borrows GAN’s thoughts on adversarial training several neural networks, for the data privacy-uniquely problem.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The notion of privacy considered in the paper makes two assumptions which I am not comfortable with: i) The protection that the notion assures is against reconstruction attacks.	MET	NOOOOOONNNNNEEEE	"In the present paper, we chose the “reconstructive error” as the quantification of privacy because it is the most intuitive one to measure the risk of disclosing sensitive background information in the raw data for the given perturbed data (Encoder output).
"	NOOOOOONNNNNEEEE	"We agree that it is essential to justify how the reconstruction error works as a measure of privacy in this paper.
"	NOOOOOONNNNNEEEE	"In the revision, we have added the following justification on privacy quantification in Section 2, Section 4 and Section 5.
"	NOOOOOONNNNNEEEE	"Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a definitely defined application.
.For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN’s Encoder output, and the sensitive patterns founded from the raw data, in the object recognition application.
"	"First, there is no single standard definition of data privacy-preserving problems and corresponding adversary attacks.
.And a fundamental problem in it is the natural tradeoff between privacy and utility, which is affected by different data privacy-preserving methods.
.Our key contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attackers and privacy quantification.
.Second, finding the right measurement for privacy is an open problem in itself.
.To evaluate RAN, one has to pick some quantifications.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also note that the proposed reconstructive adversarial network (RAN), is not an extension of GAN but only borrows GAN’s thoughts on adversarial training several neural networks, for the data privacy-uniquely problem.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I do not see the GAN style approach taken by the paper, ensures this.	MET	NOOOOOONNNNNEEEE	"In the present paper, we chose the “reconstructive error” as the quantification of privacy because it is the most intuitive one to measure the risk of disclosing sensitive background information in the raw data for the given perturbed data (Encoder output).
"	NOOOOOONNNNNEEEE	"We agree that it is essential to justify how the reconstruction error works as a measure of privacy in this paper.
"	NOOOOOONNNNNEEEE	"In the revision, we have added the following justification on privacy quantification in Section 2, Section 4 and Section 5.
"	NOOOOOONNNNNEEEE	"Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a definitely defined application.
.For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN’s Encoder output, and the sensitive patterns founded from the raw data, in the object recognition application.
"	"First, there is no single standard definition of data privacy-preserving problems and corresponding adversary attacks.
.And a fundamental problem in it is the natural tradeoff between privacy and utility, which is affected by different data privacy-preserving methods.
.Our key contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attackers and privacy quantification.
.Second, finding the right measurement for privacy is an open problem in itself.
.To evaluate RAN, one has to pick some quantifications.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also note that the proposed reconstructive adversarial network (RAN), is not an extension of GAN but only borrows GAN’s thoughts on adversarial training several neural networks, for the data privacy-uniquely problem.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The second issue I would like to raise is related to discussions around the non-universality of the vanilla PointNet model.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“The second issue I would like to raise is related to discussions around the non-universality of the vanilla PointNet model. ... if there were any other objectives beyond this in the experiments could you please clarify? “
"	NOOOOOONNNNNEEEE
- I think the comparison between prior lifetimes and humans mastering a language doesn’t hold up and is distracting	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The bijection needs to map training images to a high-density region of the Gaussian, and that aspect would make the model think twice before making the volume term too large.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are not saying that the model will totally disregard the latent density and attempt to scale the input to very large or infinite values.
.Our point is made in the context of volume term which is only one of the terms in the change-of-variable objective.
.The log volume term in the change-of-variable objective is maximizing the very quantity (the Jacobian’s diagonal terms) that the cited work on derivative-based regularization penalties has sought to minimize.
.The maximization of the derivatives in the objective directly implies increased sensitivity to perturbations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The bijection needs to map training images to a high-density region of the Gaussian, and that aspect would make the model think twice before making the volume term too large.”
"	NOOOOOONNNNNEEEE
Section 5 is based on a 2nd order expansion on the $log p(x)$ given by a deep network -- I shouldn't be the judge of this, but from a realistic perspective this does not mean much.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We emphasize that we are not trying to approximate the density function, only approximate the difference and characterize its sign.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	".Section 5 is based on a 2nd order expansion on the $log p(x)$ given by a deep network -- I shouldn't be the judge of this, but from a realistic perspective this does not mean much.”
"	NOOOOOONNNNNEEEE
This seems to call the validity of the anomalous into question. Curious what the authors have to say about this.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This is a very good point.
.See our response to Shengyang Sun’s comment below.
.We see think this phenomenon has to do with concentration of measure and typical sets, but we do not yet have a rigorous explanation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4.  “Samples from a CIFAR model look nothing like SVHN. This seems to call the validity of the anomalous into question. Curious what the authors have to say about this.”
"	NOOOOOONNNNNEEEE
Minimization of Eq. 3 and Eq. 4 contradict each other and the objective function does not converge obviously.	MET	NOOOOOONNNNNEEEE	"We call Eq. 3 and Eq.4 adversarial, as explained in out intuition, they need not be opposite all the time.
.And we agree that the resulting model is highly affected by the setting of hyper-parameters n and k. In particular, we have compared the settings of k=1, k=2, k=3, and k=4 for each task and finally select the best overall value k=3.
.As for the number of epoch n, it depends on the usual practices of developers for an acceptable converged result.
.In our experiments, we use n=10,000 for MNIST, UbiSound and Har with batch size=128, and adopt n=20,000 for CIFAR-10 and ImageNet with batch size=256 and batch size=512, respectively.
.In fact, we have already conducted exhaustive micro-benchmark experiments to determine the current design of RAN.
.For example, we adopt different options of model architectures, nine weight updating schemes on when and what order to update Encoder, Decoder and Classifier,  and several settings of the important hyper-parameters (e.g., “n” and “k”) to select the empirically optimized one.
.However, we didn’t present the micro-benchmark results in this paper due to the space limit.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the revision, we have added more explanations on the selection of n and k in Section 2.4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Without such a guarantee, the proposed method is not very useful because we	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Algorithm 1, step 20, the covariance matrix is updated after the RL step so regardless of how the RL policies are generated, the search distribution on the next distribution includes them.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"After second thoughts, this is absolutely right.
.As the reviewer says, in both this work and Khadka & Tumer, the RL updates lead to policies that may differ a lot from the search distribution and there is no guarantee in this work that the TD3 updates result in policies close to the starting point.
"	NOOOOOONNNNNEEEE	"We corrected the paper according to this new insight.
"	NOOOOOONNNNNEEEE	"A result of these second thoughts is that one could definitely build an ERL algorithm where the evolutionary part is replaced by CEM.
.Unfortunately we did not find enough time to implement and test this algorithm during the rebuttal stage, but we now mention this possibility as an interesting avenue for future work.
"	"But if the RL actor shows good enough performance, this does not prevent from computing a new covariance matrix which includes it.
.The corresponding ellipsoid in the search space may be very large, leading to a widespread next generation, but the process should tend to converge again towards a population of actors where evolutionary and RL actors are closer to each other.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The reviewer also raises doubts about the fact that the method of Khadka & Tumer (2018) cannot be extended to use CEM.
"	NOOOOOONNNNNEEEE
In both this work, and Khadka & Tumer, the RL updates lead to policies that differ from the search distribution (indeed that is the point), and there is no guarantee in this work that the TD3 updates result in policies close to the starting point.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"After second thoughts, this is absolutely right.
.As the reviewer says, in both this work and Khadka & Tumer, the RL updates lead to policies that may differ a lot from the search distribution and there is no guarantee in this work that the TD3 updates result in policies close to the starting point.
"	NOOOOOONNNNNEEEE	"We corrected the paper according to this new insight.
"	NOOOOOONNNNNEEEE	"A result of these second thoughts is that one could definitely build an ERL algorithm where the evolutionary part is replaced by CEM.
.Unfortunately we did not find enough time to implement and test this algorithm during the rebuttal stage, but we now mention this possibility as an interesting avenue for future work.
"	"But if the RL actor shows good enough performance, this does not prevent from computing a new covariance matrix which includes it.
.The corresponding ellipsoid in the search space may be very large, leading to a widespread next generation, but the process should tend to converge again towards a population of actors where evolutionary and RL actors are closer to each other.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The reviewer also raises doubts about the fact that the method of Khadka & Tumer (2018) cannot be extended to use CEM.
"	NOOOOOONNNNNEEEE
1. Why there is still a need to combine adaptive convolutions with regular convolutions? What would the model performance be for a model with only adaptive kernels?	MET	NOOOOOONNNNNEEEE	"R)It is possible to change all the layers to use Adaptive convolutions, we replaced only one to measure the unitary contribution.
.We chose the first one because it is where the feature extraction is performed, in addition fully connected layers can use this technique.
.One Adaptive layer can replace two traditional layers.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(Added to the paper)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Why there is still a need to combine adaptive convolutions with regular convolutions? What would the model performance be for a model with only adaptive kernels?
"	NOOOOOONNNNNEEEE
1) The paper claims to want to predict unordered sets, yet the model is clearly indicating a dependence in the order of the outputs and the input p_m(\pi | x_i, w) (1); this feels like a very odd choice to me.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The assumption is what is available as GT is a set.
.This means we cannot infer any specific ordering from GT.
.The proposed framework is very flexible as we don’t need to enforce the problem to be necessarily orderless  (although it can be).
.The reason we would like to learn  p_m(\pi | x_i, w) is to infer the nature of the problem.
.However, excluding the main experiment in supplementary material, we did enforce the problem to be orderless by removing O2 and the permutation loss.
.This is equivalent to assume p_m(\pi | x_i, w) is uniform (order does not matter) in Eq.2 and you can see O2 and its loss will be eliminated from Eq. 5 and 6.
.However, we still require to solve Eq. 5 to find the best permutation based on f1 only, which is equivalent to use Hungarian to solve the assignments.
.We also disagree with R3 that the problem is either unordered sets or there exist only one order to be correct.
.There can exist multiple orders to be true, but not all.
.This can be inferred by learning p_m(\pi | x_i, w) from samples derived during training by Eq. 5.
"	NOOOOOONNNNNEEEE	"- predicting unordered sets
"	NOOOOOONNNNNEEEE
2) The paper still makes very odd choices even if one ignores the above and wants to model some orderings as more likely than others.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
3) Supposing even still that one does want a mixture model with as many components as permutations, there are still some issues.	MET	NOOOOOONNNNNEEEE	"The permutation takes into the account when there is loss and a GT to compare as GT  annotations are permutated to be assigned to the outputs.
.During inference, we don’t have loss and GT.
.We just have the predicted outputs, e.g. cardinality, states and premutation and the order which we want to show the states will not change the value of the states.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- the dependence on \pi drops out when getting a MAP estimate of outputs:
"	NOOOOOONNNNNEEEE
It is very unclear how the dependence on \pi drops out when getting a MAP estimate of outputs in section 3.3.	MET	NOOOOOONNNNNEEEE	"The permutation takes into the account when there is loss and a GT to compare as GT  annotations are permutated to be assigned to the outputs.
.During inference, we don’t have loss and GT.
.We just have the predicted outputs, e.g. cardinality, states and premutation and the order which we want to show the states will not change the value of the states.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- the dependence on \pi drops out when getting a MAP estimate of outputs:
"	NOOOOOONNNNNEEEE
Also, the paper claims that it will use a super script m to denote a known cardinality, yet omits \mathcal{Y}_i^{m_i} in the training set of the first sentence in 3.1.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is not clear why the authors neglect these classical concepts, and are talking about 'random functional perturbations', ... It is also unclear where the optimized transformation (T) lives; the authors are trying to differentiate over some function space which is undefined.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
(3) I am slightly concerned about the sample complexity of keeping track of the probability of worker i finishing goal g within t steps with a bonus b. This scales linearly in parameters which usually would be large (such as the number of time-steps).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, although the proposed method achieves good performance over various (smaller) benchmarks, the method seems ad-hoc and complicated.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A: While ReMixMatch comprises many components (some of which are new), we believe our ablation study justifies the reason why each component exists. If there are additional ablation experiments that you think would be helpful for us to run, please let us know.
"	NOOOOOONNNNNEEEE	"However, although the proposed method achieves good performance over various (smaller) benchmarks, the method seems ad-hoc and complicated.
"	NOOOOOONNNNNEEEE
1. The objective of the update equation of CTAugment’s learned weights seems contradicted with the purpose of how data augmentation is used in the consistency-based SSL method.	MET	NOOOOOONNNNNEEEE	"(We experimentally observe this fact: for example, rotation is initially only invariant up to +/- 13 degrees but throughout training becomes invariant to +/- 30 degrees.)
.We don’t aim to maximize the output variation at any instant, but instead ensure that by the end of training the model is invariant to large perturbations.
"	NOOOOOONNNNNEEEE	"A: It is true that CTAugment at any point in time will only perform augmentations that the model correctly predicts.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, we select augmentations where the probability the model output will change is less than 1.
.As such, the augmentation boundary will grow progressively as the training process converges.
"	NOOOOOONNNNNEEEE	"2. The objective of the update equation of CTAugment’s learned weights seems contradicted with the purpose of how data augmentation is used
"	NOOOOOONNNNNEEEE
It is not clear how well these methods scale, and for example using k=8 adds computation which may hinder training scalability.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The major issue I have with this paper is Theorem 3.1 on the ergodic convergence rate of the proposed PowerSGD.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We did stated both in the Theorem statements and Remark 3.4 that the a large batch size $B_t=T$ is used for the convergence proof.
.This means the effective rate of convergence is $O(1/\sqrt{T})$ as pointed out by the reviewer.
.This rate matches the currently best known rate of convergence for SGD (see, e.g. Ge et al., COLT'15).
.We have now made this very clear in both Remarks 3.3 and 3.5.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
At the first glance, it is $O(\frac{1}{T})$ which is faster than the conventional SGD convergence rate $O(\frac{1}{\sqrt{T}})$.  But after a closer look, this rate is obtained by a very strong assumption on the batch size $B_{t}=T$.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We did stated both in the Theorem statements and Remark 3.4 that the a large batch size $B_t=T$ is used for the convergence proof.
.This means the effective rate of convergence is $O(1/\sqrt{T})$ as pointed out by the reviewer.
.This rate matches the currently best known rate of convergence for SGD (see, e.g. Ge et al., COLT'15).
.We have now made this very clear in both Remarks 3.3 and 3.5.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I consider this assumption unrealistic.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This means the effective rate of convergence is $O(1/\sqrt{T})$ as pointed out by the reviewer.
.This rate matches the currently best known rate of convergence for SGD (see, e.g. Ge et al., COLT'15).
.We have now made this very clear in both Remarks 3.3 and 3.5.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
In this case, it is basically a GD, not SGD any more.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This means the effective rate of convergence is $O(1/\sqrt{T})$ as pointed out by the reviewer.
.This rate matches the currently best known rate of convergence for SGD (see, e.g. Ge et al., COLT'15).
.We have now made this very clear in both Remarks 3.3 and 3.5.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It's unclear how this would scale to more complex tasks with higher-dimensional state spaces such as Atari, Starcraft II or if this would work with tasks with continuous state and action spaces such as mujoco.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We focus on simpler domains to provide proof-of-concept results as the first step on this direction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are definitely interested in studying how our approach can be applied to more complex tasks as future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. Scalability?
"	NOOOOOONNNNNEEEE
4. The biggest flaw that I see in this method is the practicality of it's use.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
If you are able to obtain or code your own agent, then you've already solved the task and there is no need to do any sort of imitation learning in the first place.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Thus, the question is 1) how well will this method work with a human acting as the demonstrator? and 2) how can this method work if you are not able to have access to a demonstrator long periods of time (or even at all)?	MET	NOOOOOONNNNNEEEE	"We focus on improving modeling machine agents, and applying the improved agent models for multi-agent tasks.
.The current form of our approach is not designed for learning from human demonstrations.
.However, there are ways to modify our approach towards that direction: i) learning probing policy with model-based RL; ii) incorporating inductive bias from humans (e.g., the learner knows a specific set of possible goals of the demonstrator and probes the demonstrator to test which goal it has).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This seems to be a good direction for future work, but we also think that the current research has provided promising results in simpler domains, and hopefully incites more research where human demonstrators are also involved by introducing this problem to the community.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4. 1) how well will this method work with a human acting as the demonstrator? and 2) how can this method work if you are not able to have access to a demonstrator long periods of time (or even at all)?
"	NOOOOOONNNNNEEEE
To me these two reasoning statements are not particularly convincing. One could also say:	MET	NOOOOOONNNNNEEEE	"In such framework, there are many modules, each of which may correspond to one sub-task with a global optimization goal.
.The outputs of modules can serve as the inputs of other modules.
.Therefore, to train such a framework in an end-to-end way, the module should be able to propagate the errors from its outputs to its inputs.
.NN can naturally support this, as its learning algorithm is the back-propagation.
.For NN's learning, we can use Stochastic Gradient Descent (SGD) or mini-batch SGD to naturally learn from streaming data, since the NN model could be updated per data sample or per mini-batch of samples.
.However, it is not effective for tree-based model to support this as its learning needs the global statistical information.
.Using the partial statistical information may produce the sub-optimal split points and results in worse models.
.There are some works addressed this problem, like Hoeffding trees, which stores the statistical histograms into leaf nodes.
.However, most of these solutions are designed for the single decision tree.
.Although there are ensemble versions of them, most of them are based on bagging (like Random Forest), which is proven not as good as GBDT.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In contrast, tree-based models do not support this as the tree learning process is not differentiable and therefore cannot propagate the errors to its inputs.
.As stated in the Section 2, although there are some works targeting to address this problem, these solutions will lose the automatic feature selection ability and cannot work well on the tabular data.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In short, NN does not suffer from these two problems due to its mini-batch back-propagation learning process.
.In contrast, tree-based model is hard to solve these two problems due to its learning algorithm is based on global statistical information.
.Therefore, TabNN is a better general solution for tabular data.
"	NOOOOOONNNNNEEEE	"3. Two shortages of tree-based models
.Let us describe these two shortages with more details here.
.1) Hard to be integrated into complex end-to-end frameworks.
.2) Hard to learn from streaming data.
"	NOOOOOONNNNNEEEE
While I agree with this to some extent, I also think this argument may not be fully right. When the probing agent is testing the expert, it is essentially showing the imitator many different configurations of the environment.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Our main idea is to show as many configurations as possible to the learner by learning a good probing policy.
.Since the probing always starts from a single setting, there is indeed a limit in terms of how different the new settings could be.
.E.g., in Maze Navigation, it is impossible for the learner to change the room layout drastically in the time limit, so the learned policy won’t make sense in a very different room layout (e.g., 8 rooms instead of 4 rooms).
.To obtain a better generalization, we may need to use a better imitation learning approach to replace the current one (behavioral cloning), and possibly using multiple starting configurations.
.But we think that it is somewhat orthogonal to our main contribution.
.The objective of our approach is to discover more diverse settings/configurations and consequently improve whatever imitation learning approach we actually use.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"5. Generalizability argument
"	NOOOOOONNNNNEEEE
It may not be that it changes in the first time step (for obvious reasons), but it is essentially showing it many configurations of the expert.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Our main idea is to show as many configurations as possible to the learner by learning a good probing policy.
.Since the probing always starts from a single setting, there is indeed a limit in terms of how different the new settings could be.
.E.g., in Maze Navigation, it is impossible for the learner to change the room layout drastically in the time limit, so the learned policy won’t make sense in a very different room layout (e.g., 8 rooms instead of 4 rooms).
.To obtain a better generalization, we may need to use a better imitation learning approach to replace the current one (behavioral cloning), and possibly using multiple starting configurations.
.But we think that it is somewhat orthogonal to our main contribution.
.The objective of our approach is to discover more diverse settings/configurations and consequently improve whatever imitation learning approach we actually use.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"5. Generalizability argument
"	NOOOOOONNNNNEEEE
The Dual FW algorithm does not need to be used along with the hinge loss (SVM loss).	MET	NOOOOOONNNNNEEEE	"In order to compare the DFW algorithm to the strongest possible baselines, we choose the baselines to use the CE loss in the CIFAR experiments.
.Indeed we have generally found CE to help the baselines in this setting.
.In addition, the hand-designed learning rate schedule of SGD and the l2 regularization were originally tuned for CE.
.In the case of the SNLI data set, we allow the baseline to use either CE or SVM because using the hinge loss can increase their performance.
.Finally, we choose to always employ the multi-class hinge loss for DFW because it gives an optimal step-size in closed form for the dual, which is a key strength of the formulation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This should be explained in detail since Line 15 is the main output of the algorithm, which is fed (Line 16) to an existing solver for completing the assignment.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- The metrics are tightly coupled to the encoder used, and no exploration of encoder architectures is performed.	MET	NOOOOOONNNNNEEEE	"One of the key findings of our work is that task-specific information is captured succinctly for a majority of 13 different NLP tasks across 4 different choices of encoder architectures.
.1. Skip-Thought Vectors (https://arxiv.org/pdf/1506.06726.pdf)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"> We are not sure if we understand this completely.
"	NOOOOOONNNNNEEEE	"Just to clarify, we do compare 4 different sentence encoders [1][2][3][4] which display a fair amount of variety in ways which sentence representations can be computed.
.ParaNMT [2] and InferSent [3] use different LSTM based architectures to perform back-translation and textual entailment respectively.
.Lastly, SIF [4] is a tf-idf based weighted average of individual GloVe word representations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Re: no exploration of encoder architectures is performed
"	"For instance, SkipThought vectors [1] use bi-GRU based encoder-decoder model to reconstruct the surrounding sentences.
"
"Page 4: Other Connections with Lower bounds: The first line "" ""we may also consider ... "". This line is vague. How will you ensure the amount of deformation is such that the set \bar{U} is contained in U ?"	MET	NOOOOOONNNNNEEEE	"The stability bounds of B+M provide upper bounds on ||Phi(x') - Phi(x)|| (where x' is a deformation of x) based on quantities related to the corresponding diffeomorphism, i.e. the maximum norm and the maximum jacobian norm.
.For simple classes of deformations these can be computed precisely in terms of the parameters of the deformation, e.g. for translations, rotations, scaling or simple parametric warps.
.When bounding these away from zero by a certain constant, ||Phi(x') - Phi(x)|| is then included in a centered ball of the RKHS with a radius growing with this constant.
.This constant then acts as a regularization parameter, just like the size of additive perturbations in the case of adversarial perturbations, and can be tuned by cross-validation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"controlling the amount of deformations
"	NOOOOOONNNNNEEEE
It needs to be ascertained when equality holds in the bounds you propose, so that we know how tight they are. What if the bounds are too loose to be practical?	MET	NOOOOOONNNNNEEEE	"This is something that we verify empirically in our experiments at the end of training by checking the values of spectral norms as a proxy of the upper bound, and looking at the gap with the lower bound.
.In particular, when using the ||f||_M penalty, lower and upper bounds seem to be controlled together in our experiments (Figure 2), making the bound useful, in contrast to PGD, for which spectral norms grow uncontrolled when the lower bound decreases.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We will further clarify this in the paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"** tightness of the lower bounds
"	NOOOOOONNNNNEEEE
This implies that the amount of work (in FLOPs) done by the algorithm (at least the version being analyzed) is quadratic in T, which makes the convergence rates a bit misleading.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
But a very similar assumption is hidden in the bounded-gradient-variance assumption Assumption 3.2; for example, Assumption 3.2 is clearly not satisfied by the least-squares regression problem	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The empirical comparisons to UNIT are reasonably thorough, though I would have preferred more in-depth evaluation of the MoVE model as well.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree and this was also pointed by 'AnonReviewer2', we are working on new incremental benchmarks, more detailed on both one-to-one and many-to-many models.
.Hence we trained models without conditioning mechanism and, as answered to 'AnonReviewer2', we are planning experiments on models which are conditional but integrating an unconditioned state to be trained in parallel of the note-conditional state.
"	NOOOOOONNNNNEEEE	"Moreover, the need of pitch/octave conditioning limits the applicability of our model to transfer only on audio carrying such note features.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* In-depth evaluation of MoVE and comparison of with/without conditioning:
"	NOOOOOONNNNNEEEE
However, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer).	MET	NOOOOOONNNNNEEEE	"We gave references to the papers that introduced such metrics.
.Discussing a set of reference scores should also come with a better explanation of these.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* Incomplete definition of the metrics:
"	NOOOOOONNNNNEEEE
Do people leave the negations in when modifying such examples for entailment or neutrality, thus breaking the simple correspondence?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"These include updating the draft to include (i) a detailed analysis of edits performed on SNLI, (ii) results on various datasets using an ELMo based classifier; (iii) concerning your question about larger Bi-LSTMs, we had tried a large Bi-LSTM but it overfit badly.
.We have updated the draft to include this detail.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It would be easy to use ELMo here, if the main question is about Transformers vs recurrent models.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"These include updating the draft to include (i) a detailed analysis of edits performed on SNLI, (ii) results on various datasets using an ELMo based classifier; (iii) concerning your question about larger Bi-LSTMs, we had tried a large Bi-LSTM but it overfit badly.
.We have updated the draft to include this detail.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I believe the proposed techniques have some flaws which hurt the eventual method.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
My concern is that the flaws in the method do not make it conducive to use as is.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- (W1) Adversely affected by rotations: One of my big concerns with the work is the way the CFS is computed.	MET	NOOOOOONNNNNEEEE	"Re: (W1 & W2) Adversely affected by rotations
.While the CFS is not invariant to rotations, it is a surprising, and empirically noteworthy, finding that all 4 different ways of producing representations consistently encode a dozen tasks very succinctly.
.This is in line with some early work that observed that certain characteristic properties like length [1][2], sentiment [3], presence/absence of brackets [4] are encoded in a single dimension in the space.
.Some of these findings can be attributed to the additive property of the cell state of the LSTMs c_t = f_t c_{t-1} + h_t {c’}_{t}, which is free from matrix rotations.
.As previously noted, this empirically also results in single cells of the LSTM being interpretable.
.To just give one example, LSTM cell state can increment by a fixed amount at every time step and can count the number of tokens reliably (i.e the string length) [1][4].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This again greatly concerned me as I am not certain how stable these metrics are.	MET	NOOOOOONNNNNEEEE	"Re: (W1 & W2) Adversely affected by rotations
.While the CFS is not invariant to rotations, it is a surprising, and empirically noteworthy, finding that all 4 different ways of producing representations consistently encode a dozen tasks very succinctly.
.This is in line with some early work that observed that certain characteristic properties like length [1][2], sentiment [3], presence/absence of brackets [4] are encoded in a single dimension in the space.
.Some of these findings can be attributed to the additive property of the cell state of the LSTMs c_t = f_t c_{t-1} + h_t {c’}_{t}, which is free from matrix rotations.
.As previously noted, this empirically also results in single cells of the LSTM being interpretable.
.To just give one example, LSTM cell state can increment by a fixed amount at every time step and can count the number of tokens reliably (i.e the string length) [1][4].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Based on my understanding the authors rank (which itself is questionable) the different tasks in order of potential for transfer and then call this the ""gold"" set. How is precision and NDCG calculated from this?"	MET	NOOOOOONNNNNEEEE	"Re: (W4) Metrics for ranking of transfer don't make sense (and some are missing).
.How is precision and NDCG calculated
.> To compute the gold set, we first train a neural network for each of the candidate tasks and then use the pre-trained sentence encoder (part of the network) from the candidate task to fine-tune on the target task.
.The ranked list (in the decreasing utility of transfer learning gain) is then considered the ‘gold’ set.
.We further compare our recommendations of candidate tasks generated using CFS and classifier weight difference methods against the gold ranked list.
.Precision@K, Reciprocal Rank and NDCG are among the popular information retrieval metrics to compare a recommended list against a gold ranked list.
.These metrics are meaningful in our case, for instance, Reciprocal Rank tells us how many tasks we need to consider as per our recommendation before we hit the highest performing candidate task.
.Figure 3 presents the accuracy boost using the best task till now in the produced recommendations for the candidate tasks using different methods.
.Regarding missing values:
.As we explain in the paper, classifier weight difference metric is only applicable in cases
.where the number of features between the tasks are of the same size.
.Thus, 2 sentence input tasks and 1 sentence input tasks cannot be compared using the metric.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The proposed  CLF weight difference method has some concerning aspects as well.	MET	NOOOOOONNNNNEEEE	"Re: (W8) The proposed  CLF weight difference method has some concerning aspects as well. For example say we had two task with exact opposite labels.
"	NOOOOOONNNNNEEEE	"They would have a very low weight difference score though they are ideal representations for each other
.> You are right. For the very same reason, we take the inverse of the difference of normalized absolute classifier weights (Section 4.2).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Likewise looking at a difference of weight vectors seems arbitrary in other ways as well.	MET	NOOOOOONNNNNEEEE	"Re: (W8) The proposed  CLF weight difference method has some concerning aspects as well. For example say we had two task with exact opposite labels.
"	NOOOOOONNNNNEEEE	"They would have a very low weight difference score though they are ideal representations for each other
.> You are right. For the very same reason, we take the inverse of the difference of normalized absolute classifier weights (Section 4.2).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Thus the metric is not a proper metric.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
As for GAN, due to the inexact update, it is not really solving the min-max problem.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This discrepancy exists for GANs, but it is a bigger issue for the duality gap interpretation.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The paper tries to control for it, however that description is rather short and vague (not clear how the proposed reward is computed without there being a grid, or how is the grid useful without the intrinsic reward).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"Mapping techniques from ""non-directional"" problems (where the action space is not a direction) and then projeting on the sphere is sub-optimal (the variance is too big)."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The question is, why one would exlude the mixture-of-softmax approach here?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It remains somewhat unclear, why this bigram-centered regularization would strongly contribute for prediction in general.	MET	NOOOOOONNNNNEEEE	"We can justify PDR theoretically as an inductive bias on the language model.
.The observed bigrams in a language are not random and the distribution of the second word given the first word in a bigram is not uniform.
.Similarly, the distribution of the first word given the second word will be far from uniform.
.A RNN based language model models the first dependence (and more long range ones) and our proposed PDR tries to model the second one.
.In a unidirectional language model, we cannot look into the future tokens and hence we use the output distribution as a proxy for the ""true second word"" and decode the distribution of the first word.
.Thus the PDR term can be thought of as biasing the language model to retain more information about the distribution of the first word given the second word in a bigram.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.	MET	NOOOOOONNNNNEEEE	"Specifically,  we use a 2-layer LSTM with hidden dimension 1024 and a word embedding dimension of 1024.
.We truncated the vocabulary by keeping approximately 100k words with the highest frequency and used the same validation and test sets as (Yang et al. 2017).
.We obtained a valid/test perplexity of 44.0/42.5 for the model with PDR and 44.3/43.1 for the model without PDR, showing a gain of 0.6 points in the test perplexity.
.Note that we tuned the PDR loss coefficient very coarsely and tuning it further could lead to higher gains.
"	"We will update the manuscript with these additional results and discussion and post it shortly.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
A more general function is	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> We respectfully disagree.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“A more general function is $P(X)_i=Ax_i+\sum_{j\in N(x_i,X)} B(x_j,x_i) x_j + c$, where $N(x_n,X)$ is the set of index of neighbors within the set… Then, can the function family the authors used in the paper approximate this function?
.No.“
"	NOOOOOONNNNNEEEE
Then, can the function family the authors used in the paper approximate this function?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are happy to include a discussion about this in the revised paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> We respectfully disagree.
.Reiterating the main result of this paper: *Every* continuous equivariant function defined solely on a set of feature vectors can be approximated with PointnetST over a compact domain.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- what is the benefit brought by the 'Structural Knowledge' transfer? is this quantified anywhere? based on the description, I don't understand if this is an add-on to TabNN or whether it is incorporated in TabNN.	MET	NOOOOOONNNNNEEEE	"We had compared the benefit brought by the 'Structural Knowledge' in the experiment.
.The difference between TabNN (S) and TabNN (R), as shown in Table 3, implies that that the structural knowledge from GBDT yields a large contribution to the performance of TabNN.
"	"The ""Structural Knowledge"" is in TabNN by default. We will clarify this in the paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"4. Benefits brought by the ""Structural Knowledge""
"	NOOOOOONNNNNEEEE
I don't really understand how learning lambda would _guarantee_ that the optimization will converge to a better solution.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing out this.
"	NOOOOOONNNNNEEEE	"We have adjusted the word.
"	NOOOOOONNNNNEEEE	"A theoretical analysis will be an interesting future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q1. The use of the word “guarantees” is imprecise:
"	NOOOOOONNNNNEEEE
-In k-means clustering (E-step and M-step), is it correct to multiply \tilde x to (c-v)?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Using \tilde x in the E- and M-steps.
"	NOOOOOONNNNNEEEE
I think that the error arising from quantizing v into c is only affected by a subset of rows of \tilde x. For example, if v is the first subvector of w_j, then I think that only 1-st, m+1-th, 2m+1-th, … rows of \tilde x affect to the error.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree with Reviewer 3 that “the error arising from quantizing v into c is only affected by a subset of rows of \tilde x”.
.However, we solve Equation (2) with this proxy algorithm for two reasons.
.First, using the full \tilde x matrix allows to factor the computation of the pseudo-inverse of \tilde x and thus allows for a much faster algorithm, see answer to Reviewer 2 and the details of the M-step in the paper (as well as footnote 2).
.Second, early (and slow) experiments suggested that the gains were not significant when using the right subsets of \tilde x in this particular context.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Given its limitation to small and low-dimensional environments, it cannot be said how well the approach will scale with respect to these factors and the resulting, more complex agent behaviours.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"While we agree that the tasks in this paper are not real world problems, we think, as a first step towards this direction, the evaluations in this paper have provided some promising proof-of-concept results. Applying the approach to more realistic and more complex tasks could be a good future research direction.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Scalability?
"	NOOOOOONNNNNEEEE
Overall, while the agent behaviour modelling focused on a type of inner state (based on past trajectories) provides benefits in the evaluated examples, it is unsure how well the approach scales to more complex domains based on strong similarity and simplicity of the tested toy scenarios (evaluation on sorting problems is an interesting step towards to address this shortcoming).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
* the ablation study designed to compare with a Gauss-Newton-like approach does not seem correct.	MET	NOOOOOONNNNNEEEE	"In Table 4 of the revised version (Appendix B), our method outperforms the Gauss-Newton algorithm in the last column.
.This is because the objective function to be optimized is non-convex, and the vanilla Gauss-Newton method might get stuck at saddle point or local minimum.
.This is why the Levenberg-Marquardt algorithm is the standard choice for conventional bundle adjustment.
.In Figure 6 of the revised version (Appendix B), our method also consistently performs better than different constant lambda values.
.This is because the value of lambda should be adapted to different data and optimization iterations.
.There is no ‘optimal’ constant lambda for all data and iterations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Secondly, we agree with the reviewer that comparing with the Gauss-Newton algorithm will be interesting and have updated such a comparison in Appendix B in the revised version according to the reviewer’s suggestions:
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We thank the reviewer for the comments and appreciate that the reviewer likes our idea of including optimization in the network. But our contribution is beyond adopting Levenberg-Marquardt instead of Gauss-Newton.
"	NOOOOOONNNNNEEEE	"Firstly, we want to clarify that our contribution is beyond improving the Gauss-Newton optimization to Levenberg-Marquardt.
.More importantly, our contribution is the combination of conventional multi-view geometry (i.e. joint optimization of depth and camera poses) and end-to-end deep learning (I.e. depth basis generator learning and feature learning).
.This contribution is achieved by our differentiable LM optimization that allows end-to-end training.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We retrained the whole pipeline with Gauss-Newton, to make sure the features are learned specifically for Gauss-Newton.
.2. We compared with various constant lambda values to see how the performance varies along with lambda.
.Note that we also fine-tune the network to make sure the features fit different lambda.
"
- for GN optimization, lambda should be set to 0 - not a constant value.	MET	NOOOOOONNNNNEEEE	"In Table 4 of the revised version (Appendix B), our method outperforms the Gauss-Newton algorithm in the last column.
.This is because the objective function to be optimized is non-convex, and the vanilla Gauss-Newton method might get stuck at saddle point or local minimum.
.This is why the Levenberg-Marquardt algorithm is the standard choice for conventional bundle adjustment.
.In Figure 6 of the revised version (Appendix B), our method also consistently performs better than different constant lambda values.
.This is because the value of lambda should be adapted to different data and optimization iterations.
.There is no ‘optimal’ constant lambda for all data and iterations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Secondly, we agree with the reviewer that comparing with the Gauss-Newton algorithm will be interesting and have updated such a comparison in Appendix B in the revised version according to the reviewer’s suggestions:
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We thank the reviewer for the comments and appreciate that the reviewer likes our idea of including optimization in the network. But our contribution is beyond adopting Levenberg-Marquardt instead of Gauss-Newton.
"	NOOOOOONNNNNEEEE	"Firstly, we want to clarify that our contribution is beyond improving the Gauss-Newton optimization to Levenberg-Marquardt.
.More importantly, our contribution is the combination of conventional multi-view geometry (i.e. joint optimization of depth and camera poses) and end-to-end deep learning (I.e. depth basis generator learning and feature learning).
.This contribution is achieved by our differentiable LM optimization that allows end-to-end training.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We retrained the whole pipeline with Gauss-Newton, to make sure the features are learned specifically for Gauss-Newton.
.2. We compared with various constant lambda values to see how the performance varies along with lambda.
.Note that we also fine-tune the network to make sure the features fit different lambda.
"
- the image features should be re-trained for the GN framework:  Since the features are learned for the LM iteration, they are adapted to the use of the predicted lambda, but they are not necessarily suitable to GN optimization.	MET	NOOOOOONNNNNEEEE	"In Table 4 of the revised version (Appendix B), our method outperforms the Gauss-Newton algorithm in the last column.
.This is because the objective function to be optimized is non-convex, and the vanilla Gauss-Newton method might get stuck at saddle point or local minimum.
.This is why the Levenberg-Marquardt algorithm is the standard choice for conventional bundle adjustment.
.In Figure 6 of the revised version (Appendix B), our method also consistently performs better than different constant lambda values.
.This is because the value of lambda should be adapted to different data and optimization iterations.
.There is no ‘optimal’ constant lambda for all data and iterations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Secondly, we agree with the reviewer that comparing with the Gauss-Newton algorithm will be interesting and have updated such a comparison in Appendix B in the revised version according to the reviewer’s suggestions:
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We thank the reviewer for the comments and appreciate that the reviewer likes our idea of including optimization in the network. But our contribution is beyond adopting Levenberg-Marquardt instead of Gauss-Newton.
"	NOOOOOONNNNNEEEE	"Firstly, we want to clarify that our contribution is beyond improving the Gauss-Newton optimization to Levenberg-Marquardt.
.More importantly, our contribution is the combination of conventional multi-view geometry (i.e. joint optimization of depth and camera poses) and end-to-end deep learning (I.e. depth basis generator learning and feature learning).
.This contribution is achieved by our differentiable LM optimization that allows end-to-end training.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We retrained the whole pipeline with Gauss-Newton, to make sure the features are learned specifically for Gauss-Newton.
.2. We compared with various constant lambda values to see how the performance varies along with lambda.
.Note that we also fine-tune the network to make sure the features fit different lambda.
"
Thus, the advantage of using a LM optimization scheme is not very convincing.	MET	NOOOOOONNNNNEEEE	"In Table 4 of the revised version (Appendix B), our method outperforms the Gauss-Newton algorithm in the last column.
.This is because the objective function to be optimized is non-convex, and the vanilla Gauss-Newton method might get stuck at saddle point or local minimum.
.This is why the Levenberg-Marquardt algorithm is the standard choice for conventional bundle adjustment.
.In Figure 6 of the revised version (Appendix B), our method also consistently performs better than different constant lambda values.
.This is because the value of lambda should be adapted to different data and optimization iterations.
.There is no ‘optimal’ constant lambda for all data and iterations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Secondly, we agree with the reviewer that comparing with the Gauss-Newton algorithm will be interesting and have updated such a comparison in Appendix B in the revised version according to the reviewer’s suggestions:
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We thank the reviewer for the comments and appreciate that the reviewer likes our idea of including optimization in the network. But our contribution is beyond adopting Levenberg-Marquardt instead of Gauss-Newton.
"	NOOOOOONNNNNEEEE	"Firstly, we want to clarify that our contribution is beyond improving the Gauss-Newton optimization to Levenberg-Marquardt.
.More importantly, our contribution is the combination of conventional multi-view geometry (i.e. joint optimization of depth and camera poses) and end-to-end deep learning (I.e. depth basis generator learning and feature learning).
.This contribution is achieved by our differentiable LM optimization that allows end-to-end training.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. We retrained the whole pipeline with Gauss-Newton, to make sure the features are learned specifically for Gauss-Newton.
.2. We compared with various constant lambda values to see how the performance varies along with lambda.
.Note that we also fine-tune the network to make sure the features fit different lambda.
"
- the state vector Chi is not defined for the proposed method, only for the standard bundle adjustment approach. If I understand correctly is made of the camera poses.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The Chi is defined in Section 3 as the vector containing all camera poses and point depths.
.Since our method also solves for these unknowns as in classic methods, we did not redefine the Chi.
.But in the revised version we have recapped the definition of Chi when introducing our method at the beginning of Section 4.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q3. The state vector Chi is not defined for the proposed method.
"	NOOOOOONNNNNEEEE
- the name 'Bundle Adjustment' is actually not adapted to the proposed method.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The term ‘Bundle Adjustment’ is originally used to refer to the joint optimization of 3D scene points and camera poses by minimizing the reprojection error.
.The keyword Bundle comes from the fact that a bundle of camera view rays pass through each of the 3D scene points.
.Multiple recent works, e.g. [Engel et al., 2017,Delaunoy and Pollefeys, 2014], have generalized it to “photometric BA” where scene points and camera poses are optimized together by minimizing the photometric error.
.Our method is along this line.
.But we further improve the photometric error to featuremetric error.
.Each 3D scene point is still constrained by a bundle of camera view rays, though the error function has been changed.
.So we believe it is justified to call this method feature-metric BA.
"	NOOOOOONNNNNEEEE	"Q4. Should the paper be called Bundle Adjustment?:
"	NOOOOOONNNNNEEEE
Eq (2) cannot have Delta Chi on the two sides.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed all the typos as suggested in the revised version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q6.Typos:
"	NOOOOOONNNNNEEEE
before Eq (3): the 'photometric ..' -> a 'photometric ..'	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have fixed all the typos as suggested in the revised version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q6.Typos:
"	NOOOOOONNNNNEEEE
But there are some minus ones in the random projection?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However in the approach proposed here, the negative examples are missing.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(we give related discussion in section 3.1 and add much more experimental results in Figure 5, further details please see the revised paper.)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A: In each iteration, only a small subset of information sets are sampled, which may lead to the neural networks forgetting values for those unobserved information sets.
.To avoid such catastrophic forgetting, we used the neural network parameters from previous iterations as initialization, which gives an online learning/adaptation to the update.
.Furthermore, due to the generalization ability of the neural networks, even samples from a small number of information sets are used to update the new neural networks, we find that the newly updated neural networks can produce very good value for the cumulative regret and the strategy mixture.
"	NOOOOOONNNNNEEEE	"Q1: the feasibility of using neural networks to learn cumulative quantities:
"	NOOOOOONNNNNEEEE
So there is no guarantee this algorithm will minimise the overall regret.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(we give related discussion in section 3.1 and add much more experimental results in Figure 5, further details please see the revised paper.)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A: In each iteration, only a small subset of information sets are sampled, which may lead to the neural networks forgetting values for those unobserved information sets.
.To avoid such catastrophic forgetting, we used the neural network parameters from previous iterations as initialization, which gives an online learning/adaptation to the update.
.Furthermore, due to the generalization ability of the neural networks, even samples from a small number of information sets are used to update the new neural networks, we find that the newly updated neural networks can produce very good value for the cumulative regret and the strategy mixture.
"	NOOOOOONNNNNEEEE	"Q1: the feasibility of using neural networks to learn cumulative quantities:
"	NOOOOOONNNNNEEEE
- It does not seem necessary to predict cumulative mixture policies (ASN network).	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A: As you say, any information nodes I_i would be sampled proportionally to \pi^{\sigma^t}_i(I_i), which is the same probability as in the definition of the mixture policy (Eq.4).
.Actually, if we have a large enough buffer to save all the sampled nodes, it’s easy to inference the mixture policy accordingly.
.Another method called reservoir sampling was used in NSFP to address a similar problem.
.We borrow this idea to our method, however, the achieved mixture policy cannot converge to a low exploitability.
.Actually, the third possible solution could employ the checkpoint of each current strategy, and mixture this current strategy accordingly.
"	NOOOOOONNNNNEEEE	"Q2: It does not seem necessary to predict cumulative mixture policies (ASN network)?
"	NOOOOOONNNNNEEEE
Since you assume the number of information nodes is large, you cannot minimize the l2 loss over all states. Do you assume you generate states by following some policy? Which policy?	MET	NOOOOOONNNNNEEEE	"A: Generally, Eq.10 is an idea of behavior cloning algorithm.
.Clone a good initialization, and then continuously update the two neural networks using our method.
.In the large extensive game, the initial strategy is obtained from an abstracted game which has a manageable number of information sets.
.The abstracted game is generated by domain knowledge, such as clustering similar hand strength cards into the  same buckets.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(refer to section 3.3 in the revised paper.)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Since you assume the number of information nodes is large, you cannot minimize the l2 loss over all states. Do you assume you generate states by following some policy? Which policy?
"	NOOOOOONNNNNEEEE
* The fact that the model makes use of pitch class and octave labels also raises questions about applicability -- if I understood correctly, transfer can only be done when this information is present.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"If the audio carries a note information, it can be easily/automatically extracted in the form of pitch tracks as we did for transferring on instrument solos.
.Some audio data do not have note qualities, which are out of the current training setting.
.For that we have been training unconditioned one-to-one models or solely instrument conditional many-to-many models that do not require any note information.
"	NOOOOOONNNNNEEEE	"* Not suited to transfer from audio without label:
"	"But we are working on models which incorporate an unconditioned processing option (eg. training while zeroing the one-hot conditioning or adding an entry in the input embedding of FiLM which is the unconditional state) to be trained on a dataset that mixes conditional and non conditional audio (eg. adding instrument solo sections which in parts have a clear pitch track and in others none).
"
I think the main point of transfer over a regular generative model that goes from labels to audio is precisely that it can be done without label information.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
* The use of fully connected layers also implies that it requires fixed length input, so windowing and stitching are necessary for it to be applied to recordings of arbitrary length. Why not train a convolutional model instead?	MET	NOOOOOONNNNNEEEE	"We use the linear layers to set the latent space dimensionality, when processing various length audio sequences, each encoding amounts to about 120ms context and we resynthesize with overlap-ad that mirrors the short-term input analysis ; this process was used when transferring on the instrument solos (a task that was beyond the training setting).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* A fully convolutional model would process arbitrary length of audio:
"	NOOOOOONNNNNEEEE
* I think the choice of a 3-dimensional latent space is poorly justified. Why not use more dimensions and project them down to 3 for visualisation and interpetation purposes with e.g. PCA or t-SNE?	MET	NOOOOOONNNNNEEEE	"At first we validated that our models could perform well in term of training/test spectrogram reconstructions with only 3 latent dimensions, some reasons that we found interesting to enforce this are more related to a possible music/creative application of the model: less synthesis/control parameters for the user (and controls which may then be more expressive), direct visualization of the latent space which is turned into a 3D synthesis space from which users may draw and decode sound paths or create other interaction schemes, a denser latent space that may be better suited for random sampling/interpolations.
.The direct interaction with 3D latent space becomes even more interesting when we pipeline our model with fast-spectrogram inversion.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"* Insufficient justification of the 3D latent space:
"	NOOOOOONNNNNEEEE
"* I found the description in Section 3.1 a bit confusing as it initially seems that the approach requires paired data (e.g. ""matching samples"")."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The only problem I see is that phrase similarity part is not convincing.	MET	NOOOOOONNNNNEEEE	"Phrase similarity results: the tensor component T(v_a,v_b,.) does yield improvement over all other weighted additive methods in 5 out of 6 cases, as shown in Table 3.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have also updated that table with additional results, which show that adding in the tensor component improves upon the strong baseline of the SIF embedding method.
.We also added Table 4, which repeats the phrase-similarity task for verb-object pairs, and shows that the tensor component leads to improvement in most cases.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is not clear that the notion of similarity through classifier weights makes sense, but see below for clarification questions.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Although they show that the Ski Rental problem can also be learned to solve though it is trivial and does not even use the framework the authors propose in its full extent, ie. problem instances are not generated by use of a machine learning model, which is one of main claims the authors are making.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The point of this work is only to see if ML can find optimal algorithms, and not about doing it faster than the known theoretical algorithms.
.Note that this is not similar to the case of solving an offline combinatorial problem via integer programming or other solvers, since our problems are online, i.e., the instance is not known beforehand, so there is no comparison to such “general-purpose” solvers.
.Thus we don't compare to the running time of offline solvers, but to the worst-case competitive ratio of the optimal online algorithms.
.Again drawing the analogy of playing Go, the objective is mostly on training an agent that can make competitive moves rather than very fast moves, and there is no known “general-purpose” strategy to accomplish this.
.*Please also see reply to reviewer #2 on a similar question of evaluating against other methods*
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-- Comment on scale / speed for large instances of combinatorial optimization:
.-- “Ski Rental problem can also be learned to solve though it is trivial and does not even use the framework the authors propose in its full extent, i.e. problem instances are not generated by use of a machine learning model, which is one of the main claims the authors are making.”
.Please see our high-level clarification on top.
"	NOOOOOONNNNNEEEE
The authors claim that the Arora's RAND-WALK model does not capture any syntactic information.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
That is, the current design hasn't well considered the local and global stability relation, but just simply sum them up.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Could you please elaborate on the comment ’the current design […] simply sums them up’?
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2)
"	"The stethoscope module has its own trainable parameters and a separate loss function.
.Only the encoder shares weights between main and secondary task.
"
I think it is misleading to call it a convolution, as (a) it is not a convolution mathematically, and (b) fast convolution techniques (Fourier, Winograd) cannot be applied, so claims to greater efficiency may be misleading.	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R)We believe as future work our algorithm can be combined with Winograd techniques for optimization.
.For instance winograd is designed to use a batch of images to convolve with a kernel, here an image convolves with a “batch of kernels”.
.There is no reason why those two techniques can be merged.
.In our implementation we perform a set of convolutions with the input image where FFT can be applied too.
"	NOOOOOONNNNNEEEE	"I think it is misleading to call it a convolution, as (a) it is not a convolution mathematically, and (b) fast convolution techniques (Fourier, Winograd) cannot be applied, so claims to greater efficiency may be misleading.
"	NOOOOOONNNNNEEEE
In (2) is (N+1)x(N+1) the kernel size (sums are over 0,1,...,N?)??	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Very good Catch
"	NOOOOOONNNNNEEEE	"it should be (N)x(N) instead of (N+1)x(N+1). (Fixed on the paper)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In (2) is (N+1)x(N+1) the kernel size (sums are over 0,1,...,N?)??
"	NOOOOOONNNNNEEEE
Is the output of the first convolution a single HxW feature planes, or a HxWx(N+1)x(N+1) tensor?	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Very good Catch
"	NOOOOOONNNNNEEEE	"it should be (N)x(N) instead of (N+1)x(N+1). (Fixed on the paper)
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Is the output of the first convolution a single HxW feature planes, or a HxWx(N+1)x(N+1) tensor?
"	NOOOOOONNNNNEEEE
x is already present within the indicator, no need to add yet	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In retrospect, we agree that this was confusing and have removed the [x] notation from the indicator function.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"x is already present within the indicator, no need to add yet
"	NOOOOOONNNNNEEEE
However, hyperparameter searching is not extending any ML technique, it is just an approach to find a good training configuration and show robustness in different hyperparameters settings.	MET	NOOOOOONNNNNEEEE	"The networks we used in this work are fairly simple: dense layers with standard ReLu activation, and we use standard Adam optimizer.
.Simply choosing commonly recommended values for the parameters turn out to work well for the problems we looked at.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In general, we agree with the reviewer’s point that hyperparameter searching can be important.
.For this particular work, our focus is to introduce the high-level ideas/framework and offer initial evidence that it can be effective, so we do not dwell much on the technical parts of ML in our discussion due to page limits.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also clarify that it is not the case that “we have no interests in extending ML techniques” in general.
.Indeed, we believe that for the future success of our approach on more open problems in online algorithms, it very much relies on the advances of ML in terms of neural network structure, optimization algorithms and training techniques.
.We also hope our work can motivate the design of new tools/techniques tailored for this direction.
"	NOOOOOONNNNNEEEE	"** Addressing Technical Comments:
.-- “hyperparameter searching”:
"	NOOOOOONNNNNEEEE
It is thus unclear if the approach is robust against different hyperparameter settings.	MET	NOOOOOONNNNNEEEE	"The networks we used in this work are fairly simple: dense layers with standard ReLu activation, and we use standard Adam optimizer.
.Simply choosing commonly recommended values for the parameters turn out to work well for the problems we looked at.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In general, we agree with the reviewer’s point that hyperparameter searching can be important.
.For this particular work, our focus is to introduce the high-level ideas/framework and offer initial evidence that it can be effective, so we do not dwell much on the technical parts of ML in our discussion due to page limits.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We also clarify that it is not the case that “we have no interests in extending ML techniques” in general.
.Indeed, we believe that for the future success of our approach on more open problems in online algorithms, it very much relies on the advances of ML in terms of neural network structure, optimization algorithms and training techniques.
.We also hope our work can motivate the design of new tools/techniques tailored for this direction.
"	NOOOOOONNNNNEEEE	"** Addressing Technical Comments:
.-- “hyperparameter searching”:
"	NOOOOOONNNNNEEEE
"- I think the authors want to make an explicit connection to counterfactuals as understood in the causality community. Then they shy away from it saying they are inspired by it. May be a formal exposition in the supplement about counterfactuals and generating mechanisms could help readers from other communities (NLP) even it means repeating standard/synthetic examples. Its good to say what exactly in a counterfactual generation process, the ""people"" in amazon turk were substituting."	MET	NOOOOOONNNNNEEEE	"Indeed, many other words, including “will”, “my”, “has”, “especially”, “life”, “works”, “both”, “it”, “its”, “lives”, “gives”, “own”, “jesus”, “cannot”, “even”, “instead”, “minutes”, “your”, “effort”, “script”, “seems”, and “something”, appear to be spuriously associated with sentiment and are captured by the original-only and revised-only classifiers as highly-weighted features.
., Notably all of these features fall out from the highly-weighted features when our classifier is trained on counterfactually-augmented data.
"	"We agree that a formal exposition introducing an NLP/deep learning audience to the basics of interventions and counterfactuals and expressing a toy DAG to explain the spurious associations between the review sentiment and the manifestation in text of other attributes of the review, including but not limited to the genre, actors, budget, etc. We are actively working on preparing this exposition and while it is not yet in the draft we plan to have it prepared in advance of the camera-ready version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. I found the argument about FID in section 2.1 unconvincing. Are there proofs or citations for the claim that real images don't follow multivariate gaussian distribution after applying FID? Copying is indeed an issue that FID cannot detect, but it may be tangential to model collapse for real world concerns like privacy.	MET	NOOOOOONNNNNEEEE	"There is a recently published survey paper that can back our claim. It is [Ali Borji, ""Pros and Cons of GAN Evaluation Measures"" (Arxiv 18)]
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Proof or citation for the flaws of FID
"	NOOOOOONNNNNEEEE
"2. The statement ""IS, FID and MODE score takes both visual fidelity and diversity into account."" under ""Evaluation of Mode Collapse"" is contradictory to the description in sec 2.1 that IS in fact does not measure diversity."	MET	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We use the word ""loss of diversity"" since IS's measuring of diversity is limited.
.E.g., on ImageNet with 1000 classes, it can not rule out the case when then generator simply repeating the same image for each different class.
"	NOOOOOONNNNNEEEE	"2. The contradiction between the two statements
"	NOOOOOONNNNNEEEE
Even though the authors answer positively to each of their four questions in the experiments section	EXP	NOOOOOONNNNNEEEE	"One of the limitation we see from NADPEx is that dropout policies are not directly interpretable from their network structures, while interpretability and composibility are prerequisites for reusing them in more complicated tasks.
.Luckily, modeled as latent random variables, an information term could be added to the objective as in [1, 2].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"This is also a direction for future research work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Though not explained in Section 4.
.The intuition for NADPEx is given in Section 3.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1) Intuition about the improvement
.2) Limitation of NADPEx
"	"Interpretation for as efficient or even faster exploration in dense environment (4.1) is that NADPEx could encourage more diverse exploration, while absorb experience from it in a relatively efficient way.
.For sparse environments (4.2), where temporally consistent exploration is crucial for learning signal acquisition, NADPEx outperforms vanilla PPO.
.It could also beat parameter noise if difficulty is increased, because intuitively low variance in gradients is a boon for faster learning.
.Improvement in 4.3 and 4.4 are basically from the theoretical grounding of NADPEx, which we believe is one of our contributions.
.Specifically, improvement in 4.3 is from high level stochasticity's adaptation to the low level; while that in 4.4 could be interpreted with the idea of trust region, that policy should be updated to somewhere near the sampling policy in the policy space, such that collected experience are usable (on-policy).
.In NADPEx, trust region also contains the meaning that dropout policies are close to each other for more efficient exploration.
"
However, I don’t know how effective this is in practice.	EXP	NOOOOOONNNNNEEEE	"We conduct experiments with decoder p(x|z, m) conditioned on the original mask in training set, and observe comparable performance and convergence time.
.The mask distribution might be easier to learn as compared to data distribution (since the mask is fully-observed)
..
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"However, we argue that jointly learning the mask distribution and data distribution provides us an opportunity to further analyze the missing mechanism and potentially can facilitate other down-stream tasks.
"	NOOOOOONNNNNEEEE	"(2) Conditioning on Ground-Truth Mask:
"	NOOOOOONNNNNEEEE
Also, the title of the paper is about problem retrieval but the experiments are about similarity comparison, there seems a gap.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1- There are two reasons that concept and problem embedding are performed in this work.
.Considering concept continuity is an important matter in education.
.Having concept embedding, concept continuity can be reached as is discussed in the last paragraph on page 7 and some other examples are given in table 2.
.By just having the most sophisticated concept extractor, the concept continuity cannot be retrieved.
.Furthermore, problem embedding is used by the recommender system to project the performance of students on the problems they solved onto other problems that they have not solved.
.This way, we have an idea of what problems should be recommended to them and which problems should not by having an evaluation of their ability to solve unseen problems and recommend problems in the boundary of their capacity, not way beyond, and to recommend problems in a way that covers all concepts necessary for students to learn.
.We have observed interesting patterns, e.g. similar problems are more likely to be solved correctly at the same time or wrong at the same time.
.Note that by just having the concepts of problems that are not in numerical form, performance projection may not be feasible and there is a need for using other methods like embedding.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The negation example is nice but this doesn't seem to display the potential power of the method to understand a neural network.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
3) The overall performance of the proposed SST in the experiments is not convincing and not promising.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A : As mentioned in our paper, SST has comparable performance to other conventional SSL algorithms.
.In Table 2 of our paper, SST achieves 34.89% on CIFAR-100, which is higher than TempEns[1](38.65%), 11.82% on CIFAR-10, which is slightly worse than VAT+EntMin[2](10.55%), and perform worse 6.88% on SVHN.
.However, SST can solve the real problem of the existence of out-of-class unlabeled data.
.[1] Laine, Samuli, and Timo Aila. ""Temporal ensembling for semi-supervised learning."" arXiv preprint arXiv:1610.02242 (2016).
.[2] Miyato, Takeru, et al. ""Virtual Adversarial Training: a Regularization Method for Supervised and Semi-supervised Learning."" arXiv preprint arXiv:1704.03976 (2017).
.Remark 4. ""Combining SST with other existing techniques can help.
.However, the additional cost is expensive.
.Further demonstrations are necessary for the proposed SST method.""
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Remark 3. ""SST itself is only comparable with or even worse than the state-of-art methods.""
"	NOOOOOONNNNNEEEE
However, all experiments only show results in the MCAR setting, so the claim is not experimentally validated.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(3) Experiments under synthetic non-MCAR masking:
.As mentioned by the reviewer, we conduct experiments on non-MCAR masking following state-of-the-art non-MCAR model MIWAE [2].
.Please refer to Table 3 and Appendix C.4 for updated comparison results.
"	"Same as MIWAE, we synthesize masks by defining some rules to specify the probability of a Bernoulli distribution.
.VSAE outperforms MIWAE under all MCAR, MAR and NMAR masking mechanisms.
"
* The experiments do not demonstrate that the model learns a meaningful *conditional* distribution for the missing modalities, since the provided figures show just one sample per conditioning image.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"When performing imputation, we assume that the generation is not conditioned on the observed image, but only conditioned on the factorized latent variables.
.Input an observed image to the model, we observe a ""conditional"" distribution if we independently sample from the latent variables.
"	NOOOOOONNNNNEEEE	"(5) Conditional imputation:
.See Figure.7 in updated Appendix C.2.
"	NOOOOOONNNNNEEEE
7. ``Our experiments show that our networks can remember a large number of images and distinguish them from unseen images’’ -- this does not seem to be true, since the model is trained on both n as well as N -n ``unseen’’ images which it labels as the negative class, thus the negative class is also seen by the memorization model.	EXP	NOOOOOONNNNNEEEE	"We feed our model an equal number of positives and negatives (chosen randomly) at each epoch.
.For n < 10K, after 300 epochs the model has seen at most 3M negatives out of 15M, and yet still generalizes to the unseen negatives.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“7. ``Our experiments show that our networks can remember a large number of images and distinguish them from unseen images’’ -- this does not seem to be true, since the model is trained on both n as well as N -n ``unseen’’ images which it labels as the negative class, thus the negative class is also seen by the memorization model.
.(*)
.”
"	NOOOOOONNNNNEEEE
3. In the experiments, there are large discrepancies between different optimizers on Cakewalk (e.g. SGA vs AdaGrad, Table 4).	EXP	NOOOOOONNNNNEEEE	"One intuitive explanation for why an algorithm that maintains a ‘memory’ of previous gradient updates like AdaGrad or Adam is required
.is that they protect against sampling biases.
.Consider for example the case when the execution is at the start, and the sampling distribution still has maximum entropy.
.Due to the combinatorial nature of the solution space, the examples that have been sampled thus far create a distorted representation of the solution space.
.In this case we could get that some x_i=j will occur few times, while some other x_k will not receive the value j at all.
.Now if we apply vanilla gradient updates this can skew the sampling distribution in random directions.
.Gradient updates such as those of AdaGrad and Adam on the other hand will lessen the impact of such deviations as the importance of each case is inversely proportional to the number of previous observations.
.As such deviations will inevitably occur whenever we rely on polynomially sized samples to represent a combinatorial solution space, without such corrections a gradient based adaptive sampling algorithm will almost surely fail.
.Furthermore, this reasoning explains why AdaGrad is superior to Adam: AdaGrad corrects against sampling biases that entail all the examples that have been encountered, while Adam does this only within some exponentially moving time window.
.Indeed, this phenomenon is studied in detail in the AdaGrad paper (though without assuming a data distribution), and sparse data like ours (one can say our data points are N indicator vectors of length M) is the first motivating example in their paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Next, we address the question regarding the gradient update types.
.Indeed, as can be seen in tables 1,2 and 4, SGA almost never leads to a locally optimal solution.
"	NOOOOOONNNNNEEEE
2. Though seemingly very important to the architecture, the purpose of constructing the super-graph g^{sup} in the training of C^{CAT} seems to be unclear to me.	EXP	NOOOOOONNNNNEEEE	"R1A2: What makes few-shot learning particularly difficult compared to common machine learning settings is the dearth of training examples, which results in a bad empirical risk approximation for the expected risk and therefore gives rise to an empirical risk minimizer that is sub-optimal.
.Reducing the required sample complexity can result in a better empirical risk minimizer.
.Therefore, given a very large space of hypotheses H, our goal is to further restrict and constrain H using some prior knowledge because a reduced H has reduced sample complexity and thus requires fewer training samples to be trained.
.We provide this “prior knowledge” in the form of a “graph of graphs”, namely our super-graph $g^{sup}$, which captures both the latent inter-class and intra-class relationships between classes.
.Observe that in $g^{sup}$, we build a k-NN graph PER super-class, restricting any flow of information between super-classes, thus further restricting H. We force our model to jointly learn both the superclass and graph class labels.
.This way similar classes (grouped under a superclass) together contribute to learning a general prior representing the superclasses and each superclass also provides “guidance” to better train with the few samples assigned to that superclass.
.The introduction of this prior knowledge in the form of a supergraph in $C^{GAT}$ during training also helps generalize better to the novel samples that are presented to our model in the fine-tuning stage.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"R1Q2: “Though seemingly very important to the architecture, the purpose of constructing the super-graph $g^{sup}$ in the training of $C^{CAT}$ seems to be unclear to me.”
.Additionally, we would also like to draw attention to the supergraph usage summary provided by reviewer 2 in paragraph 3 of their comments.
"	NOOOOOONNNNNEEEE
B. You don't schedule learning rates for your baseline methods except for a single experiment for some initial learning rate.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have addressed your concern about the baseline models and learning rate schedules in our updated paper.
.* Used manual learning rate decay schedules for the CIFAR-10/100 baselines.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I do not see these experimental settings mentioned anywhere in the paper, and this is very concerning.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Overall, this is a reasonable paper but experimental section needs much more attention.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Regarding the experiments on adversarial examples, I am not convinced of their relevance at all.	EXP	NOOOOOONNNNNEEEE	"In both setups, our inference method is shown to be more robust compared to the softmax inference.
.Such experimental results support our claim that the proposed generative classifier can improve the robustness against adversarial attacks as it utilizes multiple hidden features (i.e., harder to attack all of them).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the revised draft, we also consider optimization-based adaptive attacks against our method under the black-box setup (see Table 5) and the white-box setup (see Table 10).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q5. Evaluation on adversarial attacks.
"	"We further show that our method further improves the robustness of deep models optimized by adversarial training (see Table 6 and 11).
"
4. [Experiments.] The author presented a multimodal representation learning framework for partially-observable multimodal data, while the experiments cannot corraborrate the claim.	EXP	NOOOOOONNNNNEEEE	"In general, we believe multi-modal data is more general than conventional image-text or video-text pairs.
.By unifying tabular data also as multi-modal (with each attribute as one modality), we show that VSAE provides us a principled way for imputation, capable of generalizing to more data families.
.Specifically, we conducted experiments on two types of data:
"	NOOOOOONNNNNEEEE	"We apologize for unclear description of experimental settings.
"	NOOOOOONNNNNEEEE	"Upon request, we have included more extensive experiments following [1] on MNIST/FashionMNIST, and [2] on CMU-MOSI/ICT-MMMO.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(2) Multimodal Experiments:
.Results are reported in Table 10 and Table 11 (Appendix C.5).
"	"(1) low-dimensional tabular data, and (2) high-dimensional data (pixel or text) as ""multimodal"" to better define the overall task of learning from partially-observed data.
.As shown, VSAE consistently outperforms baseline models across the added experiments as well.
"
These synthetic setting can be used for sanity check, but cannot be the main part of the experiments.	EXP	NOOOOOONNNNNEEEE	"In general, we believe multi-modal data is more general than conventional image-text or video-text pairs.
.By unifying tabular data also as multi-modal (with each attribute as one modality), we show that VSAE provides us a principled way for imputation, capable of generalizing to more data families.
.Specifically, we conducted experiments on two types of data:
"	NOOOOOONNNNNEEEE	"We apologize for unclear description of experimental settings.
"	NOOOOOONNNNNEEEE	"Upon request, we have included more extensive experiments following [1] on MNIST/FashionMNIST, and [2] on CMU-MOSI/ICT-MMMO.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"(2) Multimodal Experiments:
.Results are reported in Table 10 and Table 11 (Appendix C.5).
"	"(1) low-dimensional tabular data, and (2) high-dimensional data (pixel or text) as ""multimodal"" to better define the overall task of learning from partially-observed data.
.As shown, VSAE consistently outperforms baseline models across the added experiments as well.
"
"From the experimental perspective, the experimental evidence on ""invertible boolean logic"" does not seem to be very convincing for validating the approach."	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The experiments are not very convincing or illustrative of the theoretical results in my opinion.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We added an illustrative example in the introduction to give an intuitive understanding of invariance, stability and their relationship.
"	"We currently thinking about an experiment to better illustrate the intuition of our theory and would appreciate any suggestions.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We would appreciate further suggestions.
"	"- Q: Illustrative experiments:
"	NOOOOOONNNNNEEEE
"If that's true, then this distribution would be very bad for training a value function, which is supposed to involve an expectation over ""nature""'s choices in the MDP."	EXP	NOOOOOONNNNNEEEE	"We argue that to estimate the integral of the loss function L(τ) of the RL agent efficiently, we need to draw samples τ from the buffer in regions which have a high probability, p(τ), but also where L|(τ)| is large.
.Since, p(τ) is a uniform distribution, i.e., the agent replays trajectories at random, we only need to draw samples which has large errors L|(τ)|.
.The result can be highly efficient, meaning the agent needs less samples than sampling from the uniform distribution p(τ).
.The CDP framework finds the samples that have large errors based on the ‘surprise’ of the trajectory.
.Any density estimation method that can approximate the trajectory density can provide a more efficient proposal distribution q(τ) than the uniform distribution p(τ).
.The sampling mechanism should have a property of oversampling trajectories with larger errors/‘surprise’.
.- To mitigate the influence of very unusual stochastic transitions, we use the ranking instead of the density directly.
.The reason is that the rank-based variant is more robust because it is not affected by outliers nor by density magnitudes.
.Furthermore, its heavy-tail property also guarantees that samples will be diverse
.(Schaul et al., 2015b).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Second, the experiments are (as I understand it, but I may be wrong) in deterministic domains, which definitely does not constitute a general test of a proposed RL  method.	EXP	NOOOOOONNNNNEEEE	"- Yes, the experiments are mostly in deterministic domains.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
On the other hand, it is hard to say what the _main_ contribution is, which in turn makes it difficult to evaluate whether the experimental evaluation is sufficient:	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Given the fact that it applies the same MLP independently to individual set members, it is obvious that it is not universal equivariant (for example, consider a function that performs a fixed permutation to its input), and I fail to see why the paper goes into the trouble of having theorems and experiments just to demonstrate this point. If there were any other objectives beyond this in the experiments could you please clarify?	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> We agree it is trivial (and indeed the proof is a one-liner).
.If the reviewers feel strongly, we can move it to appendix, however we feel it helps to provide a complete picture.
.We included it in the experiments as a naive baseline and to show that adding a single transmission layer indeed provides a significant improvement.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"“The second issue I would like to raise is related to discussions around the non-universality of the vanilla PointNet model. ... if there were any other objectives beyond this in the experiments could you please clarify? “
"	NOOOOOONNNNNEEEE
3) In the experiments, the accuracy values are too low for me.	EXP	NOOOOOONNNNNEEEE	"We trained the network for only 164 epochs with a batch size of 100, which is probably the reason that its inference accuracy is lower than expected.
.Should we adopt the hyperparameters (a batch size of 128) and more training epochs (200 epochs) as shown at https://github.com/akamaster/pytorch_resnet_cifar10 , our ResNet-110 baseline reached 93.59% in inference accuracy, and the pipelined ResNet-110 reached 92.88% in inference accuracy.
.The speedup obtained is 1.73X, slightly higher than the 1.71X obtained in our paper, which could be caused by the batch size increase that makes the GPU process more efficient.
.The exact inference accuracy of the model is somewhat orthogonal to our study.
.It is the trend of the decline in inference accuracy with pipelining is what we study and this trend exists with both our hyperparameters and those at https://github.com/akamaster/pytorch_resnet_cifar10.
.Nonetheless, it is relatively easy for us to update the results in the paper with these new hyperparameters.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We appreciate the pointer to the better performance of ResNet-110.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Actually in the experiments the authors never use an increasing batch size.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Therefore,  the faster convergence demonstrated in the experiments can not be explained by Theorem 3.1 or Theorem 3.2.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Viewing it as a “duality gap” seems to be far from the practical training.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I’m not sure whether it is due to parameter choice or due to weak D/G networks used in the simulation.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
* The claim that training a separate decoder for each domain necessarily leads to prohibitive training times is dubious -- a single conditional decoder would arguably need more capacity than each individual separate decoder model.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Another unjustified choice by the authors is their choice of weighing the Tensor term (when it is being added to two base embedding vectors) in the phrase similarity experiment.	EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
While this is a reasonable assumption, it does not necessarily seem to be the case that a larger, more disconnected saliency map indicates worse classification performance.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It is definitely a good idea to analyse the correlation between changes in classification accuracy and in FSM values, thank you. We will rigorously investigate this in future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-- It is true that evaluating the FSM is not necessarily the same as the classification results, which is precisely the reason why we show both in our results.
"	NOOOOOONNNNNEEEE	"R: - FSM vs. Classification performance
"	"As specified in page 2, “Here we propose a new measure ...” - our point in this regard is to propose another (different) manner via which catastrophic forgetting can be estimated, which is not the same as the classification accuracy.
.The goal is that (as we know and agree they are two different measures that might agree or disagree in their judgments on catastrophic forgetting) both can be used to inspect the degree of catastrophic forgetting.
.We have further clarified that in Section 6.2 in the experiments by stressing that the obtained FSM results “along with the classification results” denote the significance of the whole framework in addressing catastrophic forgetting.
"
-- solving Eq 3 by matrix inversion does not scale. Would be best to also show results using iterative optimization	RES	NOOOOOONNNNNEEEE	">>> We want to answer this question from two aspects.
.On one hand, few-shot learning assumes that training examples in each class are quite small (only 1 or 5).
.In this situation, Eq (3) and the closed-form version can be efficiently solved, since the dimension of S is only 80x80 or 100x100.
.On the other hand, there is plenty of prior work on the scalability and efficiency of label propagation, such as [2], [3], [4], which can extend our work to large-scale data.
.On miniImagenet, we performed iterative optimization and got 53.05/68.75 for 1-shot/5-shot experiments with only 10 steps.
.This is slightly worse than closed-form version (53.75/69.43), because of the inaccurate computation and unstable gradients caused by multiple step iterations.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"""solving Eq 3 by matrix inversion does not scale. Would be best to also show results using iterative optimization ""
"	NOOOOOONNNNNEEEE
Only some heuristic results are obtained for them without rigorous theory.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We will work on the writing in the future version of this work.
"	"The ION theorem is an important part of explaining sparsity, dead units, and rank as well, but perhaps our writing was not clear enough.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
While the use of a GAN in general will make the results less blurry and visually appealing, it does not necessarily mean that the samples it generates are going to be plausible or better.	RES	NOOOOOONNNNNEEEE	"However, that is typically not the case of synthetic datasets.
.In early experiments, we trained our pure VAE model on the stochastic shape movement dataset from Babaeizadeh et al. (2018), and our pure VAE was able to model the dataset without any blur and with perfect separation of the possible futures.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The purpose of adding adversarial losses to a pure VAE is to improve on blurry predictions where the latent variables alone cannot capture the uncertainty of the data.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
This claim is simply not true, and more care is needed in reporting the results here in the wider context of the literature.	RES	NOOOOOONNNNNEEEE	"We spent a considerable amount of time trying to fulfill the reviewer’s request to match state of the art (SOTA) on PTB.
.Still, we pursued two directions.
.First, we tried to reimplement an architecture similar to  Melis et al. 2017.
.However, they did not publish their code, hyperparameters, or weights, requiring re-implementing and re-training from scratch.
.We tried this path, but soon realized we would not be done in time (especially with a hyperparameter search).
.We then tried to weave neuromodulation and differentiable plasticity into the architecture and code base of Merity et al., ICLR 2018 (also tied for SOTA).
.However, while they could simply leverage existing PyTorch implementations of LSTMs (written in extremely fast C++), we had to re-implement LSTMs “by hand” (i.e. as a series of connected layers) in PyTorch to introduce plasticity and neuromodulation.
.As a result, our networks thus ran considerably slower, by more than 10x (not because our method is intrinsically slower, but just for lack of engineering optimizations on our bespoke Python implementations; we confirmed this by observing that a similar “hand-built” reimplementation of simple, non-plastic LSTMs ran similarly slower, while producing results identical to Merity et al.).
.These experiments are thus unfortunately still running.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).
"	NOOOOOONNNNNEEEE	"For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"That said, we still believe the results in the current paper demonstrate the benefits of our techniques on a sizable model, and thus it would benefit the community to allow people to know about, and build upon, these new methods and results.
.The purpose of the present paper is to introduce a novel technique and show that it can produce an advantage in realistic settings, which we believe our PTB task confirms.
.Our claim is that, all other things being equal (especially the number of parameters), a neuromodulated plastic LSTM outperformed a standard LSTM on this particular benchmark task.
.We do **not** want to claim that our results are anywhere near SOTA.
.Additionally, philosophically, If SOTA results are the bar for all papers to be accepted into conferences like ICLR, then those venues will be the exclusive domain of those with either the computation or time (i.e. large-scale resources) to dedicate to such results.
.In that case, many cutting edge ideas will by necessity be excluded from the discussion, as will many research groups.
.Moreover, insisting on papers to be SOTA to be accepted also likely encourages p-hacking and shoddy science to game the results (even if unintentionally), reducing the quality of science our community tries to build on.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, I have a few concerns about the results.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"The column ""FLOPS"" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases."	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Indeed, the manuscript introduces sample complexity results to justify the benefits of the out-of-sample procedure (th 1), but it seems to me that these give an incomplete picture.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The proposed sampling distributions assumes independence between the random variables over which the authors optimize — I find it surprising that this leads to good empirical results	RES	NOOOOOONNNNNEEEE	"The simple explanation is that in some problems the conditional expectation of the objective given that some x_i=j is much better than for other values x_i=k. In such cases, for each dimension the algorithm will tend to sample values which are useful to many possible solutions.
.In the clique problem for example, if some node i is part of a large clique, then sampling x_i=1 is likely to result in a good objective as there are many nodes that are connected to i, and the chance of not sampling any of them decreases with the clique size.
.In this way, over time the probability for sampling such nodes becomes higher, and the chance of sampling all of them together increases.
.Lastly, we note that these kind of factorized distributions have a long history of being useful  in machine learning.
.In a similar context to the one studied in the paper, such distributions have been studied by Rubinstein in his paper which discusses CE as an algorithm for combinatorial optimization, and in the classical bandit papers Exp3 is applied independently to several dimensions to study game theoretic problems.
.In different contexts, such distributions have also been used as naive mean field approximations in variational inference.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Next, we’ll try to provide some intuition as to why a sampling distribution that assumes independence between the different dimensions can be useful in some cases.
"	NOOOOOONNNNNEEEE
It is unclear how important this particular objective is to the results.	RES	NOOOOOONNNNNEEEE	"We found that the CDN objective leads to superior results, especially in the adversarial examples experiment.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have added a new section (Sec. 4) to discuss the differences between the objective used for CDN, when performing variational inference for BNNs, and in the variational information bottleneck (VIB) framework.
.Furthermore, we present an experimental investigation of these different objectives (Sec. 6.4).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- In 5.1, imagenet results are normally top-5 error rate not top-1 acc, would be better to report that more familiar number.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"10. Thank you for pointing these typos out, we have addressed it in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
e.g: REINFORCE has lower best-sample to total-sample ratio but its solutions are worse)	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- Table 3 is indeed confusing, this is a good point. We will correct it.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The authors claim that some amount of noise can be tolerated, but do not quantify how much.	RES	NOOOOOONNNNNEEEE	"1. Noise Tolerance — NOODL also has similar tolerance to noise as Arora et. al. 2015 and can be used in noisy settings as well.
.We focus on the noiseless case here to convey the main idea, since the analysis is already very involved.
.Nevertheless, the proposed algorithm can tolerate i.i.d. sub-Gaussian noise, including Gaussian noise and bounded noise, as long as the ``noise’’ is dominated by the ``signal’’.
.Under the noisy case, the recovered dictionary and coefficients will converge to a neighborhood of the true factors, where the neighborhood is defined by the properties of the additive noise.
.In other words, the noise terms will lead to additional terms which will need to be controlled for the convergence analysis.
.Specifically, the noise will add a term to the coefficient update in Lemma 2, and will effect the threshold, tau.
.For the dictionary, the noise will result in additional terms in Lemma 9 (which ensures that the updated dictionary maintains the closeness property).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A precise characterization of the relationship between the level of noise the size of convergence neighborhood requires careful analysis, which we defer to future effort.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Having this in mind note that the theoretical results on stochastic variant presented in the paper are wrong.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The authors either need to remove these results or restate them in a different way in order to satisfy the assumed conditions.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"The paper also lacks experimental results, and the main conclusion from these results seems to be ""MNIST is not suitable for benchmarking of adversarial attacks""."	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"""Table 4 shows that our first results are promising, even though they are not as good as the state of the art."" The state of the art on LibriSpeech is not Mohamed at al. 2019. See e.g. Irie et al. Interspeech 2019 for better result"	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Thanks for pointing this out, we fixed this in the updated version of the paper we just posted.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	">> The state of the art on LibriSpeech is not Mohamed at al. 2019.
.See e.g. Irie et al. Interspeech 2019 for better result.
"	NOOOOOONNNNNEEEE
Overall, I feel that the result is interesting but it depends on a strong assumption and doesn't capture all interesting cases.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"It's true that there are many activation functions that the result doesn't apply to, and in fact isn't true for.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The selling point isn't the generality of the result, but rather the novelty of the approach and the potential it suggests for future work that would be more general.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
It is also not clear how this theoretical result can shed insight on the empirical study of neural networks.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Is there actionable consequences one could draw from your papers? The way the results are presented seem like they are only useful inspection after training; are your results able to derive methods to enforce conditions on the pre-images for example?	RES	NOOOOOONNNNNEEEE	"One consequence of our paper is that it is close to impossible (each layer need at least to double the number of neuron) to enforce invertibility and it is similarly hard to enforce compactness in ReLU layers.
.This leads to the conclusion that if one wants invertibility or even just compactness reliably over the whole space, vanilla architectures using ReLU are not a good tool for the task.
.Hence, our analysis can be seen as an argument for additional structure like dimension splitting in reversible networks (see e.g. Jacobsen et al. (2018)).
.These structures allow for guarantees as they are by design bijective, while vanilla architectures show a breadth of possible effects as shown in our analysis.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-> Added a comment to “Practical Implications” in the revision
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"-Q: Actionable consequences from paper:
"	NOOOOOONNNNNEEEE
have no idea how confident the sampling based result is.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
While I understand that quantifying performance in this application is difficult, I do find the results difficult to interpret.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree on this remark, the idea of scaling scores is right and would improve the interpretability of our benchmarks.
.For that purpose, we should define a set of reference scores as you recommended to.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Interpretability of the generative scores:
"	NOOOOOONNNNNEEEE
The ResNet on Cifar-10 results are not convincing.	RES	NOOOOOONNNNNEEEE	"Again, we think the exact inference accuracy of the model is somewhat orthogonal to our study.
.It is the trend of the decline in inference accuracy with pipelining is what we study.
.This trend exists with both our hyperparameters and those at, for example, https://github.com/akamaster/pytorch_resnet_cifar10.
.The use of these set of hyperparameters, obtains an inference accuracy of 91.65% (better than the accuracy stated in the original ResNet paper) for ResNet-20 non-pipelined baseline and 91.21% for pipelined version.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are not aware of any reports of an accuracy of ResNet-20 at 92% (perhaps this is approximate).
"	"Thank you for pointing out the accuracy of ResNet-20 (similar to Reviewer 1).
.Please kindly let us know a pointer.
.It is relatively easy to update our results in the paper with new hyperparameters.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Perhaps the authors had no salient observations for loss, but explicitly stating such would be useful to the reader.	RES	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The introduction contains a few statements that may paint an incomplete or confusing picture of the current literature in adversarial attacks on neural networks:	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"1. The title of the paper is ""visual reasoning by progressive module networks."" The title may be a little overstated since the major task is focused on visual question answering (VQA)."	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- We agree that the main highest-level task that we show is VQA, even though our method is more general.
.Our title aimed to convey that we showcase PMN on a host of increasingly complex visual reasoning tasks such as relationship detection, counting, and captioning, as well as VQA.
.Our focus is on VQA as it happens to be one of the most complex visual reasoning tasks that can leverage each of the (relatively) simpler tasks.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"1. Title of the paper
"	NOOOOOONNNNNEEEE
The authors spend two paragraphs in the introduction trying to draw a distinction but I am still not convinced.	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The following link is a figure that explains the difference between zero-confidence attack and fix-perturbation attack.
.https://docs.google.com/viewer?url=https://raw.githubusercontent.com/anon181018/iclr2019_rebuttal/master/figure1.pdf
.As can be seen, the zero-confidence attack finds the closest point on the decision boundary; while fix perturbation-attack finds adversarial samples within a fix perturbation.
.Both attacks are equivalent if we only want to compute the attack success rate under a given perturbation level.
.However, we will be better off with zero-confidence attacks if we want to
.1) Compute the margin of each individual example; and
.2) Probe and study the decision boundary of a classifier
.Of course, we can also measure the margin of each example using a fix-perturbation attack, for example PGD, by binary searching over the perturbation levels.
.However, the computation cost will significantly increase.
.Consider, for example, the CIFAR-10 dataset.
.Since for our model, most margins fall within 10, so let’s assume the binary search range is 10 (for adversarially trained models this number will be much higher).
.If we want to achieve a accuracy of 0.1, then we need at least 7 binary search steps.
.In other words, the computation complexity increases by 7 times.
.In fact, CW applies a similar binary search idea to achieve zero-confidence attack, and that is why its computation cost is high.
.The above discussion is not saying that it is impossible to convert PGD to a zero-confidence attack efficiently, but it at least provides a perspective on why zero-confidence attack is challenging, and why the complexity reduction as well as accuracy improvement of MarginAttack is valuable.
"
"The title claims way more than what is actually delivered in the paper, despite the fact that the authors have put in an ""On"" in the beginning of the title."	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We understand your concern and have made the title more specific.
.Tentatively, we chose: “Convergence Properties of Deep Neural Networks on Separable Data”.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
So, the motivating assertion “[...] state-of-the-art solvers do not yet scale to large, difficult formulas, such as ones with hundreds of variables and thousands of clauses” in the introduction of the paper, is not totally correct.	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We tested PicoSAT, MiniSAT, Dimetheus and CaDiCaL and reported the
.results in the updated paper.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"CNNSAT outperformed all these solvers
.by
.at least two orders of magnitude over the ""Long Range"" dataset.
"
* Also in the introduction, it is implied that style transfer constitutes an advance in generative models, but style transfer does not make use of / does not equate to any generative model.	INT	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I also have concerns about the independence assumption in their sampling distribution (Section 3.2), and the fact that their experiments use the same set of (untuned) hyperparameters for each method.	MET_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
- Providing the same computational budget seem rather arbitrary at the moment, and it heavily depends from implementation. How many evaluations do you perform for each method? why not having the same budget of experiments?	MET_EXP	NOOOOOONNNNNEEEE	"In terms of the computational budget for each experiment, we compared different algorithms under different computational budget metrics, more specifically,  “wall-clock time”, “number of updates”, and the “final converged performance”.
.NGE performs best among all algorithms.
.We emphasize the fact that wall-clock time is a more common and realistic metric for comparing the structure search in practice.
.We agree that computational budget depends on implementation, and the curves in the paper are plotted based on the number of iterations/parameter update, which is independent of the implementation.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We are unsure what the reviewer is indicating, and would appreciate the additional clarification.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Q4: Providing the same computational budget seem rather arbitrary and depends on implementation.
"	NOOOOOONNNNNEEEE
The two things that make me more skeptical, is the convergence of the proposed algorithm and the experiments.	MET_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
However, the experimental comparison is not fair, the description of the model (e.g. how Choquet is integrated into the model and help to learn “intermediate meaningful results”) is not clear, some claims are not true.	MET_EXP	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
1. The presentation is somewhat convoluted.	OAL	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The updated paper will change the emphasis, and clarify that a proper learning progress proxy remains future work.
.We will also clarify that the little phrase “After initial experimentation, we opted for the simple proxy…” implies quite extensive experimentation with other plausible proxies that looked promising in individual environments but were not consistently effective across the suite of Atari games.
.Comment 2:
"	"We acknowledge that our presentation focused more than necessary on ideal scenarios that use learning progress LP(z) while the practical version used a (maybe disappointingly) simplistic choice of proxy f(z).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
I have some concerns on this paper:	OAL	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Quality: Below average	OAL	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The convergence analysis is on Z, not on parameters x and hyper-parameters theta.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"The convergence of the network output Z directly indicates the rate of decrease of the loss function, which is exactly what we observe in practice.
.Although the assumption of a global optimization oracle is not realistic, we believe our theoretical justification provides insight into why the method works.
.One important takeaway from the theoretical analysis is that running gradient descent on output space can potentially accelerate the optimization (since the convergence bounds have better constants).
.This directly motivates the regularization term in our meta objective to be defined as the discrepancy of network outputs instead of the network parameters, which is essential to our technique.
"	NOOOOOONNNNNEEEE	"The convergence analysis is on Z, not on parameters x and hyper-parameters theta.
.So, bounds here cannot be used to explain empirical observations in Section 5.
"	NOOOOOONNNNNEEEE
- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates.	ANA	NOOOOOONNNNNEEEE	"1. Noise Tolerance — NOODL also has similar tolerance to noise as Arora et. al. 2015 and can be used in noisy settings as well.
.We focus on the noiseless case here to convey the main idea, since the analysis is already very involved.
.Nevertheless, the proposed algorithm can tolerate i.i.d. sub-Gaussian noise, including Gaussian noise and bounded noise, as long as the ``noise’’ is dominated by the ``signal’’.
.Under the noisy case, the recovered dictionary and coefficients will converge to a neighborhood of the true factors, where the neighborhood is defined by the properties of the additive noise.
.In other words, the noise terms will lead to additional terms which will need to be controlled for the convergence analysis.
.Specifically, the noise will add a term to the coefficient update in Lemma 2, and will effect the threshold, tau.
.For the dictionary, the noise will result in additional terms in Lemma 9 (which ensures that the updated dictionary maintains the closeness property).
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A precise characterization of the relationship between the level of noise the size of convergence neighborhood requires careful analysis, which we defer to future effort.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
The presented analysis seems to neglect the error term corresponding to the value function.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We agree with your suggestions and we will revise our paper accordingly.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
Moreover, as observed by the authors this analysis currently rely on strong assumptions that might make it rather unrealistic.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"In the updated draft of our paper, we have updated the rigor of the theory section: please see Section 5 and Appendix C for updated theory.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"To summarize: we’re interested in the sample complexity of RL algorithms, i.e., the number of samples required for the learned policy to become near-optimal (achieve reward at most epsilon less than the optimal policy).
.Standard results (e.g., MBIE-EB, R-MAX) can guarantee a near-optimal policy, but they require so many samples (polynomial in the size of the state space) in deep RL settings, that the guarantees are effectively vacuous.
.In contrast, for a subclass of MDPs, our approach provably learns a near-optimal policy in a number of samples polynomial in the size of the *abstract* MDP.
"
There is a key concern about the feasibility of the numerical analysis for the first part.	ANA	NOOOOOONNNNNEEEE	"On the other hand it is a first step towards a multilayer analysis and allows a localized layer-by-layer analysis for the first time.
"	NOOOOOONNNNNEEEE	"As correctly observed, the application of our algorithm to classify the preimage of one data point of one ReLU layer does not easily translate to more than one layer.
.On the one hand, as pointed out, as soon as the preimage is no longer only a point itself it is no longer applicable.
"	NOOOOOONNNNNEEEE	"-> For more on this we refer to the newly added Section “Scope” in the revision.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"- Q: Algorithm applied layer-by-layer:
"	NOOOOOONNNNNEEEE
Moreover, if I understand correctly the WGAN analysis does not take into account that G and D are non-linear, and it is unclear if these can be done.	ANA	"A1: As for novelty, we first thank you for acknowledging that understanding GANs from the control theory perspective is promising and enjoyable to read.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Finally, we added new results in Table 1 in the revision, which shows that the same technique of negative feedback can further improve the state-of-the-art method of SN-GAN [*5].
.Specifically, we apply NF-GAN to SN-GAN [*5] and NF-GAN provides a significant improvement on the state-of-the-art inception score on CIFAR-10 (from 8.22 to 8.45).
"	NOOOOOONNNNNEEEE	"As discussed in Remark 3 and Section 7 of the revised paper, we also note that the recent analyses of GANs on the functional spaces [*4] can provide a promising solution to solve this approximation and we leave it as our future work.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Indeed, as agreed by R#2, this is a major novel contribution that provides a unified and promising framework to model the stability of GANs, which includes some recent developments (e.g., Negative Momentum and Reg-GAN, See Sec. 4.1 and Appendix A&C) and also provides us a possibility to explore advanced tools in control theory (e.g., nonlinear control and modern control theory [*3]) to improve both the stability and convergence speed of GANs.
.Then, as some useful examples, in this paper, we particularly showed that the technique of negative feedback can be leveraged to stabilize GANs and developed NF-GAN, which was proven to be effective in our experiments.
.Overall, our perspective is novel and it indeed sets new state-of-the-art results as compared to the current variants of GANs.
.As for the statement “the WGAN analysis does not take into account that G and D are non-linear”, this is a potential misunderstanding.
.In fact, in the WGAN analysis, we do not put any constraints on the G and D networks, which can be any well-defined nonlinear models.
.This confusion may arise from the linearity of the dynamics.
.In Sec. 3.2
., as we model the dynamics of G and D in the functional space instead of the parameter space, they can both denoted as integral parts (See Eqn. (10)&(11)), thereby both are linear.
.However, this doesn’t influence the nonlinearity of G and D with respect to the weights.
.Technically, we provide an approximate solution to deal with such nonlinearity.
"	NOOOOOONNNNNEEEE	"Q1: About the main concern on “novelty, improvement relative to the current state of the art implementations,  and non-linearity of G and D”:
"	"Such results indicate that our technique of NF-GAN can still benefit the state-of-the-art variants of GANs (e.g., SN-GAN).
"
- It is good that Section 5 has some theoretical analysis. But I personally find it very disturbing to base it on a 2nd order approximation of a probability density function of images when modeling something as intricate as models that generate images.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Moreover, the special structure of CV-Glow makes these derivative-based approximations better behaved and more tractable than an expansion of a generic deep neural network.
"	NOOOOOONNNNNEEEE	"2.  “It is good that Section 5 has some theoretical analysis. But I personally find it very disturbing to base it on a 2nd order approximation of a probability density function of images when modeling something as intricate as models that generate images. At least this limitation should be pointed out in the paper…
"	NOOOOOONNNNNEEEE
To evaluate the impact of the proposed changes in this paper, one would have to perform extended evaluations and ablations for the submission.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Concerning including more comparison and ablations in the paper, we have performed an extended analysis of our method to the baselines across many environments.
.See Figures 2,3,5 for more learning curve results and baseline comparisons and Figure 6 for qualitative metric analysis.
.We show that our method outperforms the baselines across multiple environments.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"No other simulation is available that combines these challenges.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE
"2.	What is the reason for using rule-based agents in all the experiments? It would have been more useful if all the analysis are done with RL agents rather than rule-based agents."	ANA	NOOOOOONNNNNEEEE	"In the main results, we focus on rule-based agents because it is computationally demanding to train a large population of RL agents, and our focus was not about the worker policies but rather how the manager assesses the workers’ mental states and encourages an optimal collaboration accordingly.
.In this paper, using a cheap rule-based implementation with randomness has demonstrated the effect of different components of our approach.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"We have actually used RL agents as well (Appendix C.3), and it showed that our approach also works when workers are RL agents.
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"2. What is the reason for using rule-based agents in all the experiments?
"	NOOOOOONNNNNEEEE
This has not been considered in the analysis.	ANA	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"Theoretically, to address this comment, we added Theorem 1 (See in the Appendix D) that states the dynamics of $D$ with Lipschitz constraint follows Eqn. (10) *around the equilibrium*. Therefore, the stability analysis and our proposed method in Sec. 4 still applies to vanilla WGAN because control theory mainly focuses on the stability *around the equilibrium* [*2].
"	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	NOOOOOONNNNNEEEE	"A3: Actually, our method also applies to WGAN with Lipschitz constraints (vanilla WGAN).
.Existing work [*3] states that vanilla WGAN diverges and we provide theoretical and empirical evidence that our method helps vanilla WGAN converge.
"	NOOOOOONNNNNEEEE	"Q3: The Lip constraints on the discriminator:
"	"Empirically, as suggested by R#3, we built a vanilla WGAN baseline using the SN-GAN [*6] framework, whose Lipschitz constraints are satisfied through spectral normalizations.
.We compared SN-GAN (WGAN loss) and NF-SN-GAN (WGAN loss) and obtained a significant improvement on both the stability and the final results (IS from 3.29 to 8.28, See details in our post for common concerns).
.It demonstrates that our method helps vanilla WGAN converge, which is consistent with our theoretical analysis.
"
