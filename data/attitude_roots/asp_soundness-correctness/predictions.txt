This somewhat conflicts the commonsense of "the deeper the better?"			NONE
2. Typos: the weight matrix in the end of page 2 should be N_l times N_{l-1}. Also, the x_i's in the first line of page 3 should be bold.			NONE
- While the authors mention multiple times that #rhs/#lhs = 1 and 2 are more challenging than #rhs/#lhs=18, they do not sufficiently explain why this is the case anywhere in the paper.			MET
However, to state the result of Theorem 4.3, k should be bigger than M c_\eta from the dentition of \tilde{\rho}_k^M, as shown under the equation (4).			MET
The proof given in the appendix is overly short and not detailed enough.			NONE
The approach is not linked to so called Tandem approach that was/is popular in speech recognition where a generative model (GMM) is trained on top of features extracted by a neural network model.			MET
- The proposed approach is a fairly specific form of self-modulation.			MET
Can you clarify how you view the relationship between the approaches mentioned above?			MET
* One aspects that is mostly left out of the discussion (except from one side comment) is the wallclock time, as some optimizers might be on average quicker to train (for example due to quicker convergence), this can easily lead it to be quicker to tune even though it requires a higher budget of trials.			NONE
I think it would be worth discussing this more.			NONE
However, it seems the only Figure showing D’s loss when unconstrained is Figure 26, in which it is hard to notice any significant jump in the loss.			TNF
- In Appendix F, Figure 20 d), the title seems wrong. It seems to report sigma^2 values, but the title says “losses”.			TNF
- important features for the new task should be in similar locations as important features of the old task (for example, one would expect that the proposed approach would negatively affect learning the new task if the important features of the old task were all located in the bottom of the image, while all important features for the new task are in the top)			MET
- the locations for important features should be comparatively stable (for example, one would expect the average saliency map to become fairly meaningless if important features, such as the face of a dog, can appear anywhere in the image.			NONE
While this is a reasonable assumption, it does not necessarily seem to be the case that a larger, more disconnected saliency map indicates worse classification performance.			RES
Comparatively small changes in FSM may not affect the classification performance at all, while larger changes may not necessarily lead to worse classifications either.			NONE
For example, by increasing the amount or size of image regions to be considered, the classifier may accidentally become more robust on an old task.			MET
This appears strange, since it would mean that $x_i$ cannot be in the center of $\hat{x}_i$.			NONE
Even though the authors answer positively to each of their four questions in the experiments section			EXP
However, I don’t know how effective this is in practice.			EXP
- The randomized weight is not very practical. Though it may be the standard approach of mean field,			MET
For example, if the rule-based concept extractor can already extract concepts very well, the “problem retrieval” should be solved by searching with the concepts as queries.			NONE
Why should we use embedding to compare the similarity?			MET
Also, the title of the paper is about problem retrieval but the experiments are about similarity comparison, there seems a gap.			EXP
This means that it is not apriori clear if using this solver instead of standard SGD, ADAM is any good.			MET
-- solving Eq 3 by matrix inversion does not scale. Would be best to also show results using iterative optimization			RES
The introduction contains a few statements that may paint an incomplete or confusing picture of the current literature in adversarial attacks on neural networks:			INT
I find these assumptions too strong for the task of learning disentangled representation.			MET
Hence, these overly simplified and unrealistic assumptions make the task too trivial.			NONE
The proposed method is very simple and frames the problem basically as a supervised learning problem.			MET
Although experiments show that learning such representations are beneficial for low-shot setting of SVHN, it is not clear whether such improvement generalizes to more realistic datasets such as ImageNet.			DAT_EXP
A quick glance at Table 1 suggests that the bounds obtained through Theorem 3 are exponential in t and are mostly vacuous.			TNF
They can indeed be subsumed by generalization bounds based on VC theory.			MET
The bound obtained in Theorem 2 comes rather easily from the bounded assumption on the non-linearity and is this not very interesting.			MET
- The search space of the proposed method, such as the number of operations in the convolution block, is limited.			MET
One question which is not addressed is the reason for only one RBM layer.			MET
If the test set is not shuffled (by emphasis on first I assume not) these images are from training NIST (cleaner) set and may not include samples of all digits.			DAT
Furthermore, If I deploy the learning algorithm on a physical robot, will the temporally consistent exploration cause less wear and tear to the actuators when the robot explores.			MET
1. The title of the paper is "visual reasoning by progressive module networks." The title may be a little overstated since the major task is focused on visual question answering (VQA).			INT
My assumption is the visual feature already contains the label information for image captioning.			MET
Is the number right?			MET
Only some heuristic results are obtained for them without rigorous theory.			RES
Furthermore, Figure 6 and Figure 7 in general show SAVP performing worse than SVG (Denton & Fergus 2018), a VAE model with a significantly less complex generator, including for the metric (VGG cosine similarity) that the authors introduce arguing that PSNR and SSIM do not necessarily indicate prediction quality.			TNF
While the use of a GAN in general will make the results less blurry and visually appealing, it does not necessarily mean that the samples it generates are going to be plausible or better.			RES
Their proposed solution of functional composition is exceedingly clever but in my opinion too impractical to really be useful.			NONE
It adds extra complexity, requires you to do function composition which may be less expressive and takes more coomputation, etc. And to what end?			MET
The function composition doesn't capture that.			MET
One observation from the submission is that the token set may need to very large (from tens of thousands to millions) for the system to work well, making the BERT training computationally expensive (I noticed that the BERT model is trained on 128 GPUs)			DAT
2. Besides the computational expensive-ness of the three-step approach (vector quantization, BERT, acoustic model training), the combined model complexity is large because these steps do not share neural network architecture.			MET
3. One concern I have with discrete representation is how robust they are wrt different dataset.			DAT
This claim is unfortunately unfounded for a very important reason: the LSTM performance is not at all close to that which can be achieved by LSTMs in general.			MET
Though this may be true, these models still undermine the claim that “neuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task”.			MET
This claim is simply not true, and more care is needed in reporting the results here in the wider context of the literature.			RES
Concerns: I find the claim on deep networks kind of irresponsible.			MET
1. The dataset is adversarially filtered using BERT and GPT, which gives deep learning model a huge disadvantage. After all, the paper says BERT scores 88% before the dataset is attacked.			DAT
Formulating the abduction task as a (binary) classification problem is less interesting.			NONE
Second, the conclusion of Theorem 2 seems to be flawed.			MET
This illustrates that the conclusion of Theorem 2 may be wrong.			MET
The proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says.			MET
Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?			MET
Another modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?			MET
Is \eta_{\mathcal{H}} is a better estimation that previous adaptability term in multi-source DA? What is the role of \eta_{\mathcal{H}} in the algorithm design? How to control it in empirical algorithm?			MET
- On the human evaluation: showing the gold standard reference to the judges introduces bias to the evaluation which is inappropriate as in language generation tasks there are multiple correct answers.			NONE
- In the outputs shown in Table 3, the questions generated by the scratchpad encoder often seem to be too general compared to the gold standard, or incorrect.			TNF
The paper does not provide very significant evidence that this method is useful.			MET
The negation example is nice but this doesn't seem to display the potential power of the method to understand a neural network.			EXP
-1 The mathematics in section 3.1 is unclear and potentially flawed (more below).			MET
-4 Talking about "agents" and "Multi-Agent" is a somewhat confusing given the slightly different use of the same term in the reinforcement literature. Why not just "mapping" or "network"?			MET
At the very least we need another "partial" sign in front of the "\delta" function in the numerator.			MET
So is the REINFORCE estimator used or something? Not that the importance sampling matter is orthogonal.			MET
As with ensembles, clearly it only helps to have multiple agents (N>2) if the additional agents are distinct from f_1 (again without loss of generality this applies to g as well).			MET
The paper should quantify that this leads to diverse "agents".			NONE
But it's not guaranteed as the upper bound contains other variables, such as the number of training samples and model complexity.			NONE
If the training samples and model complexity (think about the parameters in the deep models) are significantly large, the upper bound of the loss might be also very large.			NONE
However, the proposed upper bound in the paper involves other parameters, such as the model complexity and the number of training samples.			MET
1). Why minimizing the upper bound in this scenario would help to minimize the loss on the target domain, when the upper bound can be substantially huge? How about just evaluate \alpha by the closeness of the source domain with the target domain?			MET
Intuitively, these criteria are well motivated, but unfortunately, the combination of all the intuitions (including "selection network" with threshold) is not very principled.			MET
However, I have a few concerns about the results.			RES
To me this paper is just not good enough - the method essentially i) use "a professor and two teaching assistants" to build a "rule-based concept extractor" for problems, then ii) map problems into this "concept space" and simply treat them as words. There are several problems with this approach.			MET
First, doing so does not touch the core of the proposed application.			NONE
Moreover, the main difference between math problems and other problems is that there are math expressions; I do not think that using words/concept labels only is enough without touching on the math expressions.			MET
Second, the proposed method does not sound scalable - the use of a professor and two teaching assistants to construct the concept extractor, and the use of an expert TA to select a small set of informative words.			MET
I am not sure how this will generalize to a larger number of problem spanning many different domains.			NONE
Algorithm 1 does not include mitosis, which may have an effect on the resulting approximation.			MET
The results only compare with Shim et al. Why only this method? Why would it be expected to be faster than all the other alternatives? Wouldn't similar alternatives like the sparsely gated MoE, D-softmax and adaptive-softmax have chances of being faster?			MET_RWK
The column "FLOPS" in the result seems to measure the speedup, whereas the actual FLOPS should be less when the speed increases.			RES
Also, a "1x" label seems to be missing in for the full softmax, so that the reference is clearly specified.			RWK
In a related note, using MF for training BMs have been proposed previously and found to not work due to various reasons:			RWK
This claim is bigger than just CNNs and needs to be studied in a theoretical framework not an empirical one.			MET
Also, one simple way to stop these adversarial cases would be to explore using Sigmoid as opposed to softmax.			MET
In general it is very unlikely that you will be able to choose every variation of out-distribution cases.			NONE
Much easier if you just try to solve the problem using a set of n Sigmoids (n total number of classes) and consider each output a probability distribution.			NONE
Although the authors mention in the conclusion that it's future work to merge their proposed changes into the sparse DNC, it is hard to know how relevant the improvements are, knowing that there are much better baselines for this task.			NONE
However, the issue still exists in Dreamer, since there seems to be an upper limit of effective horizon length (perhaps around 40, according to Figure 4).			TNF
That is, the issue still exists, and Dreamer is less effective with very long horizon.			NONE
This restriction exists in Dreamer, and the method cannot be applied to discrete control tasks unless approximation techniques such as Gumbel-softmax are used.			MET
Dreamer does not use any variance reduction technique, so the gradient estimates could have very large variance.			MET
The performance of the proposed method is worse than the previous work but they claimed "state-of-the-art" results.			MET_RWK
Indeed, the manuscript introduces sample complexity results to justify the benefits of the out-of-sample procedure (th 1), but it seems to me that these give an incomplete picture.			RES
The proposed sampling distributions assumes independence between the random variables over which the authors optimize — I find it surprising that this leads to good empirical results			RES
The definition of “recovering true factor exactly” need to be given.			MET
The descent lemma used by the author is not valid for the stochastic result.			MET
The authors should address that in their revision.			NONE
Objectively saying that the author's method is better than CycleGAN is difficult. How does their ensemble method compare to just their single-agent dual method? Is there a noticeable difference there?			MET
This seems incomplete to me: there are tens of thousands (probably more) of exercises and problems available in workbooks for elementary, middle, and high school students.			NONE
- The paper makes use of a result from the David MacKay textbook			RWK
High-level			NONE
Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?			DAT_EXP
I feel the approach to implicitly assume that the classifiers to be compared are already "reasonably accurate"; since if not, both classifiers might be easily falsified by certain trivial examples, making the "disagreed examples" not as meaningful.			MET
However, since the authors adopted an affinity-aware distance, two incorrect predictions can still be compared based on their semantic tree distances to the true class.			MET
The advantage of INN, however, is not crystal clear to me versus other generative methods such as GAN and VAE.			MET
3) The overall performance of the proposed SST in the experiments is not convincing and not promising.			EXP
-	In section 4, it is unclear why only the maximal activation of the softmax layer is used to characterize a sample? Why not considering the full distribution that should contain richer information? Why just focusing on the output layer and why not using the info available at intermediate layers?			MET
This might be because the Bayes and MAT attacks are too simplistic.			MET
Again, why not using the distribution of the outputs of all layers? Why focusing only on the output of the last layer?			MET
Therefore, it is an overclaim that the KL-divergence bound (2) provides an immediate justification for AGZ’s core learning algorithm.			MET
As mentioned earlier, the actual conclusion in Section 4.2 is that minimizing the KL-divergence between the parametric policy and the optimal policy by SGD will converge to the optimal policy, which is straightforward and is not what AlphaGo Zero does.			MET_RES
The effect of the imperfection in the target policy is not taken into account in the paper.			NONE
Furthermore, the robust MDP view of the AGZ in sequential decision-making problems is not so impressive either.			MET
It is more or less like a reformulation of the AGZ setting in the MDP problem. And it is commonly known that two-player zero-sum game is closely related to minimax robust control. Therefore, it cannot be called as “generalizing AlphaGo Zero” as stated in the title of the paper.			NONE
It isn’t clear why the particular proposals are necessary or to which of the proposed extensions the inflated OOD uncertainties can be attributed:			MET
2. The  objective? The proposed objective,  Eq 5, trades off stochastically approximating the (conditional) marginal likelihood against not deviating too much from p(\theta) =  MN(0, I, I) in the KL sense.			MET
It is unclear how important this particular objective is to the results.			RES
-  Instead of relying on the KL regularizer, a standard approach to learning the model in Eq 3 would be to use well understood MCMC or variational methods that explicitly retain uncertainty in \theta and induce predictive uncertainties.  Were they explored and found to be not effective?			MET
3.  Or simply to a well tuned \lambda, chosen on a per dataset basis? From the text it appears that \lambda is manually selected to trade off accuracy against uncertainty on OOD data.			MET_DAT
In the real world, one would not have access to OOD data during training, how is one to pick \lambda in such cases?			DAT_EXP
a) The uncertainties produced by CDN in Figure 2 seems strange.			TNF
Why does it go to nearly zero around x = 0, while being higher in surrounding regions with more data?			DAT
b) Down weighting the KL term by lambda for the VI techniques unfairly biases the comparison.			MET
This forces the VI solution to tend to the MLE, sacrificing uncertainty in the variational distribution.			NONE
However, this can be tricky in practice since it requires having an estimate for Q_r(s,a) as a function of the state (in order to ensure that the state-dependent lower bound can indeed be satisfied).			MET
However, this paper rather than proposing solution address the meta-learning problem, albeit the title “meta domain adaptation”, only brings few-shot learning to domain adaptation.			NONE
The problem with the current model is that during training, it is trained to target at one specific type of test domain--the generator network G aims to generated images that align with the unsupervised  test domain X_test.			NONE
Thus, the trained model will also only be able to handle one test domain, not much different than regular meta-learning models.			MET
In short, the meta-learning part stays in the regular few-shot learning module (which is implemented as a prototypical network), and has nothing related to domain adaptation.			MET
Specifically, what if the few-shot learning component is removed, and the network is trained with standard domain adaptation.			MET
Note: after reading the comments updated by authors, I remain my opinions: even though exact meta-testing data is unseen during training, the domain is seen during training, and therefore it cannot be qualified for being "meta domain adaptation".			DAT
Obviously there must be some false ranking (specially at the initial stages of updating the classifier) for the unlabeled samples (e.g. the classifier may output high entropy for the unlabeled samples of the classes with labeled samples) and they may harm the performance of adaptation.			NONE
It is not clear how MULANN can work in this situation and how its performance vary with the noisy signals conveyed in those false pseudolabeled samples.			MET
- can you motivate why you are not using perplexity in section 3.2?			MET
-The average distortion metric (that’s unfavourable to your method anyway) doesn’t really mean anything as the constraint optimization has no incentive to find a value smaller than the constraint.			MET
I did not see any theoretical or empirical support for this in the paper.			NONE
- I am not sure what the authors mean by “the Frank-Wolfe gap is affine invariant”. If we scale the input space by a, the gap should be scaled by a^2 - how/why is it invariant?			MET
- In remark 4.8 in the end option I and II are inverted by mistake			MET
- In 5.1, imagenet results are normally top-5 error rate not top-1 acc, would be better to report that more familiar number.			RES
- In the proof you wrongfully use the term telescope sum twice, there is nothing telescopic about the sum it is just bound by the max value times the length.			MET
- Authors claim to identify a fundamental problem with the existing generative models for point clouds, yet Section 2 tries to show that a _specific version_ that uses DeepSet does not satisfy theoretical guarantees. What if we use e.g. a recurrent network instead?			MET
- It is not clear why authors did not follow the evaluation protocol of [Achlioptas’17] or [Wu’16] more closely.			RWK
- I don't understand why the authors say that their space "interpolates smoothly" just because the limit in the curvature is the same from the left and right side.			MET
- One thing that I didn't see discussed by the authors is that there are subtle difference between hyperbolic and spherical spaces.			MET
For example, the weighted midpoint of Def. 3.2 doesn't immediately extend to spherical space (or at least won't be unique).			MET
You probably have to limit the operation to a half-sphere (there's some ideas for this in Gu et al).			RWK
- For the synthetic tree, why is the number of edges 2(|V|-1) rather than |V|-1?			MET
- In the appendix, the statement "Sarkar (2011) show that a similar statement as in Theorem 2 holds for a very general class of trees" is confusing to me. The "general class", as far as I know, is actually *all* trees, weighted or unweighted.			MET_RWK
However, the implementation details are hazy, and some design choices (which operations, hyperparameters etc.) aren't well justified.			MET
- What are the motivations to use Frank-Wolfe ? Usually this algorithm is used when the constraints are to complicated to have a tractable projection (which is not the case for the L_2 and L_\infty balls) or when one wants to have sparse iterates which do not seem to be the case here.			MET
- There is no motivations for the use of $\lambda >1$ neither practical or theoretical since the results are only proven for $\lambda =1$ whereas the experiments are done with \lambda = 5,20 or 30.			RES_EXP
- In Theorem 4.7 an expectation on g(x_a) is missing			MET
- Sec 3.1 theta_i -> x_i			NONE
- Sec 3.3 the argmin is a set, then it is LMO $\in$ argmin.			MET
- p8par1: "approximate embedding $\alpha(e(\gamma'(...)))$ - $e$ is undefined and should probably be $e'$ (this is also the case in the caption of Fig. 5), and $c'$ should probably be included as well.			TNF
- One drawback is that this method requires the mask during training. How can it be adapted for scenarios where the mask is not present? In other words, we only see multiple modalities as input, but we are not sure which are noisy and which are not?			MET
I am still a bit confused about the difference between "zero-confidence attacks" and those that don't fall into that category such as PGD.			MET
Since all of these are approximations, and we cannot know how far we are from the true margin, I don't see why these categories help.			MET
The authors spend two paragraphs in the introduction trying to draw a distinction but I am still not convinced.			INT
The proofs provided by the authors assume that convexity and many assumptions, which makes it not very useful for the real world case.			NONE
My main concern is that sampling the target values for the unobserved modalities from the prior would almost necessarily lead to blurry synthetic “ground truth” for these modalities, which in turn means that the model would produce underconfident predictions for them.			MET
The samples from MNIST in Figure 3 are indeed very blurry, supporting this.			TNF
Furthermore, it is not obvious to me why these prior samples would be sensible at all, given that all modalities have independent latents by construction.			MET
* The paper states multiple times that VAEAC [Ivanov et al., 2019] cannot handle partially missing data, but I don’t think this is true, since their missing features imputation experiment uses the setup of 50% truly missing features.			RWK
However, all experiments only show results in the MCAR setting, so the claim is not experimentally validated.			EXP
* The experiments do not demonstrate that the model learns a meaningful *conditional* distribution for the missing modalities, since the provided figures show just one sample per conditioning image.			EXP
1. Could you comment on the differences in your setup in Section 4.1 compared to the VAEAC paper? I’ve noticed that the results you report for this method significantly differ from the original paper, e.g. for VAEAC on Phishing dataset you report PFC of 0.24, whereas the original paper reports 0.394; for Mushroom it’s 0.403 vs. 0.244. I’ve compared the experimental details yet couldn’t find any differences, for example the missing rate is 0.5 in both papers.			RWK_RES
7. ``Our experiments show that our networks can remember a large number of images and distinguish them from unseen images’’ -- this does not seem to be true, since the model is trained on both n as well as N -n ``unseen’’ images which it labels as the negative class, thus the negative class is also seen by the memorization model.			EXP
Without any comparisons it’s hard to tell how difficult the tasks under consideration are and what would amount to good performance on the held-out tasks.			MET
3. What are the limitations of the F-pooling? It is good to me that the authors discuss one limitation on the imaginary part of output and I would like to hear more on other potential limitations for this method.			MET
Besides some issues in the technical details, the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.			MET
However, based on the definition of \theta and \tilde{\theta} given in the first sentence of section 2.3, the relation between \theta, \tilde{\theta} and D			MET
Either case, I don't think we can have the inequality in eq. (5).			MET
The usefulness of the approach is also lessened by the greater importance of the choice of the optimizer.			MET
Additionally, I find the motivation for caring about local optimality unconvincing.			NONE
e.g: REINFORCE has lower best-sample to total-sample ratio but its solutions are worse)			RES
- In order to pre-train the discriminator network, additional (s,a,s') experiences are required, thus it seems difficult to say that it is better for exploration than VIME.			MET
The convergence analysis is on Z, not on parameters x and hyper-parameters theta.			ANA
So, bounds here can not be used to explain empirical observations in Section 5.			NONE
1. I had hard time to understand latent canonicalization.			MET
Do you mean that each latent variable is fixed to a value, such that this factor of variation is disabled? Are the canonicalizers pre-specified using meta-labels? Are they updated/learned during model training?			MET
More explanation of canonicalization is needed.			MET
Perhaps an example in linear algebra is needed.			NONE
2. The learning of the proposed model relies on meta-data description such that the learning is supervised. Can the method be applicable to situations where no meta-data and no class labels are available?			MET
3. How can the proposed method be generalized to non-image data?			MET
The experiments were only done on simple image datasets.			DAT_EXP
I am wondering this method can be applied to other complex datasets whose latent factors are unknown.			MET_DAT
However, it seems a little unexplainable to apply a technique developed from classification to analyze RNNs, since the main task of RNNs never should be classification.			MET
I wonder the motivation of analyzing generalization of RNNs by the techniques established by Bartlett.			MET_RWK
It did also not match any numbers in Tab. 4 of the appendix.			TNF
I also have concerns about the independence assumption in their sampling distribution (Section 3.2), and the fact that their experiments use the same set of (untuned) hyperparameters for each method.			MET_EXP
2. The distribution proposed in section 3.2 assumes independence between the elements $x_j$. This seems problematic for some relatively simple problems.			MET
3. In the experiments, there are large discrepancies between different optimizers on Cakewalk (e.g. SGA vs AdaGrad, Table 4).			EXP
Is there any explanation for this?			MET
It seems like a large assumption that the same learning rate would work for different methods, especially when some of them are normalizing the objective function.			MET
The reason for this is only given in a single sentence at the end of Section 6, so it is a little confusing.			NONE
The comparison of different observation representations doesn’t include any analytical component, the empirical component is primarily inconclusive, and the position statements are fairly non-controversial (and not really conclusively supported).			MET
- doesn’t answer the one question regarding observation representation that it set out to evaluate			MET
- presumably, the sample complexity is ridiculous			MET
Dealing with highly stochastic environments seems a potential fatal flaw of the assumptions of this method.			MET
To start with, the set of rotations R(phi, nu, 0) called the alt-az group in this paper is not a group in the mathematical sense.			MET
This easy to see, because a composition of rotations of the form Rz(phi) Ry(nu) is not generally of that form.			MET
This would mean that the layer is actually SO(3)-equivariant, but it has been proven [1], that any rotation equivariant layer between scalar spherical feature maps can be expressed as an azimuthally isotropic convolution.			MET
Since the alt-az convolution is not isotropic and maps between scalars on S2, it cannot be equivariant.			MET
This also becomes apparent in the experiments section, where rotational data augmentation is found to be necessary.			DAT_EXP
But it is easy to see that eq. 10 will give different results for each of these coordinates, because they correspond to different rotations of the filter about the Z-axis.			MET
In particular, I believe that any algorithms you compare against, you should optimize both G and theta, since optimizing purely the hardware is unfair.			MET
You should use an existing ES implementation (e.g., from some well-known package) instead of a naive implementation, and as additional baseline also CMA-ES.			MET_RWK
This statement is ambiguous and potentially unsupported by evidence. how do you define complex? that can or that did discover?			MET
This is rather subject, and I would tend to disagree.			NONE
What is the point that you are trying to make? Also, note that some of the algorithms that you are citing there have indeed applied beyond architecture search, eg. Bayesian optimization is used for gait optimization in robotics, and Genetic algorithms have been used for automatic robot design.			RWK
- The stated contributions number 3 and 5 are not truly contributions.			NONE
#3 is so generic that a large part of the previous literature on the topic fall under this category -- not new.			RWK
#5 is weak, and tell us more about the limitations of random search and naive ES than necessarily a merit of your approach.			MET
- Sec 2.2: "(GNNs) are very effective" effective at what? what is the metric that you consider?			MET
- Sec 3 "(PS), where weights are reused" can you already go into more details or refer to later sections?			MET
- Sec 3.1: the statements about MB and MF algorithms are inaccurate.			MET
- Sec 4.1:			MET
- Providing the same computational budget seem rather arbitrary at the moment, and it heavily depends from implementation. How many evaluations do you perform for each method? why not having the same budget of experiments?			MET_EXP
- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates.			ANA
The authors claim that some amount of noise can be tolerated, but do not quantify how much.			RES
- A.4 makes it sound like eps_t needs to be assumed to be bounded, when all that is required is the bound on eps_0.			MET
However, when there is no defense deployed in the training process, it is not intuitive to see why the proposed attack is more effective and persistent than the centralized attack, given that a smaller trigger usually results in a worse attack performance.			MET
Thus, I would like to see more possible explanation on it.			NONE
It is not natural to decompose such kind of patterns into several smaller pieces, unless the performance is significantly boosted.			NONE
1. The classification of base class into super classes seems questionable to me.			MET
Hence, to characterize different tasks, as far as I am concerned, the classification should take both the graph G and the label Y into consideration, instead of solely the graph.			MET
2. Though seemingly very important to the architecture, the purpose of constructing the super-graph g^{sup} in the training of C^{CAT} seems to be unclear to me.			EXP
It seems that the authors are not aware of this difference.			NONE
I do not see in the updated paper that this typo (in differentiating D in hinge loss and non-saturating loss) is corrected.			NONE
- I don't see a discussion about the downsides of the method (for example, the large number of triplet comparison examples needed for training; and possible methods to overcome this problem).			MET
- in section 4.3, there is no guarantee that the intersection between the training set and test set is empty.			DAT
The reparameterization trick does not apply to all continuous random variables, only to such that the reparameterization satisfies certain smoothness conditions.			MET
Discrete variables are supported by the method only in the case that the distribution factors over all discrete variables conditionally on any additional “continuous variables” (to which the reparameterization trick is applicable).			MET
A Bernoulli(p) random variable is discrete, yet it is reparametrizable as [Z>p] with Z following standard logistic distribution, whose density and cdf is smooth.			MET
The notation of the true distribution as “q” the model as p and the approximate posterior of the model as “q” again is inconsistent.			MET
Equations (5) and (6) require a theorem of differentiating under integral (expectation), such as Leibnitz rule, which in case of (6) requires q_gamma(y)f(y) to be continuous in y and q_gamma(y) continuously differentiable in gamma.			MET
- Some assumptions are not explicitly stated.			MET
This is also lacking from the description of the experimental protocol, which does not address the data-splits (how many classes were used for each) and size of the unlabelled test set.			DAT_EXP
- The overall method seems to be not very principled, and requires a lot of "tweaks and tunes", with additional losses and regularizers, to work.			MET
Also, the definition of mutual information used in this paper uses the inferred distribution q (e.g., in eq. 2), which is somewhat unusual.			MET
Authors should analyze the stability of their method in details.			MET
1. The observation that gradients explode in spite of BN is quite counter-intuitive. Can you give an intuitive explanation of why this occurs?			MET
I think having this in mind, showing the convergence of Theorems 3.2-3.4 is somehow trivial.			MET
5) In Theorem 5.2, the term 1/sqrt(2) is missing from the final bound.			MET
Having this in mind note that the theoretical results on stochastic variant presented in the paper are wrong.			RES
The authors either need to remove these results or restate them in a different way in order to satisfy the assumed conditions.			RES
The use of “blank inputs (referred to as “thinking steps”)” in “Simple LSTM” and “Attentional LSTM" doesn’t seem to be a standard approach.			MET
In the attentional LSTM, the use of “parse LSTM” is also not a standard approach in seq2seq models and doesn’t seem to work well in the experiment (similar result to “Simple LSTM").			MET
They start from Equation (4) which is incorrectly denoted as the log-marginal distribution while it is the same conditional distribution introduced in Equation (3) with the extra summation for all the available data points.			MET_DAT
Furthermore, in the beginning of Section 3.1 the authors present their idea on probabilistic hypernetoworks which “maps x to a distribution over parameters instead of specific value \theta.” How is this different from the case that we were considering so far? If we had a point estimate for \theta we would not require to take an expectation in Equation (3) in the first place.			PDI
Roughly, the theorem states that if for example we fix any matrix B of size e.g. 256 x k and matrix U of size 512 x 256 and then compute U relu(B C) where C is the vector of parameters of size k x 1, AND if k < 2.5 (i.e. if we use at most 2 parameters), then it would be very hard to fit 512 iid gaussian values (i.e. min_C ||U relu(B C) - eta|| where eta ~ N(0, 1)).			MET
The presented analysis seems to neglect the error term corresponding to the value function.			ANA
From my experience, aligning embedding spaces is something that usually does not work very well, especially in high dimension.			MET
The role of \sigma seems very redundant given \omega.			MET
The cited Berrett and Samworth MI test uses a permutation approach to obtaining the test threshold, not an asymptotic approach  (see the results of Section 4 of that paper).			RWK
How is this a reasonable assumption?			MET
Considering the optimization problem involved in the learning process, it is hard to judge whether the effect of such a procedure from the optimization perspective.			MET
B. You don't schedule learning rates for your baseline methods except for a single experiment for some initial learning rate.			EXP
C. Your method involves a hyperparameter to be tuned which affects the shape of the schedule.			MET
This hyperparameter itself benefits from (requires?) some scheduling.			MET
The more interesting question of how to generalize to unseen items (how would that be possible given that items have no representation at all) is not discussed at all and seems not to be realizable, which makes the starting point of such methods (items have no representation) questionable.			MET
8. The itemized part in 5.3, "...carefully selected baselines: 1.xxx, 2.xxx, 3. xxx, 4. xxx". However, both 3 and 4 are not baselines!			RWK
-	The paper has a specific form of formulation for abductive reasoning, where there are exactly two observations and one proceeds the other; the explanation happens in between. I can see this helps collect and annotate data, but also limit the form of abductive reasoning and how models should be developed.			MET
When optimizing the compression rate, it is important not to look at the test set error.			NONE
If the compression rate is optimized on the test set, then the compressed model is nothing but a model overfit to the test set.			MET
Optimizing compression rates should be done on the training set with a separate development set.			DAT
The test set should not used before the best compression scheme is selected.			DAT
I do not see these experimental settings mentioned anywhere in the paper, and this is very concerning.			EXP
Lee et al. seem to make similar mistakes, and it is likely that their experimental design is also flawed.			RWK
The paper also lacks experimental results, and the main conclusion from these results seems to be "MNIST is not suitable for benchmarking of adversarial attacks".			RES
1) The problem it aims to solve is neither multi-task learning nor meta-learning: it tries to solve a supervised classification problem defined on principle classes, with the help of simultaneously predicting/generating auxiliary class labels.			NONE
The two things that make me more skeptical, is the convergence of the proposed algorithm and the experiments.			MET_EXP
I am a making a recommendation for reject for this paper with the main reason being that I believe the primary derivations for their method appear flawed.			MET
--In the main section describing the approach (Section 4), the authors start with a claim that Equation 1 and 2 are equal; I don’t believe 1 and 2 are equal.			MET
--In Section 4.1, it appears that they are instead making a claim about Equation 2 being a bound for equation 1; but even this derivation appears to have a problem.			MET
If one were to interpret the second one as the unnormalized distribution on z defined via the likelihood for c given z; even this has an issue because then the expression for KL where we plug the unnormalized density in place of the normalized need not be positive which is something they need to derive their bound.			MET
--Another issue is that the regularization lambda should apply to both the terms in the bound but in Equation (7) only appears selectively for one of the two terms.			MET
--“Redundant weights” seems like not a very strong constraint especially for a small cardinality label space (like 10, in the case of this paper).			MET
In fact, there is more to the Byzantine setting than that,			NONE
Otherwise, some poorly performed models could lead to near-random or adversarial inter-model discrepancies, failing the proposed approach.			MET
Another potential issue is that the proposed approach cannot handle training set bias. If all models are biased in similar ways (e.g., toward a particular class or domain), they will not reveal informative discrepancies for the images over which they all make similar mistakes.			MET
The unlabeled set is not "unlabeled" in essence. If my understanding was correct, it cannot contain open-set images which do not belong to any of the classes of interest.			NONE
It is also nontrivial to control that the images contain only one salient object per image.			NONE
Hence, while I agree with the authors that existing approaches to comparing deep neural network classifiers could be improved, I think the proposed solution is not a good alternative yet.			MET
Comparison to "SGD BN removed" is not fair because the initialization is different (application of BN re-initializes weight scales and biases).			MET
- It seems that the model is not very scalable; while the authors do provide a way of reducing the necessary parameters that the hypernetwork has to predict, minibatching can still be an issue as it is implied that you draw a separate random weight matrix for each datapoint due to the input specific distribution (as shown at Algorithm 1).			MET
Is this how you implemented minibatching in practice? How easily is this applied to convolutional architectures?			MET
- How many samples did you use from p(theta|x) during training?			DAT_EXP
When you say that full-matrix computation "requires taking the inverse square root", I assume you know that is not really correct?			MET
As a matter of good implementation, one never takes the inverse of anything.			MET
There are several issues convolved here: one is ``full-matrix,'' another is that this is really a low-rank approximation to a matrix and so not full matrix, another is that this may or may not be implementable on GPUs.			MET
The latter may be important in practice, but it is orthogonal to the full matrix theory.			NONE
There is a great deal of discussion about full-matrix preconditioning, but there is no full matrix here.			MET
It is difficult to know what the theory says about the empirical results, given the tweaks discussed in Sec 2.2, and so it is difficult to know what is the benefit of the method versus the tweaks.			MET
You say that you "informally state the main theorem."  The level of formality/informality makes it hard to know what is really being said.  You should remove it if it is not worth stating precisely, or state it precisely.  (It's fair to modularize the proof, but as it is it's hard to know what it's saying, except that your method comes with some guarantee that isn't stated.)			MET
"Table 4 shows that our first results are promising, even though they are not as good as the state of the art." The state of the art on LibriSpeech is not Mohamed at al. 2019. See e.g. Irie et al. Interspeech 2019 for better result			RES
How would the given graph network compare to this?			MET
However, the original performance of the hand-engineered design is surprisingly bad (see first data point in any plot in Figure-4).			NONE
Does the controller also start from scratch? If so, why? Also, it is not clear what is the meaning of generations if the graph is fixed, can't it be learned altogether at once?			MET
Overall, this is a reasonable paper but experimental section needs much more attention.			EXP
Could it be that what we are seeing is the attack being denoised?			MET
I am puzzled and looking forward to answers to the above questions. I don't yet understand what is the thing that makes this approach appear to work, or why you were able to drop the Bayes inference inversion altogether as done by Schott.			MET
Does such approximation guarantee the policy improvement?			MET
Any justification?			NONE
(6) If the authors jointly and simultaneously optimize \theta and \phi, why a regularization term about q_{\phi}(z)  is missing in Eq 12 while a regularization term about \pi_{\theta|z} does appear in Eq 12?			MET
For Figure 2, Did you try applying canonicalizations in different orders? Do they give the same results?			TNF
There might be other constructions that are more efficient and less restrictive.			MET
I disagree on the importance of the numbers reported on the abstract: DenseNet on Cifar10 with 60% goes from 53.34 to 74.72.			NONE
Therefore, I don’t find interesting to report how DDGC improve upon “no baseline”, because known methods do even better.			MET_RWK
Regarding the experiments on adversarial examples, I am not convinced of their relevance at all.			EXP
One more unclear but important point: is Table 3 obtained by white-box attacks on the Resnet/Denset but oblivious of the MCD? Is so, I don’t think such an experiment tells the whole story: as the the MCD would arguably also be deployed for classification, the attacker would also target it.			NONE
I don’t follow this argument: this is just part of the classifier. White box attacks are by definition performed with the knowledge of the model, what			MET
Table 8 rises some concerns.			TNF
I appreciate the idea of testing full white-box adversarial attacks here. But I don’t understand how it is possible that DDGC is more robust, with higher adversarial test accuracy, than in Table 3.			MET
This aspect of the task seems somewhat contrived, and it makes me wonder whether the striking failure of the non-modulated RNNs depends on this detail.			MET
However, the experimental comparison is not fair, the description of the model (e.g. how Choquet is integrated into the model and help to learn “intermediate meaningful results”) is not clear, some claims are not true.			MET_EXP
The major concern I have is that the ensemble of MC-Dropout models is not an approximation of the posterior anymore.			MET
Each MC-Dropout model is an approximation of the posterior, but the ensemble of them may not.			MET
Therefore, it is a little misleading to still call it Bayesian active learning.			MET
Also, the ensemble of MC-Dropout models does not have the theoretic support from the Bayesian perspective.			MET
The motivation for the proposed method is to solve the mode collapse problem of MC-Dropout, but using ensemble loses the Bayesian support benefit of MC-Dropout.			MET
So it seems not a reasonable solution for the mode collapse problem of MC-Dropout.			NONE
Since this paper select the top-k images in D, if k is large the annotating for S will be very tedious, however if k is relatively small the method seems very sensitive to selected examples, which will make the comparison not totally convincing.			MET
My major concern is that the authors assume the hyperparameters to be independent (section 3.2), which is not necessarily true.			MET
Specifically, prior work considered non-missing data during training, while we can't always guarantee that all the modalities are available.			RWK
1. [The claim] One of my concerns for this paper is the assumption of the factorized latent variables from multimodal data.			DAT
Specifically, the author mentioned Tsai et al. assumed factorized latent variables from the multimodal data, while Tsai et al. actually assumed the generation of multimodal data consists of disentangled modality-specific and multimodal factors.			RWK
It seems to me; the author assumed data from one modality is generated by all the latent factors (see Eq. (11)), then what is the point for assuming the prior of the latent factor is factorized (see Eq. (4) and (5))?			MET_DAT
The author should comment on this.			NONE
a. In Eq. (3), it surprises me to see the symbol \epsilon without any explanation.			MET
b. In Eq. (6), it also surprises me to see no description of \phi and \psi.			MET
h. Generally speaking, the paper does require a significant effort to polish Section 3 and 4.			NONE
4. [Experiments.] The author presented a multimodal representation learning framework for partially-observable multimodal data, while the experiments cannot corraborrate the claim.			EXP
First, I consider the tabular features as multi-feature data and less to be the multimodal data.			DAT
Second, the synthetic image pairs are not multimodal in nature.			NONE
These synthetic setting can be used for sanity check, but cannot be the main part of the experiments.			EXP
Also, since the synthetic image pairs are not multimodal in nature, it is unclear to me for what the messages are conveyed in Figure 3 and 4.			TNF
I am also not			NONE
6. I am not sure how interesting this work will be for the ICLR audience,			NONE
While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs.			MET_RWK
- why do you need a conditional GAN discriminator, if you already model similarity by L1?			MET
Instead here you seem to suggest to use L1 and GAN to do basically the same thing, or with significant overlap anyways.			MET
This is confusing to me.			NONE
Please explain the logic for this architectural choice.			MET
However, when the weights are set to zero the weight matrix became sparser but still requires the whole weight matrix to be used by the computing resources, as removing some of the weights based on the sorting will not remove a node, only removes some of the connection with that node.			MET
Therefore, it is not clear how the proposed framework is helping the model compression techniques.			MET
Also, the fact that the accuracy on the Kaggle non-doctored test set is low is simply because the test set is not coming from the same distribution of the training set.			DAT
Thus, based on this approach, the reconstruction image may not be optimal with respect to the resolution which might be critical for cryo-EM reconstruction.			MET
1. The presentation is somewhat convoluted.			OAL
Moreover, as observed by the authors this analysis currently rely on strong assumptions that might make it rather unrealistic.			ANA
It is not even clear that the final compression of the baselines would not be better.			RWK
Even if they did show these convincingly, it is not obvious to me that it is valuable; the authors need to *show* that uniform usage is desirable.			NONE
Even without the "train to convergence" question above, I don't think the authors have demonstrated that their claims on the properties of their algorithms/formulations are generally true.			MET
From the experimental perspective, the experimental evidence on "invertible boolean logic" does not seem to be very convincing for validating the approach.			EXP
However, it does exclude some popular activation families, such as the polynomial activation, which were proven effective in multiple areas.			MET
Overall, I feel that the result is interesting but it depends on a strong assumption and doesn't capture all interesting cases.			RES
It is also not clear how this theoretical result can shed insight on the empirical study of neural networks.			RES
- It is not clear whether pushing the catastrophic forgetting problem into the generator is the best approach.			MET
As such, I find it surprising that simply storing instances would do as poorly as stated in this paper which says cannot provide enough diversity.			MET
It also seems strange to say that storing instances "violates the strictly incremental setup" while generative models do not.			MET
1. The approach is not well justified either by theory or practice.			MET
The setup where labeled data (c) also seems a bit unnatural (this also seems to be confirmed by the fact that the authors had to build datasets for the problem).			DAT
There is a key concern about the feasibility of the numerical analysis for the first part.			ANA
That is, a layer-by-layer study can have a computational problem where the preimage is finite at each layer but can become infinite by the mapping of the preceding layers.			NONE
(b) a significant clarification of Figure 4.			TNF
When I look at Figure 4abcd, it appears that the Convolution and Dilated Convolutions fit a clean signal faster (it is just not as clean.			TNF
Additionally, the Wave-U-Net appears to reach the same accuracy as the Harmonic Convolution with many fewer iterations (while also continuing to get much higher PSNRs).			MET
Perhaps I am misreading this plot, but it is not obvious to me that this plot supports the claims the authors are making.			TNF
A significant concern/confusion for me is that this doesn't seem to be a mixed membership model, and so I don't know how meaningful it is to generate a level distribution from a Dirichlet and then draw from that mixture one time.			MET
My understanding is that this isn't being done here.			NONE
- although the paper does not expose this point (it is discussed the HER paper)			NONE
Moreover, the equation J_DIM seems to be wrong since it contains g_\omega twice while I think (but maybe I am wrong) that it has also to be defined by g_\psi.			MET
One other limitation seems to be that Theorem 1 requires using a step size which seems to be much smaller than what one may hope to use in practice. Can you comment on this?			MET
It is a minor weak point that the algorithm can work only when the abstract state is obtained by the RAM state.			MET
In some RL tasks, it is not allowed to access the RAM state.			MET
Although this paper contains interesting idea and results, as other reviewers pointed out, it is very hard to compare with other algorithm.			NONE
The algorithm assumptions are strong.			MET
- Some arguments that are presented could deserve a bit more precision.			NONE
Memory and computation limitations are mentioned, but not sufficently discussed.			NONE
The authors state that proposed framework can be added to any baseline model, but miss to clearly mention the limitations.			MET
It is stated that future work will aim at scaling PeerNets to benchmarks like ImageNet, but it is unclear how this could be done.			NONE
Given the very specific nature of the topic treated in the paper I find the title of the paper largely misleading.			NONE
The title claims way more than what is actually delivered in the paper, despite the fact that the authors have put in an "On" in the beginning of the title.			INT
The final sentence in Section 2 is highly speculative and I find this hard to believe without solid backing.			NONE
The sentence reads "... and helps develop intuitions about behaviors observed in more general settings." Given the restrictive nature of your set-up I find it very hard to believe that this extends to more general settings.			MET
PS: After discussion, I think the motivation of the method is not clear to understand why the proposed method works.			MET
1. Experimental settings are clear, however, what makes me confused is that the construction for p_{\bar{d}} is straightforward for simple distribution like 2D points dataset, however, it might be intractable for complex high dimensional data such as images.			DAT_EXP
Thus, the above claim made in the paper does not seem well-founded.			NONE
Furthermore, in experiments, the paper does not provide any quantitatively convincing results to suggest the generator in use is a good one.			RES_EXP
- While the authors suggest that a latent model over the input distribution needs to be trained only once and is applicable off-the-shelf for any further contrastive explanations regarding any network operating on the same dataset -- learning such a model of the input space is an overhead in itself.			MET
- Typographical Errors: Section 3.1 repeats the use of D for a discriminator as well as the input distribution.			MET
Procedure 1 and Procedure 2 share the same titles -- which is slightly misleading.			MET
Since, there is no clear metric to evaluate contrastive explanations -- human studies to judge the class-discriminativeness (or trust) of the proposed approach would have made the paper stronger.			MET
It is not well explained in the paper how this proxy correlates with the Learning progress criteria.			MET
- The way the authors adapt the modulation z (or at least its description in the paper) seems not technically sounded for me.			MET
- Is there actionable consequences one could draw from your papers? The way the results are presented seem like they are only useful inspection after training; are your results able to derive methods to enforce conditions on the pre-images for example?			RES
The experiments are not very convincing or illustrative of the theoretical results in my opinion.			EXP
It is not clear how those observations can affect practical algorithms and this is something I hope the author can address.			MET
I could see this being an issue when episode length is too long.			NONE
However, in this way, when more and more tasks come, the generator will become larger and larger.			MET
The storing problem still exists.			NONE
Finally yet importantly, though a large number of works have been proposed to try to solve this problem especially the catastrophic forgetting, most of these works are heuristic and lack mathematical proof, and thus have no guarantee on new tasks or scenarios.			RWK
The proposed method is also heuristic and lacks promising guarantee.			MET
First, the mechanism provided has no mathematical justification--it seems fairly arbitrary.			MET
I have a substantial concern that this method might end up assigning a high likelihood of resampling trajectories where something unusual happened, not because of the agent's actions, but because of the world having made a very unusual stochastic transition.			MET
If that's true, then this distribution would be very bad for training a value function, which is supposed to involve an expectation over "nature"'s choices in the MDP.			EXP
Second, the experiments are (as I understand it, but I may be wrong) in deterministic domains, which definitely does not constitute a general test of a proposed RL  method.			EXP
- I'm not sure we can conclude much from the results on fetchSlide (and it would make sense not to use the last set of parameters but the best one encountered during training)			RES_EXP
Also, Figure 6 is referenced in the text in the context of binary multiplication ("[...] is able to outperform a multiplier created just by training, as can be seen in Figure 6"), but presents results for addition and factorization only.			TNF
However, the assumption is too strong.			MET
- In addition, the paper provides the standard deviation for the mean deviations over 100 fits of the function as the measure of its uncertainty, but I suspect that the optimizer converging to different coefficients at different runs isn't the main source of uncertainty.			NONE
A bigger source of uncertainty is likely due to there being a limited amount of data to fit the coefficients to.			DAT
* p.3 third paragraph: you repeat yourself in math notation a few times here.			NONE
third paragraph: Your claim of invariance to time rescaling is technically correct, but I am not convinced that a model can learn the correct omega values for an arbitrary rescaling (e.g. if the period is smaller than the time unit).			MET
(5) The authors override the CW distance: first in Theorem 3.1 they define it as a distance between two finite point clouds, and later in Theorem 3.2 they redefine it as a distance between a point cloud and the Gaussian distribution.			MET
Other recent works which have demonstrated effective regularization of LSTM LMs have proposed methods that can be used in any LSTM model, but that is not the case here.			RWK
The loss term is motivated by the idea that we want the output distribution to retain some information about the context, but why should that be the case?			MET
However, the proposed technique does not seem to be handling the problem foundationally well.			MET
-The proposed technique seems to include very heavy feature engineering and several ad-hoc practical steps--that is far from the motivation of using NN in tabular data.			MET
- In Table 1, for ImageNet, Shadow Attach does not always generate adversarial examples that have on average larger certified radii than the natural parallel, at least for sigma=0.5 and 1.0. Could the authors explain the reason?			TNF
- In Table 2, it is not clear to me what is the point for comparing errors of the natural images (which measures the misclassification rate of a natural image) and that of the adversarial images (which measures successful attacks rate), and why this comparison helps to support the claim that the attack results in a stronger certificates.			TNF
- Sim(delta) should be Dissim(delta) which measures the dissimilarity between channels.			MET
The paper positions itself generally as dealing with arbitrary transformations T, but really is			MET
Moreover, if I understand correctly the WGAN analysis does not take into account that G and D are non-linear, and it is unclear if these can be done.			ANA
As the approach uses NF is derived specifically for unstable dynamics, it is not clear to me how adding it would affect the training if the dynamics *is stable*. In this context, I consider that for example, the work by Balduzzi et al. 2018 may be relevant as it describes that the dynamics of games (the Jacobian) has two components, one of which describes the oscillating behavior (Hamiltonian game); whereas most games are a mix of oscillating and non-oscillating dynamics.			MET_RWK
It is not clear to me if NF would improve stability/performances in general games.			MET
- Page 3, Eq. 5: as D and G are functions of time here, eq 5 should maybe be written in more detail to include t			MET
On the other hand, it is hard to say what the _main_ contribution is, which in turn makes it difficult to evaluate whether the experimental evaluation is sufficient:			EXP
However, this work, as far as I can tell, is separate from the MARL problem.			NONE
However, as far as I can tell, there is no difference between applying such a hierarchy to the MARL case and to the single agent problem.			MET
I also understand that HRL can reduce the number of parameters, but I don't see how structured exploration reduces the number of parameters.			MET
And lastly, I also can see how parameter sharing can simplify the learning, but I still don't see how it would allow agents to estimate the behaviour change of other agents easier.			MET
My concern here is that beta might be affecting the result more than the proposed training algorithm.			MET
How do performance and model size trade off?			MET
How were the number of layers and kernels chosen?			MET
Was the 5x10x20x10 topology used for MNIST the only topology tried?			MET
That would be very surprising.			NONE
It seems reasonable to suspect that the phenomenon may be due to a common cause in all three model types.			MET
Negative aspects: One major concern I have with the paper is the notion of privacy considered.			MET
The notion of privacy considered in the paper makes two assumptions which I am not comfortable with: i) The protection that the notion assures is against reconstruction attacks.			MET
There has been a large body of work which shows that weaker attacks like membership attacks can be equally damaging, ii) Privacy is a worst-case guarantee.			RWK
I do not see the GAN style approach taken by the paper, ensures this.			MET
The second issue I would like to raise is related to discussions around the non-universality of the vanilla PointNet model.			MET
Given the fact that it applies the same MLP independently to individual set members, it is obvious that it is not universal equivariant (for example, consider a function that performs a fixed permutation to its input), and I fail to see why the paper goes into the trouble of having theorems and experiments just to demonstrate this point. If there were any other objectives beyond this in the experiments could you please clarify?			EXP
I am a bit worried about the fact that the agents have access to their history of locations (“the grid”).			NONE
- I think the comparison between prior lifetimes and humans mastering a language doesn’t hold up and is distracting			MET
- It is good that Section 5 has some theoretical analysis. But I personally find it very disturbing to base it on a 2nd order approximation of a probability density function of images when modeling something as intricate as models that generate images.			ANA
At least this limitation should be pointed out in the paper.			NONE
- I don't think Glow necessarily is encouraged to increase sensitivity to perturbations.			NONE
The bijection needs to map training images to a high-density region of the Gaussian, and that aspect would make the model think twice before making the volume term too large.			MET
- Figure 6(a) clearly suggests that the data mean for SVHN and CIFAR are very different, instead of similar.			TNF
Section 5 is based on a 2nd order expansion on the $log p(x)$ given by a deep network -- I shouldn't be the judge of this, but from a realistic perspective this does not mean much.			MET
To evaluate the impact of the proposed changes in this paper, one would have to perform extended evaluations and ablations for the submission.			ANA
5. One of the anonymous comments on OpenReview is very interesting: samples from a CIFAR model look nothing like SVHN.			DAT
This seems to call the validity of the anomalous into question. Curious what the authors have to say about this.			MET
Minimization of Eq. 3 and Eq. 4 contradict each other and the objective function does not converge obviously.			MET
3) In the experiments, the accuracy values are too low for me.			EXP
I have some concerns on this paper:			OAL
Without such a guarantee, the proposed method is not very useful because we			MET
have no idea how confident the sampling based result is.			RES
Intuitively, it seems like it may be possible to construct counter-examples where the gradient updates will prevent convergence.			NONE
The justification that the method of Khadka & Tumer (2018) cannot be extended to use CEM, since the RL policies do not comply with the covariance matrix is unclear to me.			MET_RWK
Algorithm 1, step 20, the covariance matrix is updated after the RL step so regardless of how the RL policies are generated, the search distribution on the next distribution includes them.			MET
In both this work, and Khadka & Tumer, the RL updates lead to policies that differ from the search distribution (indeed that is the point), and there is no guarantee in this work that the TD3 updates result in policies close to the starting point.			MET
1. Why there is still a need to combine adaptive convolutions with regular convolutions? What would the model performance be for a model with only adaptive kernels?			MET
7.	The study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data.			DAT
Unfortunately, there is a bit of an identity crisis happening in this paper. There are several choices that do not follow based on the data the paper considers.			DAT
1) The paper claims to want to predict unordered sets, yet the model is clearly indicating a dependence in the order of the outputs and the input p_m(\pi | x_i, w) (1); this feels like a very odd choice to me.			MET
The outputs are either unordered sets, where you would have a permutation invariant (or exchangeable) likelihood, or they are ordered sequence where the order of the outputs does matter, as some are more likely than others.			NONE
2) The paper still makes very odd choices even if one ignores the above and wants to model some orderings as more likely than others.			MET
The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense.			DAT
I don't think this makes much sense, and if it was an intentional choice, the paper did a poor job of indicating it.			NONE
3) Supposing even still that one does want a mixture model with as many components as permutations, there are still some issues.			MET
It is very unclear how the dependence on \pi drops out when getting a MAP estimate of outputs in section 3.3.			MET
This needs to be justified.			NONE
There are some stylistic shortcomings as well.			NONE
Also, the paper claims that it will use a super script m to denote a known cardinality, yet omits \mathcal{Y}_i^{m_i} in the training set of the first sentence in 3.1.			MET
The paper should not be published until it can resolve or make sense of the methodological discrepancies between what it says it looks to do and what it actually does as described in points 1), 2), and 3) above.			NONE
This is actually a direct consequence of any minmax theorem in game theory; the authors decided to credit that result to Yao (I tend to *strongly* disagree with that point as, even if he stated this fact in CS, this result was quite standard several decades before him - anyway.).			MET_RES
It is not clear why the authors neglect these classical concepts, and are talking about 'random functional perturbations', ... It is also unclear where the optimized transformation (T) lives; the authors are trying to differentiate over some function space which is undefined.			MET
(3) I am slightly concerned about the sample complexity of keeping track of the probability of worker i finishing goal g within t steps with a bonus b. This scales linearly in parameters which usually would be large (such as the number of time-steps).			MET
However, although the proposed method achieves good performance over various (smaller) benchmarks, the method seems ad-hoc and complicated.			MET
1. The objective of the update equation of CTAugment’s learned weights seems contradicted with the purpose of how data augmentation is used in the consistency-based SSL method.			MET
It is not clear how well these methods scale, and for example using k=8 adds computation which may hinder training scalability.			MET
Regardless, nobody really uses human evaluation anymore - so this is just not correct.			NONE
and rendering the third claim from the introduction ("We propose an new algorithm with the new metric which demonstrates better results than state-of-the-art algorithms.") completely untrue.			INT_MET
The major issue I have with this paper is Theorem 3.1 on the ergodic convergence rate of the proposed PowerSGD.			MET
At the first glance, it is $O(\frac{1}{T})$ which is faster than the conventional SGD convergence rate $O(\frac{1}{\sqrt{T}})$.  But after a closer look, this rate is obtained by a very strong assumption on the batch size $B_{t}=T$.			MET
In other words, when the number of iterations is large, the batch size will be large too.			NONE
I consider this assumption unrealistic.			MET
In this case, it is basically a GD, not SGD any more.			MET
Actually in the experiments the authors never use an increasing batch size.			EXP
Therefore,  the faster convergence demonstrated in the experiments can not be explained by Theorem 3.1 or Theorem 3.2.			EXP
2. There are numerous inaccuracies in the proof given the supplementary material.			NONE
should be $\nabla f(x)^{T} \sigma(\nabla f(x))$   The random variable $\xi_{t}$ should be a scalar on training samples, not a vector, etc..  The authors should clean it up.			NONE
It's unclear how this would scale to more complex tasks with higher-dimensional state spaces such as Atari, Starcraft II or if this would work with tasks with continuous state and action spaces such as mujoco.			MET
4. The biggest flaw that I see in this method is the practicality of it's use.			MET
In very simple tasks, such as the one presented here, the authors were able to hard-code their own demonstration agent.			NONE
However, in harder tasks, this will not be feasible.			NONE
If you are able to obtain or code your own agent, then you've already solved the task and there is no need to do any sort of imitation learning in the first place.			MET
In reality, for sufficiently difficult tasks, a human would be the demonstration agent (as is done in most robotics tasks).			NONE
However, this task requires the learning to be interactive and thus the demonstrator needs to be present during the learning.			NONE
Thus, the question is 1) how well will this method work with a human acting as the demonstrator? and 2) how can this method work if you are not able to have access to a demonstrator long periods of time (or even at all)?			MET
However, the runtimes were a bit strange.			NONE
For example, ADP and ADP-T runtimes were very close on WikiText-103 dataset but very different on Billion Word corpus (Table 3 and 4).			DAT
To me these two reasoning statements are not particularly convincing. One could also say:			MET
While I agree with this to some extent, I also think this argument may not be fully right. When the probing agent is testing the expert, it is essentially showing the imitator many different configurations of the environment.			MET
It may not be that it changes in the first time step (for obvious reasons), but it is essentially showing it many configurations of the expert.			MET
A more drastic change of the environment could make for a stronger argument.			NONE
The Dual FW algorithm does not need to be used along with the hinge loss (SVM loss).			MET
Unless I missed something, the output of the CNN architecture is a probability value that the input formula is SAT, so I don’t really see how this can be related to prediction probabilities of assignments.			NONE
This should be explained in detail since Line 15 is the main output of the algorithm, which is fed (Line 16) to an existing solver for completing the assignment.			MET
The example at the end of section 3.3 is not very helpful: namely, the CNF formula $(x_2) \land (\neg x_2)$ is clearly unsatisfiable, so how can the model predict that it is satisfiable with 80% probability? And, if we try here $x_2 = 1$, we immediately get $\bot$ (the unsat CNF), but not $x_1$ (which was already assigned to $0$).			NONE
So, the motivating assertion “[...] state-of-the-art solvers do not yet scale to large, difficult formulas, such as ones with hundreds of variables and thousands of clauses” in the introduction of the paper, is not totally correct.			INT
The abstract mentioned that the proposed algorithm works as an “implicit regularization leading to better classification accuracy than the original model which completely ignores privacy”. But I don’t see clearly from the experimental results how the accuracy compares to a non-private classifier.			MET_RES
I am unconvinced that one frequently enough has access to a sufficiently large set of candidate source tasks for this to be a real practical issue.			NONE
- The metrics are tightly coupled to the encoder used, and no exploration of encoder architectures is performed.			MET
Page 4: Other Connections with Lower bounds: The first line " "we may also consider ... ". This line is vague. How will you ensure the amount of deformation is such that the set \bar{U} is contained in U ?			MET
Page 4 last paragraph: "One advantage ... complex architectures in practice" : True, but the tightness of the bounds *do* depend on "f" (specifically the RKHS norm).			NONE
It needs to be ascertained when equality holds in the bounds you propose, so that we know how tight they are. What if the bounds are too loose to be practical?			MET
This implies that the amount of work (in FLOPs) done by the algorithm (at least the version being analyzed) is quadratic in T, which makes the convergence rates a bit misleading.			MET
But a very similar assumption is hidden in the bounded-gradient-variance assumption Assumption 3.2; for example, Assumption 3.2 is clearly not satisfied by the least-squares regression problem			MET
As the norm of β goes to infinity, so does the expected norm of the error of \hat g. I'm not saying this is a particularly big			NONE
The empirical comparisons to UNIT are reasonably thorough, though I would have preferred more in-depth evaluation of the MoVE model as well.			MET
While I understand that quantifying performance in this application is difficult, I do find the results difficult to interpret.			RES
However, the more pressing issue is that evaluation is done either sample-wise within-domain (reconstruction), or distribution-wise across domains (transfer).			MET
The transfer metrics (MMD and kNN) are opaque to the reader: for instance, in table 1, is a knn score of 43173 qualitatively different than 43180?			TNF
Do people leave the negations in when modifying such examples for entailment or neutrality, thus breaking the simple correspondence?			MET
It would be easy to use ELMo here, if the main question is about Transformers vs recurrent models.			MET
However, I can not agree because you can simply generate poisoned data and train the neural networks on the poisoned data regardless of the underlying approach that is targeted in generating the poisoned data.			MET_DAT
Quality: Below average			OAL
I believe the proposed techniques have some flaws which hurt the eventual method.			MET
My concern is that the flaws in the method do not make it conducive to use as is.			MET
- (W1) Adversely affected by rotations: One of my big concerns with the work is the way the CFS is computed.			MET
This again greatly concerned me as I am not certain how stable these metrics are.			MET
I would have liked to see results for both trivial baselines like random ranking as well as more informed baselines where we can estimate transfer potential using say k representation techniques, and then use that to help us understand how well it would do on the other representations.			RWK_EXP
Based on my understanding the authors rank (which itself is questionable) the different tasks in order of potential for transfer and then call this the "gold" set. How is precision and NDCG calculated from this?			MET
The proposed  CLF weight difference method has some concerning aspects as well.			MET
Likewise looking at a difference of weight vectors seems arbitrary in other ways as well.			MET
Thus the metric is not a proper metric.			MET
As for GAN, due to the inexact update, it is not really solving the min-max problem.			MET
Viewing it as a “duality gap” seems to be far from the practical training.			EXP
This discrepancy exists for GANs, but it is a bigger issue for the duality gap interpretation.			MET
The reported FID for CIFAR10 using WGAN-GP is 54.4, which seems to be a bit high.			RWK
I’m not sure whether it is due to parameter choice or due to weak D/G networks used in the simulation.			EXP
- Why are there missing BLEU scores and the number of parameters in Table 1?			TNF
It is possible that a large part of the gain comes from the clever design of the space for computing intrinsic exploration reward.			NONE
The paper tries to control for it, however that description is rather short and vague (not clear how the proposed reward is computed without there being a grid, or how is the grid useful without the intrinsic reward).			MET
Table 1 tries to provide some comparisons on Atari, however number of samples is different for different methods making the comparisons invalid.			TNF
Mapping techniques from "non-directional" problems (where the action space is not a direction) and then projeting on the sphere is sub-optimal (the variance is too big).			MET
What takes away from the paper is that while perfect optimization of IB/sufficiency is equivalent to perfect optimization of DB, it is not clear what happens when perfection is not achieved.			NONE
In their abstract, the authors claim to provide state-of-the-art perplexity on Penn Treebank, which is not true.			NONE
The question is, why one would exlude the mixture-of-softmax approach here?			MET
This is clearly misleading.			NONE
It remains somewhat unclear, why this bigram-centered regularization would strongly contribute for prediction in general.			MET
Considering the small size of the corpus for the evaluation of a regularization method, the results even seem optimistic - it remains unclear, if this approach would readily scale to larger datasets.			DAT
It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.			MET
3. Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?			DAT
A more general function is			MET
Then, can the function family the authors used in the paper approximate this function?			MET
No.			NONE
On the Knapsack test, the metric of interest is not the accuracy of individual prediction.			NONE
Also, the authors should compare with few more graphnet + transmission layer (GraphNetST) baselines with the graph layers: $P(X)_i = Ax_i + \sum_{j \in N(x_i, X)} Bx_j + c$ and the same single transmission layer $\mathbf{1}\mathbf{1}^TXB$ in PointNetST.			RWK
PointNet is a specialization of graphnets and GraphNetST should be added as a baseline with reasonable adjacency.			RWK
In this case, A: PointNet, B: DeepSet			DAT
2.	What is the reason for using rule-based agents in all the experiments? It would have been more useful if all the analysis are done with RL agents rather than rule-based agents.			ANA
- what is the benefit brought by the 'Structural Knowledge' transfer? is this quantified anywhere? based on the description, I don't understand if this is an add-on to TabNN or whether it is incorporated in TabNN.			MET
I don't really understand how learning lambda would _guarantee_ that the optimization will converge to a better solution.			MET
This has not been considered in the analysis.			ANA
-In k-means clustering (E-step and M-step), is it correct to multiply \tilde x to (c-v)?			MET
I think that the error arising from quantizing v into c is only affected by a subset of rows of \tilde x. For example, if v is the first subvector of w_j, then I think that only 1-st, m+1-th, 2m+1-th, … rows of \tilde x affect to the error.			MET
Given its limitation to small and low-dimensional environments, it cannot be said how well the approach will scale with respect to these factors and the resulting, more complex agent behaviours.			MET
Overall, while the agent behaviour modelling focused on a type of inner state (based on past trajectories) provides benefits in the evaluated examples, it is unsure how well the approach scales to more complex domains based on strong similarity and simplicity of the tested toy scenarios (evaluation on sorting problems is an interesting step towards to address this shortcoming).			MET
* the ablation study designed to compare with a Gauss-Newton-like approach does not seem correct.			MET
- for GN optimization, lambda should be set to 0 - not a constant value.			MET
- the image features should be re-trained for the GN framework:  Since the features are learned for the LM iteration, they are adapted to the use of the predicted lambda, but they are not necessarily suitable to GN optimization.			MET
Thus, the advantage of using a LM optimization scheme is not very convincing.			MET
- the state vector Chi is not defined for the proposed method, only for the standard bundle adjustment approach. If I understand correctly is made of the camera poses.			MET
- the name 'Bundle Adjustment' is actually not adapted to the proposed method.			MET
I thus find the name misleading.			NONE
Marquet -> Marquardt			NONE
title of Section 3: revisitED			NONE
1st paragraph of Section 3: audience -> reader			NONE
caption of Fig 1: extractS			TNF
Eq (2) cannot have Delta Chi on the two sides.			MET
before Eq (3): the 'photometric ..' -> a 'photometric ..'			MET
1st paragraph of Section 4.3: difficulties -> reason			NONE
typo in absolute in caption of Fig 4			TNF
Section 4.5: applies -			NONE
> apply			NONE
But there are some minus ones in the random projection?			MET
The PPL expression at the bottom of p.5 doesn't look right.			NONE
It looks like all the results are given on the test set. Did you not do any tuning on the validation data?			DAT
However in the approach proposed here, the negative examples are missing.			MET
So there is no guarantee this algorithm will minimise the overall regret.			MET
- It does not seem necessary to predict cumulative mixture policies (ASN network).			MET
Since you assume the number of information nodes is large, you cannot minimize the l2 loss over all states. Do you assume you generate states by following some policy? Which policy?			MET
* The fact that the model makes use of pitch class and octave labels also raises questions about applicability -- if I understood correctly, transfer can only be done when this information is present.			MET
I think the main point of transfer over a regular generative model that goes from labels to audio is precisely that it can be done without label information.			MET
* The use of fully connected layers also implies that it requires fixed length input, so windowing and stitching are necessary for it to be applied to recordings of arbitrary length. Why not train a convolutional model instead?			MET
* I think the choice of a 3-dimensional latent space is poorly justified. Why not use more dimensions and project them down to 3 for visualisation and interpetation purposes with e.g. PCA or t-SNE?			MET
* Also in the introduction, it is implied that style transfer constitutes an advance in generative models, but style transfer does not make use of / does not equate to any generative model.			INT
* Mor et al. (2018) do actually make use of an adversarial training criterion (referred to as a "domain confusion loss"), contrary to what is claimed in the introduction.			RWK
* The claim that training a separate decoder for each domain necessarily leads to prohibitive training times is dubious -- a single conditional decoder would arguably need more capacity than each individual separate decoder model.			EXP
* I found the description in Section 3.1 a bit confusing as it initially seems that the approach requires paired data (e.g. "matching samples").			MET
* The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. Why does the MMD version constitute an improvement? Or is it simply more stable to train?			TNF
* The descriptor distributions in Figure 3 don't look like an "almost exact match" to me (as claimed in the text).			TNF
There are some clearly visible differences.			NONE
I think the wording is a bit too strong here.			NONE
The ResNet on Cifar-10 results are not convincing.			RES
The only problem I see is that phrase similarity part is not convincing.			MET
It is not obvious that shuffling image patches at a particular scale would lead to complete loss of global information, but the paper does show results on SVHN and CIFAR10 for which global information is sufficiently disentangled.			RWK_RES
It is not clear that the notion of similarity through classifier weights makes sense, but see below for clarification questions.			MET
For example, clustering on bags-of-words might also show that SST, SST-fine, and IMDb are close/similar/transferable.			NONE
The same could be said for SICK and SNLI.			NONE
Although they show that the Ski Rental problem can also be learned to solve though it is trivial and does not even use the framework the authors propose in its full extent, ie. problem instances are not generated by use of a machine learning model, which is one of main claims the authors are making.			MET
Therefore I do not find being able to solve this problem as a supporting evidence for the contributions claimed.			NONE
Though the title promises a contribution to an understanding of word embedding compositions in general, they barely expound on the broader implications of their idea in representing elements of language through vectors.			PDI
The authors claim that the Arora's RAND-WALK model does not capture any syntactic information.			MET
Another unjustified choice by the authors is their choice of weighing the Tensor term (when it is being added to two base embedding vectors) in the phrase similarity experiment.			EXP
A better design could be a learnable \lambda.			NONE
2) The global stability prediction does not have a consistent correlation with the local stability prediction, as shown by the easy and hard examples.			NONE
That is, the current design hasn't well considered the local and global stability relation, but just simply sum them up.			MET
I think it is misleading to call it a convolution, as (a) it is not a convolution mathematically, and (b) fast convolution techniques (Fourier, Winograd) cannot be applied, so claims to greater efficiency may be misleading.			MET
In (2) is (N+1)x(N+1) the kernel size (sums are over 0,1,...,N?)??			MET
Is the output of the first convolution a single HxW feature planes, or a HxWx(N+1)x(N+1) tensor?			MET
I feel the discussion on loss was rushed, and I gained no insight on what the authors thought was a prominent difference between the three losses studied.			NONE
Perhaps the authors had no salient observations for loss, but explicitly stating such would be useful to the reader.			RES
In Table 2 I saw some optimizers end up with much lower test accuracy.			TNF
x is already present within the indicator, no need to add yet			MET
1) 4.1,  “O(n^2/2)” -- just put O(n^2) or simply write as n^2/2.			NONE
I weakly reject this paper because although the approach is indeed interesting, the paper is lacking some structure, as described below:			NONE
However, hyperparameter searching is not extending any ML technique, it is just an approach to find a good training configuration and show robustness in different hyperparameters settings.			MET
It is thus unclear if the approach is robust against different hyperparameter settings.			MET
-	In Figure 2.b I’m surprised by the difference obtained in the feature maps for images which seems very similar (only the lighting seems to be different). Is it three consecutive frames?			TNF
- I think the authors want to make an explicit connection to counterfactuals as understood in the causality community. Then they shy away from it saying they are inspired by it. May be a formal exposition in the supplement about counterfactuals and generating mechanisms could help readers from other communities (NLP) even it means repeating standard/synthetic examples. Its good to say what exactly in a counterfactual generation process, the "people" in amazon turk were substituting.			MET
-  Is the romantic/ horror flips and their absence the only spurious thing in Figure 4 ?			TNF
1. I found the argument about FID in section 2.1 unconvincing. Are there proofs or citations for the claim that real images don't follow multivariate gaussian distribution after applying FID? Copying is indeed an issue that FID cannot detect, but it may be tangential to model collapse for real world concerns like privacy.			MET
2. The statement "IS, FID and MODE score takes both visual fidelity and diversity into account." under "Evaluation of Mode Collapse" is contradictory to the description in sec 2.1 that IS in fact does not measure diversity.			MET
For example, "The old system of private arbitration courts is off the table" from DE-EN 2016 Dev doesn't seem like it should benefit from this architecture.			RWK
