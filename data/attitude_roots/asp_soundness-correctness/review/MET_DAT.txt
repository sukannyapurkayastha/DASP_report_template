3.  Or simply to a well tuned \lambda, chosen on a per dataset basis? From the text it appears that \lambda is manually selected to trade off accuracy against uncertainty on OOD data.
I am wondering this method can be applied to other complex datasets whose latent factors are unknown.
They start from Equation (4) which is incorrectly denoted as the log-marginal distribution while it is the same conditional distribution introduced in Equation (3) with the extra summation for all the available data points.
It seems to me; the author assumed data from one modality is generated by all the latent factors (see Eq. (11)), then what is the point for assuming the prior of the latent factor is factorized (see Eq. (4) and (5))?
However, I can not agree because you can simply generate poisoned data and train the neural networks on the poisoned data regardless of the underlying approach that is targeted in generating the poisoned data.
