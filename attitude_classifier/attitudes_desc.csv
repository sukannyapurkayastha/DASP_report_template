Descriptions,Attitude_roots
"Lack of realistic datasets used in experiments (small siz, synthetic)",Substance(DAT_EXP)
"Missing details on methodology (eg., use of notation, use on tasks, etc)",Replicability(MET)
More variations of experiments needs to be added,Substance(MET_EXP)
"Improper explanation of results (as in advantages, why are results better, etc)",Clarity(RES)
claims on the datasets is questionable,Soundness-correctness(DAT)
Lack of discussion of performance of method on different datasets,Substance(MET_DAT)
"Reasons for rejection (not fit for conference, contains several weaknesses, etc.)",Other(OAL)
"Improper writing of realted work section (as in 1 paragraph rather than multiple for related work, explanation of somepapers, etc)",Clarity(RWK)
Limited improvement over baselines,Substance(RWK)
"The advantage of this random encoding was to reduce the number of parameters for an embedding layer, but the results showed we gained much PPL from a 25% reduction in embedding size (Table 1).",Substance(ANA_EXP)
Lack of discussion of analysis,Clarity(ANA)
"correctness of results presented is questionable(eg., metrics, complexity, etc)",Soundness-correctness(RES)
Suggest missing related work,Originality(BIB)
Too strong assumptions in analysis,Soundness-correctness(ANA)
Incorrect claims about performance in tables and figures,Substance(MET_TNF)
Lack of analysis,Substance(ANA)
Limited insights based on design choices,Motivation-impact(MET)
Limited generalizability of claims on other datasets,Soundness-correctness(DAT_EXP)
Not enough novelty in experiments (seems similar to previous work),Originality(EXP)
3. The paper is not nicely written or rather easy to follow.,Clarity(OAL)
Lacking details on datasets,Replicability(DAT)
"Incorrect presentation of tables and figures (plots, typos in tables and figs. description of plot)",Clarity(TNF)
More experiments needed with related work,Meaningful-comparison(ANA)
* The differences between UNIT (GAN; C-po) and UNIT (MMD; C-po) in Table 1 seem very small and I'm not convinced that they are significant. Why does the MMD version constitute an improvement? Or is it simply more stable to train?,Soundness-correctness(RWK_RES)
Incremental novelty of method as compared to related work,Originality(RWK)
Lack of analysis of proposed method,Substance(MET_ANA)
generalizability of method on datasets created from different distributions is questionable,Soundness-correctness(MET_DAT)
"Missing details in tables and figures (how some value as calculated in fig, some notation missing in fig, etc)",Replicability(TNF)
More comparisons needed with variations of the proposed method,Meaningful-comparison(RES)
Missing explanation of comparsion with related work in tables and figures,Meaningful-comparison(TNF)
"Unclear connection of method with related work (description of the related work it is based on, why earlier methods fail, etc)",Clarity(MET_RWK)
"In terms of applicability, it seems that many cases where discrete latent variables would be really interesting are not covered (e.g. sigmoid belief networks); the paper demonstrates experiments with discrete images (binary or 4-bit) not particularly motivated in my opinion.",Originality(DAT)
Missing citations in the paper,Other(BIB)
Limited contribution in problem definition,Motivation-impact(PDI)
Missing explanation of utility of proposed method,Motivation-impact(EXP)
"Incorrect claims in introduction (confusing related work presented in intro, wrong claims)",Soundness-correctness(INT)
More experiments needed with related work,Meaningful-comparison(EXP)
incorrect claims for related work,Soundness-correctness(MET_RWK)
Less datasets used,Substance(DAT)
"Not much novelty in methodology (previous works already studied these methods, similar motiation of methodology)",Originality(MET_RWK)
correctness of experiments is questionable,Soundness-correctness(RES_EXP)
Improper presentation of results in tables and figures,Clarity(RES_TNF)
Incorrect explanation of resuts,Soundness-correctness(MET_RES)
"While better than most of the baseline methods, the N^2 memory/computational complexity is not bad, but still too high to scale to very large graphs.",Soundness-correctness(PDI)
Missing implementation details of related work used as baselines,Replicability(RWK)
Theoretical misunderstanding in methodology,Other(MET)
"Overall not original enough (primary claim, limited evaluation, limited novelty)",Originality(OAL)
"Lack of discussion of experimental setup (conclusion from experiments, poor experimental details, etc)",Clarity(EXP)
Limited novelty in theoretical contribution,Originality(MET)
Incomplete details on perfromance of the method,Substance(MET)
"The advantage of this random encoding was to reduce the number of parameters for an embedding layer, but the results showed we gained much PPL from a 25% reduction in embedding size (Table 1).",Substance(RES_TNF)
Incorrect citation styles,Clarity(BIB)
"While this is a new and interesting task, the contribution (as discussed above in “pros” above) is somewhat limited.",Motivation-impact(MET_RES)
"Lack of experimental details (no of images, sampling criteria, etc)",Replicability(EXP)
Improper comparison of related work in terms of implementation,Substance(MET_RWK)
"Concerns regarding correctness of methods (assumption, budget, etc)",Soundness-correctness(MET_EXP)
Lack of comparison with related works,Meaningful-comparison(MET_EXP)
Limited novelty as compared to related work,Motivation-impact(RWK)
Missing details for reproducibility of result,Replicability(RES)
Unclear description of method,Clarity(MET)
"Generalizability of results in terms of method parameters (only applies for some number of parameters, only for these type of matrices, etc)",Substance(MET_RES)
Lacking clarity overall (needs better presentation),Substance(OAL)
"Missing ablation study (how to generalize findings, what happens if some changes are done to the method, etc)",Replicability(MET_DAT)
Incorrect baselines used,Meaningful-comparison(MET_RWK)
"5) Last but not least, convergence analysis of the proposed method should be provided given that asynchrony may lead to divergence in the optimization.",Substance(INT)
Missing theoretical comparisons,Meaningful-comparison(RWK_EXP)
Experimental study not strong enough,Substance(EXP)
Incorrect assumptions as compared to related work,Soundness-correctness(RWK)
Not enough originality in results (not surprising),Originality(RES)
generalizability of results is questionable,Substance(RES)
Missing interpretation of results due to missing related work,Meaningful-comparison(RES_EXP)
Correctness of algorithm proposed is questionable,Soundness-correctness(MET)
Missing theoretical comparisons,Meaningful-comparison(MET)
Incomplete ablation in terms of tables and figures,Soundness-correctness(TNF)
"Because of this concern, I believe the results in the paper can only really characterize the learning close to convergence, since the network is already able to provide correct classification.",Replicability(MET_EXP)
Limited impact of results,Motivation-impact(RES)
"Because of this concern, I believe the results in the paper can only really characterize the learning close to convergence, since the network is already able to provide correct classification.",Replicability(OAL)
Lack of ablation on different datasets/ sizes,Substance(MET_DAT_EXP)
Need more experimental results,Substance(RES_EXP)
Lack of experiments,Substance(RWK_EXP)
Unclear problem definition,Clarity(PDI)
"Perhaps I missed it, but I believe Dan Ciresan's paper ""Multi-Column Deep Neural Networks for Image Classification"" should be cited.",Meaningful-comparison(MET_TNF)
Need more interesting problem definition,Substance(PDI)
"Incomprehensible tables and figures (what is the point of the plot, no decription of figure in main text, etc)",Substance(TNF)
Missing baselines,Meaningful-comparison(RWK)
design choices are questionable,Soundness-correctness(EXP)
Unclear intro (eg. contributions),Clarity(INT)
"Lack of discussion on datasets (size, motivation for use, etc)",Clarity(DAT)
Results are more or less similar to baselines,Substance(RWK_RES)
"In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing.",Substance(DAT_RES)
Not enough info on dataset and hyper-parameters,Replicability(DAT_EXP)
"While sensible, this seems to me to be too minor a contribution to stand alone as a paper.",Motivation-impact(OAL)
Incorrect citation,Meaningful-comparison(BIB)
"Improper Structuring of experimental results on paper (as in on some page, before some section)",Clarity(RES_EXP)
1. The presentation is somewhat convoluted.,Soundness-correctness(OAL)
-The experimental section do not clarify the benefits of the proposed approach.,Clarity(MET_EXP)
Reproducibility of result,Replicability(ANA)
"The main reason is that from the narration, I cannot figure out what is the idea or technique of other works and what is the contribution of this paper.",Originality(PDI)
"Missing literature review (some literature not included, misses baseline citations, etc)",Other(RWK)
"[-] The combination of VAEs and GANs, while new for videos, had already been proposed for image generation as indicated in the Related Work section and its formulation for video prediction is relatively straightforward given existing VAE (Denton & Fergus 2018) and GAN models (Tulyakov et al. 2018).",Other(MET_RWK)
Also experiment figures are extremely compact. Try using log scale or other lines to make the gaps wider.,Other(TNF)
I’m also confused by the presentation of the results.,Other(RES)
"hence, there is no connection between the theoretical results on MDL generalization bound and the proposed method MULANN.",Other(MET_RES)
"Some of the experiments (eg. comparisons involving ShakeShake and ScheduledDropPath, Section 5.2) could also be moved to the appendix in order to make room for a description of LEMONADE in the main paper.",Other(EXP)
"With regard to my first negative point above about the lack of discussions, it seems the analysis of Section 4 is disproportionate compared to other places.",Other(ANA)
"- My main concern about the analysis is that it shows why several methods (e.g., momentum, multiple update steps) are *not* helpful for stabilising GANs, but does not tell why training with these methods, as well as others such as gradient penalty, *do converge* in practice with properly chosen hyper-parameters?",Clarity(MET_ANA)
If I were to go through the computation of then why not just train a smaller version of that representation technique instead and **directly** see how well it can encode data in k dimensions via that technique / for that task?,Clarity(MET_DAT_EXP)
9. It is not clear that baseline 1 and 2 correspond to which baselines in later experiments.,Clarity(RWK_EXP)
- It is unclear why the results on WikiSQL is presented in Appendix. Combining the results on both datasets in the experiments section would be more convincing.,Clarity(DAT_RES_EXP)
"As pointed out by R2, with depth there are a lot more number of possible ways in which one could carve out decision boundaries to separate data points, thus, it is not clear that the loose linear upper bound holds Specifically, as one might expect with depth it could be possible that linear capacity increase is a lower bound (I am not suggesting that it is, but that possibility should be considered and explained in the paper).",Clarity(MET_DAT)
"However, since quantitative exploration of large real-world datasets may be challenging and expensive to collect, the synthetic experiments could have been more detailed.",Clarity(DAT_EXP)
"Specifically, the first contribution listed in the introduction makes it look like this paper introduces the idea of not learning the decoder on the dataset (the one that starts with “The network is not learned and itself incorporates all assumptions on the data.”).",Clarity(INT_PDI)
The details of the approach is not entirely clear and no theoritcal results are provided to support the approach.,Clarity(MET_RES)
"The real data experiments (sections 4.2 and 4.3) are not very convincing, not only because of the very small size of N, but also because there is no comparison with the other approaches.",Meaningful-comparison(DAT_EXP)
"- I’d also like to see more extensive comparisons between FICM and ICM across different datasets, for example, Super Mario Bros. and the Atari games, instead of only comparing FICM against ICM on ViZDoom.",Meaningful-comparison(DAT)
"2:    The authors should compare against several costs/algorithms (e.g. l_0 with OMP, l_1 with LARS, etc.), and across various N_0/sparsity penalties, and across several datasets.",Meaningful-comparison(MET_DAT)
"E.g., in Table 1 and 2,  the best result of VAT (Miyato et al., 2017) is VAT+Ent, 13.15 for CIFAR-10 (4000 labels) and 4.28 for SVHN (1000 labels).",Meaningful-comparison(RWK_RES)
"3. In the introduction, the Authors point that prior methods have trouble dealing with textureless, reflective or transparent approaches, but it's not clear form the paper where it addresses these cases, and if yes, what is the mechanism for that.",Meaningful-comparison(INT)
There should be some kind of comparison with test set results from other state-of-the-art work on these datasets.,Meaningful-comparison(RWK_DAT)
"In terms of method, the guidance for learning Siamese networks are designed heuristically (e.g. edges, colors, etc.) which limits its applicability over various datasets; I think that designing more principled approach to build such guidances from data should be one of the key contributions of the paper.",Motivation-impact(MET_DAT)
"Overall, the idea is simple, the explanation is clear and experimentation is extensive. I would like to see more commentary on why this method might have long-term impact (or not).",Motivation-impact(PDI_MET)
Unfortunately the paper doesn't provide any qualitative analysis on how modulation is employed by the models after training.,Motivation-impact(ANA)
"-The conclusions of the study were suggested by previous papers or are rather expected: adversarial transfer is not symmetric: Deep models less transferable than shallow ones, averaging gradient is better",Originality(RWK_RES)
"2. In experiments, the authors explored many existing methods on improving",Originality(RWK_EXP)
"When it comes to experiments, constant epoch budget is also fairly well understood and the behavior in Figure 1 is not really surprising (as the eventual training performance gets worse with large batches).",Originality(TNF)
"that (except the minor small section of streaming data), the paper is more like a proper verification of how tree-based learning algorithms work very well in tabular data--which is far from the basis of the paper and does not make the paper novel enough for ICLR.",Originality(MET_DAT)
"Overall, the method looks incremental and experimental results are mixed on small datasets so I vote for rejection.",Originality(DAT_RES)
"- Gradient starvation, Kaggle experiment: I'm not too convinced about the novelty/usefulness of this result. In the end, even a decision tree stump would stop growing after learning the dark/light feature as a discriminator.",Originality(RES_EXP)
"3. The authors argue in their rebuttal that ""the grid"" is a novel idea that warrants investigation, but remark in figure 5 that likely it isn't the key aspect of their algorithm.",Originality(MET_TNF)
The idea of using a constrained formulation is not novel either (constrained MDPs have been thoroughly studied since Altman (1999)).,Originality(PDI_RWK)
- little methodological innovation or analytical explanations,Originality(ANA)
"In the experiments, both the setting and the experimental results show that the proposed W_s will be very close to W_U. As a result, the improvement caused by the proposed method is incremental compared with its variants.",Originality(MET_EXP)
"-- While the overall claim of the paper in the introduction seems to be to speed up frequency estimation using machine learned advice, results are only given for the Zipfian distribution.",Replicability(INT_RES)
"For example, for baseline 1, it is very hard to understand why would we want to use such an unusual baseline, and why it is called a ""random baseline"".",Replicability(MET_RWK)
"This sort of two-stage generation is also potentially interesting, I was wondering if the authors had ideas to generalize this idea.",Replicability(PDI)
"-In the introduction, ""it is in general impossible to find an embedding in R^d such that ..."", why do we have to make v and v'(and u, and u') far from each other?",Replicability(INT)
"and rendering the third claim from the introduction (""We propose an new algorithm with the new metric which demonstrates better results than state-of-the-art algorithms."") completely untrue.",Soundness-correctness(INT_MET)
"I would have liked to see results for both trivial baselines like random ranking as well as more informed baselines where we can estimate transfer potential using say k representation techniques, and then use that to help us understand how well it would do on the other representations.",Soundness-correctness(RWK_EXP)
"The MNIST+SVHN dataset setup is described in detail, yet there is no summary of the experimental results, which are presented in the appendix.",Substance(DAT_RES_EXP)
- What is the difference between the result of Theorem 4.3 and the result from (Lacoste-Julien 2016)?,Substance(MET_RWK_RES)
"Although the idea is interesting, I would like to see more experimental results showing the scalability of the proposed method and for evaluating defense strategies against different types of adversarial attacks.",Substance(MET_RES_EXP)
"Some baseline DA methods [A, B] and datasets [C, D] are not considered.",Substance(MET_RWK_DAT)
"The two ideas (use of grids, and intra-life curiosity vs inter-life curiosity) should be independently investigated and put in context of past work.",Substance(PDI_RWK)
