11/22/2024 22:50:16 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
11/22/2024 22:50:16 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
eval_use_gather_object=False,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=t5-large-output/10/1e-4/runs/Nov22_22-50-15_penelope.ukp.informatik.tu-darmstadt.de,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=t5-large-output/10/1e-4,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=8,
predict_with_generate=True,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=t5-large-output/10/1e-4,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=-1.0,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[nltk_data] Downloading package punkt_tab to /ukp-
[nltk_data]     storage-1/yang1/miniconda3/envs/jitsupeer/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!
Using custom data configuration default-a8a91f409bd3f4eb
11/22/2024 22:50:16 - INFO - datasets.builder - Using custom data configuration default-a8a91f409bd3f4eb
11/22/2024 22:50:16 - INFO - datasets.info - Loading Dataset Infos from /ukp-storage-1/yang1/miniconda3/envs/jitsupeer/lib/python3.8/site-packages/datasets/packaged_modules/csv
Loading Dataset Infos from /ukp-storage-1/yang1/miniconda3/envs/jitsupeer/lib/python3.8/site-packages/datasets/packaged_modules/csv
Overwrite dataset info from restored data version if exists.
11/22/2024 22:50:16 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.
Loading Dataset info from /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52
11/22/2024 22:50:16 - INFO - datasets.info - Loading Dataset info from /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52
Found cached dataset csv (/storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52)
11/22/2024 22:50:16 - INFO - datasets.builder - Found cached dataset csv (/storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52)
Loading Dataset info from /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52
11/22/2024 22:50:16 - INFO - datasets.info - Loading Dataset info from /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52
[INFO|configuration_utils.py:679] 2024-11-22 22:50:16,772 >> loading configuration file config.json from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:746] 2024-11-22 22:50:16,794 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "classifier_dropout": 0.0,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.46.3",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_auto.py:706] 2024-11-22 22:50:16,917 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:679] 2024-11-22 22:50:17,040 >> loading configuration file config.json from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:746] 2024-11-22 22:50:17,040 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "classifier_dropout": 0.0,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.46.3",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|tokenization_utils_base.py:2211] 2024-11-22 22:50:17,282 >> loading file spiece.model from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/spiece.model
[INFO|tokenization_utils_base.py:2211] 2024-11-22 22:50:17,282 >> loading file tokenizer.json from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/tokenizer.json
[INFO|tokenization_utils_base.py:2211] 2024-11-22 22:50:17,282 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2211] 2024-11-22 22:50:17,282 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2211] 2024-11-22 22:50:17,282 >> loading file tokenizer_config.json from cache at None
[INFO|configuration_utils.py:679] 2024-11-22 22:50:17,293 >> loading configuration file config.json from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/config.json
[INFO|configuration_utils.py:746] 2024-11-22 22:50:17,294 >> Model config T5Config {
  "_name_or_path": "t5-large",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "classifier_dropout": 0.0,
  "d_ff": 4096,
  "d_kv": 64,
  "d_model": 1024,
  "decoder_start_token_id": 0,
  "dense_act_fn": "relu",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "relu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": false,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 16,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "transformers_version": "4.46.3",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|modeling_utils.py:3937] 2024-11-22 22:50:17,579 >> loading weights file model.safetensors from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/model.safetensors
[INFO|configuration_utils.py:1096] 2024-11-22 22:50:17,638 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

[INFO|modeling_utils.py:4800] 2024-11-22 22:50:18,289 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:4808] 2024-11-22 22:50:18,289 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-large.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1051] 2024-11-22 22:50:18,426 >> loading configuration file generation_config.json from cache at /storage/ukp/work/yang1/.cache/huggingface/hub/models--t5-large/snapshots/150ebc2c4b72291e770f58e6057481c8d2ed331a/generation_config.json
[INFO|configuration_utils.py:1096] 2024-11-22 22:50:18,427 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

Loading cached processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-d14a3d187bcfb2b2.arrow
11/22/2024 22:50:18 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-d14a3d187bcfb2b2.arrow
Loading cached processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-31ab66c0a2197eb5.arrow
11/22/2024 22:50:18 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-31ab66c0a2197eb5.arrow
11/22/2024 22:50:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-bfc382a13e2862f2.arrow
Running tokenizer on prediction dataset:   0%|          | 0/467 [00:00<?, ? examples/s]Caching processed dataset at /storage/ukp/work/yang1/.cache/huggingface/datasets/csv/default-a8a91f409bd3f4eb/0.0.0/9ea1179385ff7ad1e756d327ffccaa3b801175702a2d91528226ba2c66873f52/cache-bfc382a13e2862f2.arrow
11/22/2024 22:50:19 - WARNING - accelerate.utils.other - Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Running tokenizer on prediction dataset: 100%|██████████| 467/467 [00:00<00:00, 4454.46 examples/s]
main.py:661: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
[INFO|trainer.py:2314] 2024-11-22 22:50:27,040 >> ***** Running training *****
[INFO|trainer.py:2315] 2024-11-22 22:50:27,040 >>   Num examples = 1,678
[INFO|trainer.py:2316] 2024-11-22 22:50:27,041 >>   Num Epochs = 10
[INFO|trainer.py:2317] 2024-11-22 22:50:27,041 >>   Instantaneous batch size per device = 8
[INFO|trainer.py:2320] 2024-11-22 22:50:27,041 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:2321] 2024-11-22 22:50:27,041 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2322] 2024-11-22 22:50:27,041 >>   Total optimization steps = 520
[INFO|trainer.py:2323] 2024-11-22 22:50:27,042 >>   Number of trainable parameters = 737,668,096
  0%|          | 0/520 [00:00<?, ?it/s][WARNING|logging.py:328] 2024-11-22 22:50:28,544 >> Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
  0%|          | 1/520 [00:03<26:08,  3.02s/it]  0%|          | 2/520 [00:03<14:18,  1.66s/it]  1%|          | 3/520 [00:04<10:41,  1.24s/it]  1%|          | 4/520 [00:05<09:06,  1.06s/it]  1%|          | 5/520 [00:05<08:03,  1.07it/s]  1%|          | 6/520 [00:06<07:24,  1.16it/s]  1%|▏         | 7/520 [00:07<07:12,  1.19it/s]  2%|▏         | 8/520 [00:08<06:58,  1.22it/s]  2%|▏         | 9/520 [00:09<06:53,  1.24it/s]  2%|▏         | 10/520 [00:09<06:33,  1.30it/s]  2%|▏         | 11/520 [00:10<06:25,  1.32it/s]  2%|▏         | 12/520 [00:11<06:41,  1.27it/s]  2%|▎         | 13/520 [00:12<06:40,  1.26it/s]  3%|▎         | 14/520 [00:12<06:42,  1.26it/s]  3%|▎         | 15/520 [00:13<06:30,  1.29it/s]  3%|▎         | 16/520 [00:14<06:22,  1.32it/s]  3%|▎         | 17/520 [00:15<06:19,  1.33it/s]  3%|▎         | 18/520 [00:15<06:29,  1.29it/s]  4%|▎         | 19/520 [00:16<06:27,  1.29it/s]  4%|▍         | 20/520 [00:17<06:23,  1.30it/s]  4%|▍         | 21/520 [00:18<06:20,  1.31it/s]  4%|▍         | 22/520 [00:18<06:12,  1.34it/s]  4%|▍         | 23/520 [00:19<06:08,  1.35it/s]  5%|▍         | 24/520 [00:20<06:05,  1.36it/s]  5%|▍         | 25/520 [00:21<06:00,  1.37it/s]  5%|▌         | 26/520 [00:21<06:07,  1.34it/s]  5%|▌         | 27/520 [00:22<06:06,  1.34it/s]  5%|▌         | 28/520 [00:23<06:04,  1.35it/s]  6%|▌         | 29/520 [00:24<06:00,  1.36it/s]  6%|▌         | 30/520 [00:24<05:59,  1.36it/s]  6%|▌         | 31/520 [00:25<05:59,  1.36it/s]  6%|▌         | 32/520 [00:26<05:55,  1.37it/s]  6%|▋         | 33/520 [00:26<05:52,  1.38it/s]  7%|▋         | 34/520 [00:27<06:04,  1.33it/s]  7%|▋         | 35/520 [00:28<06:00,  1.35it/s]  7%|▋         | 36/520 [00:29<05:58,  1.35it/s]  7%|▋         | 37/520 [00:29<05:57,  1.35it/s]  7%|▋         | 38/520 [00:30<05:59,  1.34it/s]  8%|▊         | 39/520 [00:31<06:01,  1.33it/s]  8%|▊         | 40/520 [00:32<05:56,  1.35it/s]  8%|▊         | 41/520 [00:32<05:56,  1.34it/s]  8%|▊         | 42/520 [00:33<05:56,  1.34it/s]  8%|▊         | 43/520 [00:34<05:59,  1.33it/s]  8%|▊         | 44/520 [00:35<05:53,  1.35it/s]  9%|▊         | 45/520 [00:35<05:54,  1.34it/s]  9%|▉         | 46/520 [00:36<05:49,  1.36it/s]  9%|▉         | 47/520 [00:37<05:51,  1.34it/s]  9%|▉         | 48/520 [00:38<05:46,  1.36it/s]  9%|▉         | 49/520 [00:38<05:47,  1.35it/s] 10%|▉         | 50/520 [00:39<05:41,  1.38it/s] 10%|▉         | 51/520 [00:40<05:45,  1.36it/s] 10%|█         | 52/520 [00:41<05:49,  1.34it/s] 10%|█         | 53/520 [00:41<05:44,  1.36it/s] 10%|█         | 54/520 [00:42<05:47,  1.34it/s] 11%|█         | 55/520 [00:43<05:59,  1.29it/s] 11%|█         | 56/520 [00:44<05:57,  1.30it/s] 11%|█         | 57/520 [00:44<05:51,  1.32it/s] 11%|█         | 58/520 [00:45<05:44,  1.34it/s] 11%|█▏        | 59/520 [00:46<05:41,  1.35it/s] 12%|█▏        | 60/520 [00:47<05:44,  1.33it/s] 12%|█▏        | 61/520 [00:47<05:42,  1.34it/s] 12%|█▏        | 62/520 [00:48<05:36,  1.36it/s] 12%|█▏        | 63/520 [00:49<05:38,  1.35it/s] 12%|█▏        | 64/520 [00:50<05:31,  1.38it/s] 12%|█▎        | 65/520 [00:50<05:30,  1.38it/s] 13%|█▎        | 66/520 [00:51<05:32,  1.36it/s] 13%|█▎        | 67/520 [00:52<05:26,  1.39it/s] 13%|█▎        | 68/520 [00:52<05:19,  1.42it/s] 13%|█▎        | 69/520 [00:53<05:11,  1.45it/s] 13%|█▎        | 70/520 [00:54<05:22,  1.40it/s] 14%|█▎        | 71/520 [00:55<05:25,  1.38it/s] 14%|█▍        | 72/520 [00:55<05:30,  1.36it/s] 14%|█▍        | 73/520 [00:56<05:31,  1.35it/s] 14%|█▍        | 74/520 [00:57<05:22,  1.38it/s] 14%|█▍        | 75/520 [00:58<05:31,  1.34it/s] 15%|█▍        | 76/520 [00:58<05:30,  1.34it/s] 15%|█▍        | 77/520 [00:59<05:23,  1.37it/s] 15%|█▌        | 78/520 [01:00<05:30,  1.34it/s] 15%|█▌        | 79/520 [01:00<05:24,  1.36it/s] 15%|█▌        | 80/520 [01:01<05:24,  1.36it/s] 16%|█▌        | 81/520 [01:02<05:19,  1.38it/s] 16%|█▌        | 82/520 [01:03<05:12,  1.40it/s] 16%|█▌        | 83/520 [01:03<05:21,  1.36it/s] 16%|█▌        | 84/520 [01:04<05:18,  1.37it/s] 16%|█▋        | 85/520 [01:05<05:14,  1.38it/s] 17%|█▋        | 86/520 [01:06<05:08,  1.40it/s] 17%|█▋        | 87/520 [01:06<05:13,  1.38it/s] 17%|█▋        | 88/520 [01:07<05:14,  1.37it/s] 17%|█▋        | 89/520 [01:08<05:09,  1.39it/s] 17%|█▋        | 90/520 [01:08<05:07,  1.40it/s] 18%|█▊        | 91/520 [01:09<05:04,  1.41it/s] 18%|█▊        | 92/520 [01:10<05:03,  1.41it/s] 18%|█▊        | 93/520 [01:11<05:00,  1.42it/s] 18%|█▊        | 94/520 [01:11<05:04,  1.40it/s] 18%|█▊        | 95/520 [01:12<05:03,  1.40it/s] 18%|█▊        | 96/520 [01:13<05:07,  1.38it/s] 19%|█▊        | 97/520 [01:13<05:03,  1.39it/s] 19%|█▉        | 98/520 [01:14<05:01,  1.40it/s] 19%|█▉        | 99/520 [01:15<05:00,  1.40it/s] 19%|█▉        | 100/520 [01:16<04:59,  1.40it/s] 19%|█▉        | 101/520 [01:16<05:03,  1.38it/s] 20%|█▉        | 102/520 [01:17<04:58,  1.40it/s] 20%|█▉        | 103/520 [01:18<05:00,  1.39it/s] 20%|██        | 104/520 [01:18<04:53,  1.42it/s] 20%|██        | 105/520 [01:19<04:48,  1.44it/s] 20%|██        | 106/520 [01:20<04:51,  1.42it/s] 21%|██        | 107/520 [01:21<04:53,  1.41it/s] 21%|██        | 108/520 [01:21<04:52,  1.41it/s] 21%|██        | 109/520 [01:22<04:56,  1.38it/s] 21%|██        | 110/520 [01:23<04:53,  1.40it/s] 21%|██▏       | 111/520 [01:23<04:57,  1.38it/s] 22%|██▏       | 112/520 [01:24<04:55,  1.38it/s] 22%|██▏       | 113/520 [01:25<04:59,  1.36it/s] 22%|██▏       | 114/520 [01:26<05:09,  1.31it/s] 22%|██▏       | 115/520 [01:26<05:01,  1.34it/s] 22%|██▏       | 116/520 [01:27<05:09,  1.31it/s] 22%|██▎       | 117/520 [01:28<05:04,  1.32it/s] 23%|██▎       | 118/520 [01:29<04:58,  1.35it/s] 23%|██▎       | 119/520 [01:29<04:59,  1.34it/s] 23%|██▎       | 120/520 [01:30<04:56,  1.35it/s] 23%|██▎       | 121/520 [01:31<04:56,  1.35it/s] 23%|██▎       | 122/520 [01:32<04:53,  1.35it/s] 24%|██▎       | 123/520 [01:32<04:53,  1.35it/s] 24%|██▍       | 124/520 [01:33<04:49,  1.37it/s] 24%|██▍       | 125/520 [01:34<04:47,  1.37it/s] 24%|██▍       | 126/520 [01:35<04:52,  1.35it/s] 24%|██▍       | 127/520 [01:35<04:47,  1.37it/s] 25%|██▍       | 128/520 [01:36<04:52,  1.34it/s] 25%|██▍       | 129/520 [01:37<04:58,  1.31it/s] 25%|██▌       | 130/520 [01:38<04:49,  1.35it/s] 25%|██▌       | 131/520 [01:38<04:48,  1.35it/s] 25%|██▌       | 132/520 [01:39<04:45,  1.36it/s] 26%|██▌       | 133/520 [01:40<04:42,  1.37it/s] 26%|██▌       | 134/520 [01:41<04:50,  1.33it/s] 26%|██▌       | 135/520 [01:41<04:44,  1.35it/s] 26%|██▌       | 136/520 [01:42<04:36,  1.39it/s] 26%|██▋       | 137/520 [01:43<04:37,  1.38it/s] 27%|██▋       | 138/520 [01:43<04:37,  1.38it/s] 27%|██▋       | 139/520 [01:44<04:44,  1.34it/s] 27%|██▋       | 140/520 [01:45<04:41,  1.35it/s] 27%|██▋       | 141/520 [01:46<04:42,  1.34it/s] 27%|██▋       | 142/520 [01:46<04:38,  1.36it/s] 28%|██▊       | 143/520 [01:47<04:35,  1.37it/s] 28%|██▊       | 144/520 [01:48<04:33,  1.37it/s] 28%|██▊       | 145/520 [01:49<04:34,  1.37it/s] 28%|██▊       | 146/520 [01:49<04:33,  1.37it/s] 28%|██▊       | 147/520 [01:50<04:42,  1.32it/s] 28%|██▊       | 148/520 [01:51<04:49,  1.28it/s] 29%|██▊       | 149/520 [01:52<04:54,  1.26it/s] 29%|██▉       | 150/520 [01:53<04:50,  1.27it/s] 29%|██▉       | 151/520 [01:53<04:52,  1.26it/s] 29%|██▉       | 152/520 [01:54<04:47,  1.28it/s] 29%|██▉       | 153/520 [01:55<04:42,  1.30it/s] 30%|██▉       | 154/520 [01:56<04:36,  1.32it/s] 30%|██▉       | 155/520 [01:56<04:37,  1.31it/s] 30%|███       | 156/520 [01:57<04:33,  1.33it/s] 30%|███       | 157/520 [01:58<04:37,  1.31it/s] 30%|███       | 158/520 [01:59<04:30,  1.34it/s] 31%|███       | 159/520 [01:59<04:30,  1.33it/s] 31%|███       | 160/520 [02:00<04:23,  1.37it/s] 31%|███       | 161/520 [02:01<04:18,  1.39it/s] 31%|███       | 162/520 [02:01<04:18,  1.38it/s] 31%|███▏      | 163/520 [02:02<04:18,  1.38it/s] 32%|███▏      | 164/520 [02:03<04:10,  1.42it/s] 32%|███▏      | 165/520 [02:04<04:10,  1.42it/s] 32%|███▏      | 166/520 [02:04<04:09,  1.42it/s] 32%|███▏      | 167/520 [02:05<04:10,  1.41it/s] 32%|███▏      | 168/520 [02:06<04:12,  1.39it/s] 32%|███▎      | 169/520 [02:06<04:14,  1.38it/s] 33%|███▎      | 170/520 [02:07<04:11,  1.39it/s] 33%|███▎      | 171/520 [02:08<04:09,  1.40it/s] 33%|███▎      | 172/520 [02:09<04:18,  1.35it/s] 33%|███▎      | 173/520 [02:09<04:16,  1.35it/s] 33%|███▎      | 174/520 [02:10<04:11,  1.38it/s] 34%|███▎      | 175/520 [02:11<04:14,  1.35it/s] 34%|███▍      | 176/520 [02:12<04:08,  1.39it/s] 34%|███▍      | 177/520 [02:12<04:06,  1.39it/s] 34%|███▍      | 178/520 [02:13<04:11,  1.36it/s] 34%|███▍      | 179/520 [02:14<04:09,  1.37it/s] 35%|███▍      | 180/520 [02:14<04:05,  1.39it/s] 35%|███▍      | 181/520 [02:15<03:59,  1.41it/s] 35%|███▌      | 182/520 [02:16<04:05,  1.38it/s] 35%|███▌      | 183/520 [02:17<04:07,  1.36it/s] 35%|███▌      | 184/520 [02:17<04:16,  1.31it/s] 36%|███▌      | 185/520 [02:18<04:12,  1.33it/s] 36%|███▌      | 186/520 [02:19<04:09,  1.34it/s] 36%|███▌      | 187/520 [02:20<04:05,  1.36it/s] 36%|███▌      | 188/520 [02:20<04:02,  1.37it/s] 36%|███▋      | 189/520 [02:21<04:00,  1.38it/s] 37%|███▋      | 190/520 [02:22<04:01,  1.37it/s] 37%|███▋      | 191/520 [02:23<04:05,  1.34it/s] 37%|███▋      | 192/520 [02:23<04:01,  1.36it/s] 37%|███▋      | 193/520 [02:24<03:58,  1.37it/s] 37%|███▋      | 194/520 [02:25<03:55,  1.38it/s] 38%|███▊      | 195/520 [02:26<04:00,  1.35it/s] 38%|███▊      | 196/520 [02:26<03:57,  1.36it/s] 38%|███▊      | 197/520 [02:27<03:55,  1.37it/s] 38%|███▊      | 198/520 [02:28<03:53,  1.38it/s] 38%|███▊      | 199/520 [02:28<03:55,  1.37it/s] 38%|███▊      | 200/520 [02:29<03:56,  1.35it/s] 39%|███▊      | 201/520 [02:30<04:01,  1.32it/s] 39%|███▉      | 202/520 [02:31<03:54,  1.36it/s] 39%|███▉      | 203/520 [02:31<03:49,  1.38it/s] 39%|███▉      | 204/520 [02:32<03:47,  1.39it/s] 39%|███▉      | 205/520 [02:33<03:44,  1.40it/s] 40%|███▉      | 206/520 [02:34<03:47,  1.38it/s] 40%|███▉      | 207/520 [02:34<03:47,  1.37it/s] 40%|████      | 208/520 [02:35<03:44,  1.39it/s] 40%|████      | 209/520 [02:36<03:39,  1.42it/s] 40%|████      | 210/520 [02:36<03:40,  1.40it/s] 41%|████      | 211/520 [02:37<03:40,  1.40it/s] 41%|████      | 212/520 [02:38<03:47,  1.35it/s] 41%|████      | 213/520 [02:39<03:50,  1.33it/s] 41%|████      | 214/520 [02:39<03:46,  1.35it/s] 41%|████▏     | 215/520 [02:40<03:45,  1.35it/s] 42%|████▏     | 216/520 [02:41<03:50,  1.32it/s] 42%|████▏     | 217/520 [02:42<03:47,  1.33it/s] 42%|████▏     | 218/520 [02:42<03:44,  1.35it/s] 42%|████▏     | 219/520 [02:43<03:42,  1.36it/s] 42%|████▏     | 220/520 [02:44<03:38,  1.37it/s] 42%|████▎     | 221/520 [02:45<03:39,  1.36it/s] 43%|████▎     | 222/520 [02:45<03:39,  1.36it/s] 43%|████▎     | 223/520 [02:46<03:39,  1.35it/s] 43%|████▎     | 224/520 [02:47<03:39,  1.35it/s] 43%|████▎     | 225/520 [02:48<03:35,  1.37it/s] 43%|████▎     | 226/520 [02:48<03:32,  1.38it/s] 44%|████▎     | 227/520 [02:49<03:31,  1.39it/s] 44%|████▍     | 228/520 [02:50<03:30,  1.39it/s] 44%|████▍     | 229/520 [02:50<03:33,  1.36it/s] 44%|████▍     | 230/520 [02:51<03:32,  1.37it/s] 44%|████▍     | 231/520 [02:52<03:30,  1.37it/s] 45%|████▍     | 232/520 [02:53<03:34,  1.34it/s] 45%|████▍     | 233/520 [02:53<03:33,  1.34it/s] 45%|████▌     | 234/520 [02:54<03:30,  1.36it/s] 45%|████▌     | 235/520 [02:55<03:33,  1.34it/s] 45%|████▌     | 236/520 [02:56<03:30,  1.35it/s] 46%|████▌     | 237/520 [02:56<03:32,  1.33it/s] 46%|████▌     | 238/520 [02:57<03:30,  1.34it/s] 46%|████▌     | 239/520 [02:58<03:36,  1.30it/s] 46%|████▌     | 240/520 [02:59<03:34,  1.30it/s] 46%|████▋     | 241/520 [03:00<03:39,  1.27it/s] 47%|████▋     | 242/520 [03:00<03:33,  1.30it/s] 47%|████▋     | 243/520 [03:01<03:30,  1.32it/s] 47%|████▋     | 244/520 [03:02<03:27,  1.33it/s] 47%|████▋     | 245/520 [03:03<03:28,  1.32it/s] 47%|████▋     | 246/520 [03:03<03:23,  1.35it/s] 48%|████▊     | 247/520 [03:04<03:19,  1.37it/s] 48%|████▊     | 248/520 [03:05<03:19,  1.37it/s] 48%|████▊     | 249/520 [03:05<03:17,  1.37it/s] 48%|████▊     | 250/520 [03:06<03:15,  1.38it/s] 48%|████▊     | 251/520 [03:07<03:16,  1.37it/s] 48%|████▊     | 252/520 [03:08<03:12,  1.39it/s] 49%|████▊     | 253/520 [03:08<03:13,  1.38it/s] 49%|████▉     | 254/520 [03:09<03:16,  1.36it/s] 49%|████▉     | 255/520 [03:10<03:15,  1.36it/s] 49%|████▉     | 256/520 [03:10<03:12,  1.37it/s] 49%|████▉     | 257/520 [03:11<03:12,  1.37it/s] 50%|████▉     | 258/520 [03:12<03:11,  1.37it/s] 50%|████▉     | 259/520 [03:13<03:11,  1.36it/s] 50%|█████     | 260/520 [03:13<03:07,  1.39it/s] 50%|█████     | 261/520 [03:14<03:10,  1.36it/s] 50%|█████     | 262/520 [03:15<03:14,  1.33it/s] 51%|█████     | 263/520 [03:16<03:11,  1.34it/s] 51%|█████     | 264/520 [03:16<03:06,  1.37it/s] 51%|█████     | 265/520 [03:17<03:09,  1.35it/s] 51%|█████     | 266/520 [03:18<03:10,  1.33it/s] 51%|█████▏    | 267/520 [03:19<03:10,  1.33it/s] 52%|█████▏    | 268/520 [03:19<03:07,  1.34it/s] 52%|█████▏    | 269/520 [03:20<03:03,  1.37it/s] 52%|█████▏    | 270/520 [03:21<03:03,  1.37it/s] 52%|█████▏    | 271/520 [03:21<02:59,  1.39it/s] 52%|█████▏    | 272/520 [03:22<02:57,  1.40it/s] 52%|█████▎    | 273/520 [03:23<03:00,  1.37it/s] 53%|█████▎    | 274/520 [03:24<02:56,  1.39it/s] 53%|█████▎    | 275/520 [03:24<02:59,  1.37it/s] 53%|█████▎    | 276/520 [03:25<02:59,  1.36it/s] 53%|█████▎    | 277/520 [03:26<03:01,  1.34it/s] 53%|█████▎    | 278/520 [03:27<03:00,  1.34it/s] 54%|█████▎    | 279/520 [03:27<02:58,  1.35it/s] 54%|█████▍    | 280/520 [03:28<02:53,  1.39it/s] 54%|█████▍    | 281/520 [03:29<02:56,  1.36it/s] 54%|█████▍    | 282/520 [03:30<02:53,  1.37it/s] 54%|█████▍    | 283/520 [03:30<02:51,  1.39it/s] 55%|█████▍    | 284/520 [03:31<02:47,  1.41it/s] 55%|█████▍    | 285/520 [03:32<02:49,  1.39it/s] 55%|█████▌    | 286/520 [03:32<02:52,  1.36it/s] 55%|█████▌    | 287/520 [03:33<02:49,  1.38it/s] 55%|█████▌    | 288/520 [03:34<02:49,  1.37it/s] 56%|█████▌    | 289/520 [03:35<02:48,  1.37it/s] 56%|█████▌    | 290/520 [03:35<02:49,  1.35it/s] 56%|█████▌    | 291/520 [03:36<02:47,  1.36it/s] 56%|█████▌    | 292/520 [03:37<02:43,  1.40it/s] 56%|█████▋    | 293/520 [03:38<02:41,  1.40it/s] 57%|█████▋    | 294/520 [03:38<02:39,  1.42it/s] 57%|█████▋    | 295/520 [03:39<02:42,  1.38it/s] 57%|█████▋    | 296/520 [03:40<02:42,  1.38it/s] 57%|█████▋    | 297/520 [03:40<02:41,  1.38it/s] 57%|█████▋    | 298/520 [03:41<02:40,  1.38it/s] 57%|█████▊    | 299/520 [03:42<02:46,  1.33it/s] 58%|█████▊    | 300/520 [03:43<02:42,  1.35it/s] 58%|█████▊    | 301/520 [03:43<02:42,  1.35it/s] 58%|█████▊    | 302/520 [03:44<02:41,  1.35it/s] 58%|█████▊    | 303/520 [03:45<02:36,  1.39it/s] 58%|█████▊    | 304/520 [03:46<02:36,  1.38it/s] 59%|█████▊    | 305/520 [03:46<02:47,  1.28it/s] 59%|█████▉    | 306/520 [03:47<02:45,  1.29it/s] 59%|█████▉    | 307/520 [03:48<02:39,  1.33it/s] 59%|█████▉    | 308/520 [03:49<02:37,  1.34it/s] 59%|█████▉    | 309/520 [03:49<02:37,  1.34it/s] 60%|█████▉    | 310/520 [03:50<02:34,  1.36it/s] 60%|█████▉    | 311/520 [03:51<02:35,  1.35it/s] 60%|██████    | 312/520 [03:52<02:28,  1.40it/s] 60%|██████    | 313/520 [03:52<02:29,  1.39it/s] 60%|██████    | 314/520 [03:53<02:27,  1.40it/s] 61%|██████    | 315/520 [03:54<02:24,  1.42it/s] 61%|██████    | 316/520 [03:54<02:33,  1.33it/s] 61%|██████    | 317/520 [03:55<02:31,  1.34it/s] 61%|██████    | 318/520 [03:56<02:30,  1.34it/s] 61%|██████▏   | 319/520 [03:57<02:29,  1.34it/s] 62%|██████▏   | 320/520 [03:57<02:27,  1.36it/s] 62%|██████▏   | 321/520 [03:58<02:29,  1.33it/s] 62%|██████▏   | 322/520 [03:59<02:29,  1.32it/s] 62%|██████▏   | 323/520 [04:00<02:32,  1.29it/s] 62%|██████▏   | 324/520 [04:01<02:27,  1.33it/s] 62%|██████▎   | 325/520 [04:01<02:24,  1.35it/s] 63%|██████▎   | 326/520 [04:02<02:24,  1.34it/s] 63%|██████▎   | 327/520 [04:03<02:23,  1.35it/s] 63%|██████▎   | 328/520 [04:03<02:20,  1.36it/s] 63%|██████▎   | 329/520 [04:04<02:18,  1.38it/s] 63%|██████▎   | 330/520 [04:05<02:20,  1.35it/s] 64%|██████▎   | 331/520 [04:06<02:19,  1.36it/s] 64%|██████▍   | 332/520 [04:06<02:18,  1.35it/s] 64%|██████▍   | 333/520 [04:07<02:17,  1.36it/s] 64%|██████▍   | 334/520 [04:08<02:16,  1.36it/s] 64%|██████▍   | 335/520 [04:09<02:17,  1.35it/s] 65%|██████▍   | 336/520 [04:09<02:13,  1.38it/s] 65%|██████▍   | 337/520 [04:10<02:11,  1.39it/s] 65%|██████▌   | 338/520 [04:11<02:10,  1.39it/s] 65%|██████▌   | 339/520 [04:11<02:11,  1.37it/s] 65%|██████▌   | 340/520 [04:12<02:10,  1.38it/s] 66%|██████▌   | 341/520 [04:13<02:09,  1.38it/s] 66%|██████▌   | 342/520 [04:14<02:11,  1.35it/s] 66%|██████▌   | 343/520 [04:14<02:11,  1.34it/s] 66%|██████▌   | 344/520 [04:15<02:09,  1.36it/s] 66%|██████▋   | 345/520 [04:16<02:09,  1.36it/s] 67%|██████▋   | 346/520 [04:17<02:09,  1.34it/s] 67%|██████▋   | 347/520 [04:17<02:11,  1.31it/s] 67%|██████▋   | 348/520 [04:18<02:08,  1.34it/s] 67%|██████▋   | 349/520 [04:19<02:05,  1.36it/s] 67%|██████▋   | 350/520 [04:20<02:05,  1.36it/s] 68%|██████▊   | 351/520 [04:20<02:06,  1.34it/s] 68%|██████▊   | 352/520 [04:21<02:10,  1.28it/s] 68%|██████▊   | 353/520 [04:22<02:06,  1.32it/s] 68%|██████▊   | 354/520 [04:23<02:05,  1.32it/s] 68%|██████▊   | 355/520 [04:23<02:05,  1.32it/s] 68%|██████▊   | 356/520 [04:24<02:00,  1.36it/s] 69%|██████▊   | 357/520 [04:25<02:01,  1.34it/s] 69%|██████▉   | 358/520 [04:26<01:59,  1.36it/s] 69%|██████▉   | 359/520 [04:26<01:58,  1.36it/s] 69%|██████▉   | 360/520 [04:27<01:56,  1.38it/s] 69%|██████▉   | 361/520 [04:28<01:55,  1.38it/s] 70%|██████▉   | 362/520 [04:29<01:54,  1.38it/s] 70%|██████▉   | 363/520 [04:29<01:55,  1.36it/s] 70%|███████   | 364/520 [04:30<01:53,  1.37it/s] 70%|███████   | 365/520 [04:31<01:53,  1.37it/s] 70%|███████   | 366/520 [04:31<01:54,  1.35it/s] 71%|███████   | 367/520 [04:32<01:51,  1.38it/s] 71%|███████   | 368/520 [04:33<01:49,  1.39it/s] 71%|███████   | 369/520 [04:34<01:47,  1.40it/s] 71%|███████   | 370/520 [04:34<01:45,  1.43it/s] 71%|███████▏  | 371/520 [04:35<01:49,  1.36it/s] 72%|███████▏  | 372/520 [04:36<01:48,  1.37it/s] 72%|███████▏  | 373/520 [04:36<01:45,  1.39it/s] 72%|███████▏  | 374/520 [04:37<01:46,  1.37it/s] 72%|███████▏  | 375/520 [04:38<01:46,  1.36it/s] 72%|███████▏  | 376/520 [04:39<01:46,  1.36it/s] 72%|███████▎  | 377/520 [04:39<01:43,  1.38it/s] 73%|███████▎  | 378/520 [04:40<01:43,  1.37it/s] 73%|███████▎  | 379/520 [04:41<01:43,  1.36it/s] 73%|███████▎  | 380/520 [04:42<01:40,  1.39it/s] 73%|███████▎  | 381/520 [04:42<01:38,  1.41it/s] 73%|███████▎  | 382/520 [04:43<01:37,  1.41it/s] 74%|███████▎  | 383/520 [04:44<01:41,  1.35it/s] 74%|███████▍  | 384/520 [04:44<01:38,  1.38it/s] 74%|███████▍  | 385/520 [04:45<01:36,  1.41it/s] 74%|███████▍  | 386/520 [04:46<01:35,  1.41it/s] 74%|███████▍  | 387/520 [04:47<01:36,  1.38it/s] 75%|███████▍  | 388/520 [04:47<01:35,  1.39it/s] 75%|███████▍  | 389/520 [04:48<01:33,  1.40it/s] 75%|███████▌  | 390/520 [04:49<01:34,  1.37it/s] 75%|███████▌  | 391/520 [04:50<01:35,  1.35it/s] 75%|███████▌  | 392/520 [04:50<01:34,  1.36it/s] 76%|███████▌  | 393/520 [04:51<01:36,  1.32it/s] 76%|███████▌  | 394/520 [04:52<01:33,  1.35it/s] 76%|███████▌  | 395/520 [04:53<01:33,  1.34it/s] 76%|███████▌  | 396/520 [04:53<01:30,  1.37it/s] 76%|███████▋  | 397/520 [04:54<01:28,  1.38it/s] 77%|███████▋  | 398/520 [04:55<01:28,  1.38it/s] 77%|███████▋  | 399/520 [04:55<01:27,  1.38it/s] 77%|███████▋  | 400/520 [04:56<01:28,  1.35it/s] 77%|███████▋  | 401/520 [04:57<01:28,  1.35it/s] 77%|███████▋  | 402/520 [04:58<01:25,  1.38it/s] 78%|███████▊  | 403/520 [04:58<01:23,  1.40it/s] 78%|███████▊  | 404/520 [04:59<01:22,  1.40it/s] 78%|███████▊  | 405/520 [05:00<01:22,  1.40it/s] 78%|███████▊  | 406/520 [05:00<01:21,  1.40it/s] 78%|███████▊  | 407/520 [05:01<01:19,  1.42it/s] 78%|███████▊  | 408/520 [05:02<01:19,  1.40it/s] 79%|███████▊  | 409/520 [05:03<01:21,  1.36it/s] 79%|███████▉  | 410/520 [05:03<01:22,  1.34it/s] 79%|███████▉  | 411/520 [05:04<01:19,  1.36it/s] 79%|███████▉  | 412/520 [05:05<01:17,  1.39it/s] 79%|███████▉  | 413/520 [05:06<01:17,  1.38it/s] 80%|███████▉  | 414/520 [05:06<01:15,  1.40it/s] 80%|███████▉  | 415/520 [05:07<01:14,  1.41it/s] 80%|████████  | 416/520 [05:08<01:13,  1.41it/s] 80%|████████  | 417/520 [05:08<01:16,  1.35it/s] 80%|████████  | 418/520 [05:09<01:13,  1.38it/s] 81%|████████  | 419/520 [05:10<01:11,  1.40it/s] 81%|████████  | 420/520 [05:11<01:10,  1.42it/s] 81%|████████  | 421/520 [05:11<01:10,  1.41it/s] 81%|████████  | 422/520 [05:12<01:10,  1.38it/s] 81%|████████▏ | 423/520 [05:13<01:10,  1.37it/s] 82%|████████▏ | 424/520 [05:13<01:09,  1.37it/s] 82%|████████▏ | 425/520 [05:14<01:09,  1.36it/s] 82%|████████▏ | 426/520 [05:15<01:08,  1.36it/s] 82%|████████▏ | 427/520 [05:16<01:09,  1.34it/s] 82%|████████▏ | 428/520 [05:17<01:09,  1.33it/s] 82%|████████▎ | 429/520 [05:17<01:09,  1.31it/s] 83%|████████▎ | 430/520 [05:18<01:08,  1.31it/s] 83%|████████▎ | 431/520 [05:19<01:06,  1.33it/s] 83%|████████▎ | 432/520 [05:19<01:05,  1.35it/s] 83%|████████▎ | 433/520 [05:20<01:05,  1.33it/s] 83%|████████▎ | 434/520 [05:21<01:04,  1.34it/s] 84%|████████▎ | 435/520 [05:22<01:05,  1.29it/s] 84%|████████▍ | 436/520 [05:23<01:03,  1.32it/s] 84%|████████▍ | 437/520 [05:23<01:03,  1.31it/s] 84%|████████▍ | 438/520 [05:24<01:02,  1.31it/s] 84%|████████▍ | 439/520 [05:25<01:00,  1.35it/s] 85%|████████▍ | 440/520 [05:26<00:58,  1.36it/s] 85%|████████▍ | 441/520 [05:26<00:58,  1.36it/s] 85%|████████▌ | 442/520 [05:27<00:57,  1.36it/s] 85%|████████▌ | 443/520 [05:28<00:57,  1.34it/s] 85%|████████▌ | 444/520 [05:28<00:55,  1.36it/s] 86%|████████▌ | 445/520 [05:29<00:55,  1.35it/s] 86%|████████▌ | 446/520 [05:30<00:53,  1.37it/s] 86%|████████▌ | 447/520 [05:31<00:53,  1.38it/s] 86%|████████▌ | 448/520 [05:31<00:52,  1.36it/s] 86%|████████▋ | 449/520 [05:32<00:52,  1.36it/s] 87%|████████▋ | 450/520 [05:33<00:50,  1.38it/s] 87%|████████▋ | 451/520 [05:34<00:50,  1.38it/s] 87%|████████▋ | 452/520 [05:34<00:50,  1.35it/s] 87%|████████▋ | 453/520 [05:35<00:48,  1.37it/s] 87%|████████▋ | 454/520 [05:36<00:48,  1.37it/s] 88%|████████▊ | 455/520 [05:37<00:47,  1.37it/s] 88%|████████▊ | 456/520 [05:37<00:46,  1.38it/s] 88%|████████▊ | 457/520 [05:38<00:46,  1.37it/s] 88%|████████▊ | 458/520 [05:39<00:45,  1.35it/s] 88%|████████▊ | 459/520 [05:39<00:45,  1.35it/s] 88%|████████▊ | 460/520 [05:40<00:43,  1.38it/s] 89%|████████▊ | 461/520 [05:41<00:41,  1.41it/s] 89%|████████▉ | 462/520 [05:42<00:41,  1.40it/s] 89%|████████▉ | 463/520 [05:42<00:40,  1.40it/s] 89%|████████▉ | 464/520 [05:43<00:41,  1.35it/s] 89%|████████▉ | 465/520 [05:44<00:40,  1.36it/s] 90%|████████▉ | 466/520 [05:45<00:39,  1.38it/s] 90%|████████▉ | 467/520 [05:45<00:39,  1.35it/s] 90%|█████████ | 468/520 [05:46<00:38,  1.36it/s] 90%|█████████ | 469/520 [05:47<00:38,  1.33it/s] 90%|█████████ | 470/520 [05:48<00:37,  1.32it/s] 91%|█████████ | 471/520 [05:48<00:36,  1.34it/s] 91%|█████████ | 472/520 [05:49<00:35,  1.37it/s] 91%|█████████ | 473/520 [05:50<00:34,  1.36it/s] 91%|█████████ | 474/520 [05:50<00:33,  1.38it/s] 91%|█████████▏| 475/520 [05:51<00:32,  1.40it/s] 92%|█████████▏| 476/520 [05:52<00:31,  1.39it/s] 92%|█████████▏| 477/520 [05:53<00:30,  1.40it/s] 92%|█████████▏| 478/520 [05:53<00:30,  1.38it/s] 92%|█████████▏| 479/520 [05:54<00:29,  1.38it/s] 92%|█████████▏| 480/520 [05:55<00:28,  1.38it/s] 92%|█████████▎| 481/520 [05:55<00:27,  1.41it/s] 93%|█████████▎| 482/520 [05:56<00:28,  1.35it/s] 93%|█████████▎| 483/520 [05:57<00:27,  1.37it/s] 93%|█████████▎| 484/520 [05:58<00:26,  1.37it/s] 93%|█████████▎| 485/520 [05:58<00:25,  1.36it/s] 93%|█████████▎| 486/520 [05:59<00:24,  1.40it/s] 94%|█████████▎| 487/520 [06:00<00:23,  1.42it/s] 94%|█████████▍| 488/520 [06:01<00:22,  1.39it/s] 94%|█████████▍| 489/520 [06:01<00:21,  1.43it/s] 94%|█████████▍| 490/520 [06:02<00:21,  1.42it/s] 94%|█████████▍| 491/520 [06:03<00:20,  1.38it/s] 95%|█████████▍| 492/520 [06:03<00:20,  1.36it/s] 95%|█████████▍| 493/520 [06:04<00:19,  1.36it/s] 95%|█████████▌| 494/520 [06:05<00:18,  1.37it/s] 95%|█████████▌| 495/520 [06:06<00:18,  1.35it/s] 95%|█████████▌| 496/520 [06:06<00:17,  1.37it/s] 96%|█████████▌| 497/520 [06:07<00:16,  1.39it/s] 96%|█████████▌| 498/520 [06:08<00:15,  1.40it/s] 96%|█████████▌| 499/520 [06:08<00:15,  1.39it/s] 96%|█████████▌| 500/520 [06:09<00:14,  1.40it/s]                                                  96%|█████████▌| 500/520 [06:09<00:14,  1.40it/s] 96%|█████████▋| 501/520 [06:10<00:14,  1.35it/s] 97%|█████████▋| 502/520 [06:11<00:13,  1.37it/s] 97%|█████████▋| 503/520 [06:11<00:12,  1.37it/s] 97%|█████████▋| 504/520 [06:12<00:11,  1.37it/s] 97%|█████████▋| 505/520 [06:13<00:10,  1.40it/s] 97%|█████████▋| 506/520 [06:14<00:09,  1.42it/s] 98%|█████████▊| 507/520 [06:14<00:09,  1.41it/s] 98%|█████████▊| 508/520 [06:15<00:08,  1.45it/s] 98%|█████████▊| 509/520 [06:16<00:07,  1.43it/s] 98%|█████████▊| 510/520 [06:16<00:07,  1.39it/s] 98%|█████████▊| 511/520 [06:17<00:06,  1.41it/s] 98%|█████████▊| 512/520 [06:18<00:05,  1.40it/s] 99%|█████████▊| 513/520 [06:19<00:05,  1.36it/s] 99%|█████████▉| 514/520 [06:19<00:04,  1.39it/s] 99%|█████████▉| 515/520 [06:20<00:03,  1.38it/s] 99%|█████████▉| 516/520 [06:21<00:02,  1.40it/s] 99%|█████████▉| 517/520 [06:21<00:02,  1.38it/s]100%|█████████▉| 518/520 [06:22<00:01,  1.40it/s]100%|█████████▉| 519/520 [06:23<00:00,  1.41it/s]100%|██████████| 520/520 [06:24<00:00,  1.37it/s][INFO|trainer.py:3812] 2024-11-22 22:56:51,141 >> Saving model checkpoint to t5-large-output/10/1e-4/checkpoint-520
[INFO|configuration_utils.py:414] 2024-11-22 22:56:51,165 >> Configuration saved in t5-large-output/10/1e-4/checkpoint-520/config.json
[INFO|configuration_utils.py:865] 2024-11-22 22:56:51,169 >> Configuration saved in t5-large-output/10/1e-4/checkpoint-520/generation_config.json
[INFO|modeling_utils.py:3035] 2024-11-22 22:56:54,725 >> Model weights saved in t5-large-output/10/1e-4/checkpoint-520/model.safetensors
[INFO|tokenization_utils_base.py:2646] 2024-11-22 22:56:54,734 >> tokenizer config file saved in t5-large-output/10/1e-4/checkpoint-520/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2024-11-22 22:56:54,739 >> Special tokens file saved in t5-large-output/10/1e-4/checkpoint-520/special_tokens_map.json
[INFO|trainer.py:2591] 2024-11-22 22:57:01,287 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 520/520 [06:34<00:00,  1.37it/s]100%|██████████| 520/520 [06:34<00:00,  1.32it/s]
[INFO|trainer.py:3812] 2024-11-22 22:57:01,288 >> Saving model checkpoint to t5-large-output/10/1e-4
[INFO|configuration_utils.py:414] 2024-11-22 22:57:01,302 >> Configuration saved in t5-large-output/10/1e-4/config.json
[INFO|configuration_utils.py:865] 2024-11-22 22:57:01,306 >> Configuration saved in t5-large-output/10/1e-4/generation_config.json
[INFO|modeling_utils.py:3035] 2024-11-22 22:57:04,610 >> Model weights saved in t5-large-output/10/1e-4/model.safetensors
[INFO|tokenization_utils_base.py:2646] 2024-11-22 22:57:04,618 >> tokenizer config file saved in t5-large-output/10/1e-4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2655] 2024-11-22 22:57:04,623 >> Special tokens file saved in t5-large-output/10/1e-4/special_tokens_map.json
{'loss': 0.5904, 'grad_norm': 4.225503921508789, 'learning_rate': 3.846153846153847e-06, 'epoch': 9.52}
{'train_runtime': 394.2442, 'train_samples_per_second': 42.562, 'train_steps_per_second': 1.319, 'train_loss': 0.5756038601581867, 'epoch': 9.9}
***** train metrics *****
  epoch                    =     9.9048
  total_flos               =  4036723GF
  train_loss               =     0.5756
  train_runtime            = 0:06:34.24
  train_samples            =       1678
  train_samples_per_second =     42.562
  train_steps_per_second   =      1.319
11/22/2024 22:57:04 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:4128] 2024-11-22 22:57:04,657 >> 
***** Running Evaluation *****
[INFO|trainer.py:4130] 2024-11-22 22:57:04,657 >>   Num examples = 187
[INFO|trainer.py:4133] 2024-11-22 22:57:04,657 >>   Batch size = 8
  0%|          | 0/24 [00:00<?, ?it/s]  8%|▊         | 2/24 [00:01<00:15,  1.42it/s] 12%|█▎        | 3/24 [00:02<00:17,  1.18it/s] 17%|█▋        | 4/24 [00:03<00:19,  1.01it/s][WARNING|trainer.py:761] 2024-11-22 22:57:13,327 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:13,328 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:13,328 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:13,328 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 21%|██        | 5/24 [00:07<00:36,  1.94s/it] 25%|██▌       | 6/24 [00:08<00:28,  1.61s/it] 29%|██▉       | 7/24 [00:09<00:26,  1.56s/it] 33%|███▎      | 8/24 [00:10<00:22,  1.41s/it] 38%|███▊      | 9/24 [00:12<00:21,  1.41s/it][WARNING|trainer.py:761] 2024-11-22 22:57:19,326 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:19,326 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:19,326 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:19,326 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 42%|████▏     | 10/24 [00:13<00:18,  1.31s/it][WARNING|trainer.py:761] 2024-11-22 22:57:20,357 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:20,358 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:20,358 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:20,358 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|████▌     | 11/24 [00:14<00:15,  1.23s/it][WARNING|trainer.py:761] 2024-11-22 22:57:21,502 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:21,502 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:21,503 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:21,503 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 50%|█████     | 12/24 [00:15<00:14,  1.20s/it] 54%|█████▍    | 13/24 [00:16<00:12,  1.13s/it] 58%|█████▊    | 14/24 [00:17<00:10,  1.06s/it] 62%|██████▎   | 15/24 [00:18<00:09,  1.06s/it] 67%|██████▋   | 16/24 [00:19<00:09,  1.17s/it][WARNING|trainer.py:761] 2024-11-22 22:57:27,147 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:27,147 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:27,147 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:27,147 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 71%|███████   | 17/24 [00:21<00:08,  1.21s/it][WARNING|trainer.py:761] 2024-11-22 22:57:28,044 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,044 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,044 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,044 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,088 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,088 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,088 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:28,088 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|███████▌  | 18/24 [00:22<00:06,  1.13s/it] 79%|███████▉  | 19/24 [00:23<00:05,  1.15s/it] 83%|████████▎ | 20/24 [00:24<00:04,  1.13s/it][WARNING|trainer.py:761] 2024-11-22 22:57:31,191 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:31,191 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:31,191 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:31,191 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 88%|████████▊ | 21/24 [00:25<00:03,  1.04s/it] 92%|█████████▏| 22/24 [00:27<00:02,  1.27s/it] 96%|█████████▌| 23/24 [00:28<00:01,  1.21s/it][WARNING|trainer.py:761] 2024-11-22 22:57:34,783 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,783 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,783 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,783 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,827 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,827 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,827 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:34,827 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
***** eval metrics *****
  epoch                   =     9.9048
  eval_gen_len            =    13.6791
  eval_loss               =     0.4278
  eval_rouge1             =    44.4982
  eval_rouge2             =    35.3017
  eval_rougeL             =    43.8864
  eval_rougeLsum          =    44.1202
  eval_runtime            = 0:00:30.57
  eval_samples            =        187
  eval_samples_per_second =      6.116
  eval_steps_per_second   =      0.785
11/22/2024 22:57:35 - INFO - __main__ - *** Predict ***
100%|██████████| 24/24 [00:28<00:00,  1.07s/it]100%|██████████| 24/24 [00:29<00:00,  1.22s/it]
[INFO|trainer.py:4128] 2024-11-22 22:57:35,251 >> 
***** Running Prediction *****
[INFO|trainer.py:4130] 2024-11-22 22:57:35,251 >>   Num examples = 467
[INFO|trainer.py:4133] 2024-11-22 22:57:35,251 >>   Batch size = 8
  0%|          | 0/59 [00:00<?, ?it/s]  3%|▎         | 2/59 [00:01<00:44,  1.30it/s]  5%|▌         | 3/59 [00:02<00:51,  1.08it/s]  7%|▋         | 4/59 [00:03<00:55,  1.01s/it][WARNING|trainer.py:761] 2024-11-22 22:57:43,761 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:43,761 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:43,761 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:43,761 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
  8%|▊         | 5/59 [00:07<01:41,  1.89s/it] 10%|█         | 6/59 [00:08<01:26,  1.64s/it][WARNING|trainer.py:761] 2024-11-22 22:57:46,379 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:46,379 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:46,379 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:46,379 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 12%|█▏        | 7/59 [00:09<01:22,  1.59s/it][WARNING|trainer.py:761] 2024-11-22 22:57:47,294 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:47,294 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:47,294 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:47,294 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 14%|█▎        | 8/59 [00:10<01:10,  1.38s/it][WARNING|trainer.py:761] 2024-11-22 22:57:49,425 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:49,425 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:49,425 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:49,425 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 15%|█▌        | 9/59 [00:13<01:20,  1.61s/it] 17%|█▋        | 10/59 [00:14<01:10,  1.44s/it] 19%|█▊        | 11/59 [00:15<01:04,  1.35s/it] 20%|██        | 12/59 [00:16<00:58,  1.25s/it][WARNING|trainer.py:761] 2024-11-22 22:57:54,153 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:54,153 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:54,153 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:54,153 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 22%|██▏       | 13/59 [00:17<01:01,  1.33s/it] 24%|██▎       | 14/59 [00:18<00:56,  1.25s/it][WARNING|trainer.py:761] 2024-11-22 22:57:56,183 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:56,183 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:56,183 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:57:56,183 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 25%|██▌       | 15/59 [00:19<00:51,  1.17s/it] 27%|██▋       | 16/59 [00:20<00:48,  1.12s/it] 29%|██▉       | 17/59 [00:21<00:47,  1.13s/it] 31%|███       | 18/59 [00:22<00:44,  1.09s/it] 32%|███▏      | 19/59 [00:24<00:44,  1.11s/it][WARNING|trainer.py:761] 2024-11-22 22:58:01,337 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:01,337 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:01,337 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:01,337 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 34%|███▍      | 20/59 [00:24<00:39,  1.02s/it] 36%|███▌      | 21/59 [00:25<00:37,  1.01it/s] 37%|███▋      | 22/59 [00:26<00:37,  1.02s/it] 39%|███▉      | 23/59 [00:28<00:40,  1.13s/it] 41%|████      | 24/59 [00:29<00:38,  1.11s/it] 42%|████▏     | 25/59 [00:30<00:37,  1.12s/it] 44%|████▍     | 26/59 [00:32<00:42,  1.30s/it][WARNING|trainer.py:761] 2024-11-22 22:58:09,778 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:09,778 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:09,778 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:09,778 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 46%|████▌     | 27/59 [00:33<00:40,  1.25s/it] 47%|████▋     | 28/59 [00:34<00:34,  1.12s/it][WARNING|trainer.py:761] 2024-11-22 22:58:11,593 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,593 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,593 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,593 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,643 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,643 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,643 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:11,643 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 49%|████▉     | 29/59 [00:35<00:33,  1.10s/it][WARNING|trainer.py:761] 2024-11-22 22:58:12,748 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:12,748 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:12,748 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:12,748 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 51%|█████     | 30/59 [00:36<00:31,  1.10s/it] 53%|█████▎    | 31/59 [00:37<00:32,  1.16s/it][WARNING|trainer.py:761] 2024-11-22 22:58:15,170 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:15,170 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:15,170 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:15,170 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 54%|█████▍    | 32/59 [00:38<00:31,  1.15s/it][WARNING|trainer.py:761] 2024-11-22 22:58:16,184 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:16,184 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:16,184 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:16,184 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 56%|█████▌    | 33/59 [00:39<00:28,  1.11s/it] 58%|█████▊    | 34/59 [00:40<00:27,  1.10s/it] 59%|█████▉    | 35/59 [00:42<00:27,  1.15s/it] 61%|██████    | 36/59 [00:43<00:24,  1.07s/it][WARNING|trainer.py:761] 2024-11-22 22:58:20,286 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:20,286 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:20,287 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:20,287 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 63%|██████▎   | 37/59 [00:43<00:22,  1.03s/it] 64%|██████▍   | 38/59 [00:45<00:24,  1.16s/it] 66%|██████▌   | 39/59 [00:46<00:23,  1.16s/it] 68%|██████▊   | 40/59 [00:47<00:21,  1.13s/it] 69%|██████▉   | 41/59 [00:48<00:19,  1.11s/it][WARNING|trainer.py:761] 2024-11-22 22:58:25,907 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:25,907 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:25,907 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:25,907 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 71%|███████   | 42/59 [00:49<00:17,  1.02s/it] 73%|███████▎  | 43/59 [00:50<00:16,  1.04s/it][WARNING|trainer.py:761] 2024-11-22 22:58:28,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:28,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:28,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:28,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 75%|███████▍  | 44/59 [00:51<00:15,  1.04s/it] 76%|███████▋  | 45/59 [00:52<00:14,  1.04s/it] 78%|███████▊  | 46/59 [00:53<00:13,  1.00s/it] 80%|███████▉  | 47/59 [00:54<00:11,  1.01it/s] 81%|████████▏ | 48/59 [00:55<00:11,  1.00s/it] 83%|████████▎ | 49/59 [00:56<00:10,  1.05s/it][WARNING|trainer.py:761] 2024-11-22 22:58:34,252 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:34,252 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:34,252 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:34,252 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 85%|████████▍ | 50/59 [00:57<00:09,  1.07s/it] 86%|████████▋ | 51/59 [00:59<00:10,  1.35s/it][WARNING|trainer.py:761] 2024-11-22 22:58:37,459 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:37,459 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:37,459 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:37,459 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 88%|████████▊ | 52/59 [01:01<00:09,  1.30s/it][WARNING|trainer.py:761] 2024-11-22 22:58:38,690 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:38,690 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:38,690 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:38,690 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 90%|████████▉ | 53/59 [01:02<00:07,  1.28s/it][WARNING|trainer.py:761] 2024-11-22 22:58:40,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,023 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,024 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,024 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,066 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,067 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,067 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:40,067 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 92%|█████████▏| 54/59 [01:03<00:06,  1.31s/it] 93%|█████████▎| 55/59 [01:04<00:04,  1.23s/it][WARNING|trainer.py:761] 2024-11-22 22:58:41,911 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:41,911 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:41,911 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:41,911 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
 95%|█████████▍| 56/59 [01:05<00:03,  1.10s/it] 97%|█████████▋| 57/59 [01:06<00:02,  1.13s/it] 98%|█████████▊| 58/59 [01:07<00:01,  1.13s/it][WARNING|trainer.py:761] 2024-11-22 22:58:45,094 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:45,094 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:45,094 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[WARNING|trainer.py:761] 2024-11-22 22:58:45,094 >> Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
100%|██████████| 59/59 [01:08<00:00,  1.05s/it]100%|██████████| 59/59 [01:09<00:00,  1.18s/it]
[INFO|modelcard.py:449] 2024-11-22 22:58:46,162 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Summarization', 'type': 'summarization'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 44.4982}]}
***** predict metrics *****
  predict_gen_len            =    14.2056
  predict_loss               =     0.3452
  predict_rouge1             =    40.3181
  predict_rouge2             =    31.7333
  predict_rougeL             =    39.9149
  predict_rougeLsum          =    39.9014
  predict_runtime            = 0:01:10.58
  predict_samples            =        467
  predict_samples_per_second =      6.616
  predict_steps_per_second   =      0.836
