# dummy_df.py

import pandas as pd
import logging
import sys


# If you want to use a pipeline instead:
# from transformers import pipeline

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,  # DEBUG for verbose logs; switch to INFO or WARNING in production
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

###############################################################################
#                               SAMPLE DATA
###############################################################################
overview = pd.DataFrame({ 
    'Category': ['Rating', 'Soundness', 'Presentation', 'Contribution'],
    'Avg_Score': [4.8, 2.8, 2.6, 2.4],
    'Individual_scores': [
        [['Reviewer eS3u', 6.0], ['Reviewer jP4i', 5.0], ['Reviewer wiS9', 3.0], ['Reviewer a6Ps', 5.0], ['Reviewer Frem', 5.0]],
    	[['Reviewer eS3u', 3.0], ['Reviewer jP4i', 3.0], ['Reviewer wiS9', 2.0], ['Reviewer a6Ps', 3.0], ['Reviewer Frem', 3.0]],
        [['Reviewer eS3u', 2.0], ['Reviewer jP4i', 3.0], ['Reviewer wiS9', 2.0], ['Reviewer a6Ps', 3.0], ['Reviewer Frem', 3.0]],
    	[['Reviewer eS3u', 3.0], ['Reviewer jP4i', 2.0], ['Reviewer wiS9', 2.0], ['Reviewer a6Ps', 3.0], ['Reviewer Frem', 2.0]]

    ]
})

attitude_roots = pd.DataFrame({
    'Attitude_roots': ['Substance(EXP)','Substance(MET)','Clarity(OAL)','Substance(DAT)','Originality(MET)','Meaningful-comparison(MET)','Clarity(MET)','Originality(PDI)','Clarity(RWK)','Meaningful-comparison(TNF)','Meaningful-comparison(RWK)','Substance(TNF)'],
    'Frequency': [0.8,0.8,0.6,0.6,0.4,0.4,0.4,0.4,0.2,0.2,0.2,0.2,],
    'Descriptions': [
                    'Experimental study not strong enough',
                    'Incomplete details on perfromance of the method',
                    '3. The paper is not nicely written or rather easy to follow.',
                    'Less datasets used',
                    'Limited novelty in theoretical contribution',
                    'Missing theoretical comparisons',
                    'Unclear description of method',
                    'The main reason is that from the narration, I cannot figure out what is the idea or technique of other works and what is the contribution of this paper.',
                    'Improper writing of realted work section (as in 1 paragraph rather than multiple for related work, explanation of somepapers, etc)',
                    'Missing explanation of comparsion with related work in tables and figures',
                    'Missing baselines',
                    'Incomprehensible tables and figures (what is the point of the plot, no decription of figure in main text, etc)'
    ],
    'Comments': [
            [['Reviewer eS3u', ['1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method.']], ['Reviewer wiS9', ['My major concern is with the experimental setup. While the experiments on ShapeNet is common in the community and shows good result, I am in general doubtful whether such an approach could be really applied to the real world.', 'In motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases.', 'It would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.']], ['Reviewer Frem', ['3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method.', '3) Experimental results are good.', "1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset."]], ['Reviewer jP4i', ['2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the "global" features by such a mechanism, the features turn to "local"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so) 3. Regarding the experiments: 3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments.', '3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.', '3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.']]],
            [['Reviewer eS3u', ['2. The proposed method is straightforward and shown to be effective on the test data.', '1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method.', '3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?']], ['Reviewer wiS9', ['1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity?', '2. Will the network still be functional if the density distributions are different across input and output?', '4. Would non-gt and/or biased key points and semantic parts be transferred properly?']], ['Reviewer Frem', ['3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method.', '2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation.']], ['Reviewer jP4i', ['2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer.', '2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the "global" features by such a mechanism, the features turn to "local"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so) 3. Regarding the experiments: 3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments.', '3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.', '3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?']]],
            [['Reviewer eS3u', ['1. The paper is in general well organized and easy to follow.']], ['Reviewer wiS9', ['1) This paper is generally well-written.']], ['Reviewer Frem', ['2. The overall writing is good and the methodology part is well-organized and easy to follow.']]],
            [['Reviewer eS3u', ['2. The proposed method is straightforward and shown to be effective on the test data.', '1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method.']], ['Reviewer wiS9', ['3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?']], ['Reviewer Frem', ['3) Experiments on the KeypointNet dataset show the effectiveness of the proposed method.', "1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset."]]],
            [['Reviewer eS3u', ["4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design."]], ['Reviewer wiS9', ['1. The novelty of this work seems insufficient for ICLR. The whole pipeline heavily relies on VNNs and the main contribution I personally consider is the local shape transform and the self-supervised mechanism for correspondences.']]],
            [['Reviewer eS3u', ['2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.']], ['Reviewer wiS9', ['4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data].']]],
            [['Reviewer eS3u', ['The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.']], ['Reviewer wiS9', ['4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.']]],
            [['Reviewer eS3u', ['2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms seems to be novel.']], ['Reviewer wiS9', ['1. The idea of cross-reconstruction for generating inter-object correspondences in a self-supervised way is interesting.']]],
            [['Reviewer eS3u', ['4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.']]],
            [['Reviewer eS3u', ['2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.']]],
            [['Reviewer eS3u', ['4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data].']]],
            [['Reviewer eS3u', ['3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?']]],
    ]
})

request_information = pd.DataFrame({ 
    'Request Information': ['Improvement','Experiment','Explanation','Result'],
    'Frequency': [0.8, 0.6, 0.6, 0.2],
    'Comments': [
[['Reviewer Frem', ['1. The main issue of the proposed method lies in the experimental evaluation. Only one learned-based method is adopted for comparison in the main paper on a rather simple dataset. More methods including some traditional methods should be also evaluated for better comparison. The experiment on the real dataset should be also provided to show the robustness of the proposed method.', '2. From Fig. 6 in the supplementary, we can see that the performance of the proposed method on the I/I scenario is much worse than the SOTA method. More analysis of the drop of performance should be given. Moreover, the performance of different methods with different rotation angles should be provided for better comparison.']], ['Reviewer a6Ps', ['1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity?']], ['Reviewer jP4i', ["1) The main weakness of this paper could be all experiments are performed on synthetic datasets, with simple point cloud. It's good for authors' to show some examples/experiments on real-world datasets. For example, the 3Dmatch dataset.", '4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data].']], ['Reviewer wiS9', ['2.2.2 Second, the so-called local shape transform is predicted by a multi-layer perception from some SO(3)-invariant features that obtained from the input. Why after transforming the "global" features by such a mechanism, the features turn to "local"? I cannot see any specific design that enables it. It should be further explained. (I personally do not think so) 3. Regarding the experiments: 3.1 The experiments are only conducted on synthetic data, which cannot support the proposed method can work for real applications. I think it would be better to have additional real-data experiments.', '3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.', '4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.']]],
[['Reviewer a6Ps', ['2. Will the network still be functional if the density distributions are different across input and output?', '3. Will it work out of the 16-category domain? Do we need more training data, or would it work out-of-box?', 'It would be nice if the authors could conduct a minimal set of experiments in the real-world setup (e.g., extract a reconstruction from a ScanNet model and attempt to apply keypoint/semantic part transfer). Otherwise, it would be good to see a justification that this paper itself is an inevitable intermediate step toward real-world usage, and what can be done to further extend it.']], ['Reviewer jP4i', ['2) Since the proposed method can estimate dense correspondences, I wonder whether the proposed method can be used to estimate the relative rotation/translation for a point cloud pair. For example, the estimated dense correspondences can be fed to an ICP method to estimate the relative rotation/translation.']], ['Reviewer wiS9', ['3.2 As this paper also targets on correspondence estimation, whose typical downstream task is pose estimation. Therefore, I consider it worthwhile to also conduct experiments on tasks of 6D pose estimation or point cloud registration (there you always use real data), to further validate the estimated correspondences.']]],
[['Reviewer Frem', ['3. How about the performance of other methods with a rough alignment of the initial shape? If a rough alignment is enough for the existing methods, why should we learn SO(3)-invariant correspondence in an end-to-end manner?']], ['Reviewer eS3u', ['The reason why other methods are much better than LSTNet under the setting of I/I should be clarified.']], ['Reviewer wiS9', ['2.2.1 First, why are the features obtained by the Encoder global? They are generated by a DGCNN-based VNN, but DGCNN is not guaranteed to capture the global context, as it is graph-based and really depends on the number of layers together with the number of rings of each layer.', '3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?']]],
[['Reviewer a6Ps', ['4. Would non-gt and/or biased key points and semantic parts be transferred properly?']]],

    ]
})

def get_dummy_data():
    return overview, attitude_roots, request_information