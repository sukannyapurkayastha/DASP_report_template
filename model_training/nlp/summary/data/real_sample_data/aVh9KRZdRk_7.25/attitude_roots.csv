Attitude_roots,Frequency,Descriptions,Comments
Substance(EXP),1.0,Experimental study not strong enough,"[['Reviewer Jerg', ['What does the MLP do? Given the mechinterp focused on attention solely, it is unclear what role MLPs played. Two experiments to try here are: (i) train attention only models to see if MLPs are even necessary, and (ii) perform the PCA analysis to uncover representations\' geometry at the level of attentions and MLPs at each block in the model. Experiment (i) may require retraining models, so I understand if the authors are unable to conduct it, but my expectation will be that you will see that model ""internalizes"" task vectors and records them in MLPs. Attention only models can solve the task, but I expect the representations\' geometry will be quite different. For experiment (ii) however, I expect that\'s easy to run and is merely repeating the plotting script on intermediate representations as a forward pass occurs through the model. If the geometry is primarily formed at attention layers, we\'ll see that in this experiment. vice versa, if it forms via MLPs, we\'ll see it explicitly.']], ['Reviewer PjEW', ['This work has many interesting experiments. I found Section 5.2 (Attention Heads Implement Essential Skills) pretty interesting.', 'The paper claims that for larger models, early stopping is necessary (line 52). While I appreciate that the authors used GPT-like architectures to reflect realistic settings, the architectures in the experiments are not that large. Even amongst popular open source models, the smallest are usually around 7B parameters.']], ['Reviewer CrUb', [""The setting and experiments neatly isolate and clearly demonstrate several interesting phenomena of emergence of capabilities and shifting in the solutions found by deep networks throughout training, contributing to the field's developing catalogue of examples of these phenomena.""]], ['Reviewer rwBm', ['The experiments are well-designed, providing compelling support for the claims.']]]"
Substance(MET),0.75,Incomplete details on perfromance of the method,"[['Reviewer Jerg', [""PCA variance. Given this is a rather rich geometry in 2-D, I'm slightly surprised to see PCA captured it. Did you have to do some preprocessing? How much variance is explained by the two projected components? If there are other components that are not shown but have a large variance, what do those components encode---can you try 3D plots?""]], ['Reviewer PjEW', ['I am left wondering if this batch construction methodology, as a further departure from the standard language modelling setting, has any other implications for the learning process that may affect the generality of the results.', ""Note: This weakness is not decisive because the authors clearly document their training methodology and it's not that artificial anyway."", 'However, I feel that this section could be improved if the authors attempted to offer greater insight into the relationship between these prior works and the present work. For example, the authors have an opportunity here to informally describe the in-context linear regression and the modular addition problem settings that the newly proposed setting generalises.']], ['Reviewer CrUb', ['The skill decomposition discussed in section 5 is great. The clear pattern in attention heads verifies it very well. (The hypotheses could be further verified if the author can link the values of $c_1, c_2$ to some weights in the network, see the question part.)', 'Equation 2 is a bit hard to understand. How does it correlate to $z = ax+by$ ? (Although, from the latter explanations, I know the model relies on $c_1z_1^t + c_2z_2^t$ to get $z$, but it might be helpful to claim how it is derived.) - Better to define $GF(p)$, i.e., the Galois field, before using it.']]]"
Clarity(MET),0.5,Unclear description of method,"[['Reviewer Jerg', ['The definition of task diversity is not well defined. Is the number of pretraining tasks truly indicative of task diversity? I think the paper could benefit from some justification of this assumption.', 'Since multiplication can be viewed as repeated addition, isn’t skill 2 an extension of skill 3 (or can even be viewed as skill 3 composed with itself multiple times)? Is hierarchy of skills important here?']], ['Reviewer PjEW', ['4. I noticed some minor text errors as follows, which I expect the authors can easily correct. Line 94: The notation $[1, p^2]$ to me suggests a closed continuous interval, whereas you appear to mean $\\lbrace1, \\ldots, p^2\\rbrace$, also in some cases denoted $[p^2]$.', 'It seems that equation 2 should read $\\ldots = (z_1^t, z_2^2) \\mod p$ and the equation on line 203 should read $c_1x + c_2y \\mod p$. That is, $x$ and $y$ should swap places with $z_1^t$ and $z_2^t$. Is this indeed a mistake, or am I missing something?']]]"
Substance(ANA),0.5,Lack of analysis,"[['Reviewer Jerg', [""While some elements of the analysis are complex, the authors have done an exceptional job of clearly presenting their findings. I feel careful study of each section and figure in the main text was rewarded since there was no question that occurred to me that was not addressed in the authors' clear descriptions or figures."", '2. The mechanistic analysis is only partial. The authors admit that they have not been able to identify an end-to-end mechanistic model of how the trained transformers perform the task. This leaves their posited skill decomposition and partial mechanistic analysis open to the possibility that they are incomplete.']], ['Reviewer PjEW', ['The task and batch sample selection in this paper have many constraints (e.g., the rectangular rule, the balanced number of samples in each batch, etc.). However, the practical systems usually cannot strictly satisfy all these assumptions. Hence a more detailed analysis of how these assumptions influence the generalization ability would provide more insights to practical systems.']]]"
Clarity(OAL),0.5,3. The paper is not nicely written or rather easy to follow.,"[['Reviewer Jerg', ['The paper is fairly well written and clear. Going beyond the standard linear regression task to study ICL was great to see as well.']], ['Reviewer PjEW', ['The paper is easy to follow. Good presentation!']]]"
Clarity(TNF),0.5,"Incorrect presentation of tables and figures (plots, typos in tables and figs. description of plot)","[['Reviewer Jerg', ['In figure 6 (top row) there is a typo: ""Qeury"" on the vertical axis.', ""2. In the figure 1 caption, is it possible to offer a clearer summary of the difference between in-distribution generalisation and out-of-distribution memorisation? On my first read through, treating the figure and caption as an overview of the work's main results, I had trouble distinguishing these two concepts.""]], ['Reviewer PjEW', ['The results in Figure 5 are cool.', 'The paper claims in line 147 that “As the o.o.d. performance increases, the pre-training performance simultaneously degrades “. However, it is hard to read this information from Figure 3-a panel 1. Maybe a different color mapping or adding numbers on these patches would be helpful.', 'In line 264, the paper claims that the pattern depends on $(a,b)$, but it is hard to read that from Figure 6b.']]]"
Meaningful-comparison(RWK),0.5,Missing baselines,"[['Reviewer Jerg', ['Many works in the continual learning and meta learning literature suggest that training on multiple tasks at once leads to better generalization. Perhaps it is worth including brief discussion on the connections between this point and the model’s ability to generalize ood which is predominantly determined by the number of pre-training tasks.']], ['Reviewer PjEW', ['The OOD settings studied in grokking or emergent ability setting are quite related to the compositional generalization and systematic generalization. It would be helpful to discuss them in the related works, here are some of them: [1] Schott, Lukas, et al. ""Visual representation learning does not generalize strongly within the same domain."" ICLR 2022 [2] Xu, Zhenlin, Marc Niethammer, and Colin A. Raffel. ""Compositional generalization in unsupervised compositional representation learning: A study on disentanglement and emergent language."" NeurIPS 2022 [3] Ren, Yi, et al. ""Improving compositional generalization using iterated learning and simplicial embeddings."" NeurIPS 2023']]]"
Substance(TNF),0.5,"Incomprehensible tables and figures (what is the point of the plot, no decription of figure in main text, etc)","[['Reviewer Jerg', [""PCA variance. Given this is a rather rich geometry in 2-D, I'm slightly surprised to see PCA captured it. Did you have to do some preprocessing? How much variance is explained by the two projected components? If there are other components that are not shown but have a large variance, what do those components encode---can you try 3D plots?""]], ['Reviewer PjEW', ['Are the results in Figure 6 coming from $d=2$ or $d=4$? I can find the figure for all 8 attention heads for $d=2$ in the appendix, what about the $d=4$ case? It might be helpful to see if the pattern in later layers (i.e., attention focusing on different $z_i$) exists in shallow layers, and vice versa.']]]"
Substance(RES),0.5,generalizability of results is questionable,"[['Reviewer Jerg', ['I am left wondering if this batch construction methodology, as a further departure from the standard language modelling setting, has any other implications for the learning process that may affect the generality of the results.']], ['Reviewer PjEW', ['Are the results in Figure 6 coming from $d=2$ or $d=4$? I can find the figure for all 8 attention heads for $d=2$ in the appendix, what about the $d=4$ case? It might be helpful to see if the pattern in later layers (i.e., attention focusing on different $z_i$) exists in shallow layers, and vice versa.']]]"
Clarity(RES),0.25,"Improper explanation of results (as in advantages, why are results better, etc)","[['Reviewer Jerg', ['The results in Figure 5 are cool.']]]"
Meaningful-comparison(OAL),0.25,none,"[['Reviewer Jerg', ['I have not noticed any weaknesses in the paper that would temper my overall recommendation to accept. However, I note the following weaknesses, some of which the authors have already acknowledged, and others which they may like to take into consideration if they are interested to improve the paper further.']]]"
Motivation-impact(RWK),0.25,Limited novelty as compared to related work,"[['Reviewer Jerg', ['Related Work. At this point, the topic this paper is focused on has a rather rich literature and I think a more detailed related work is warranted (perhaps in the appendix if space is an issue). For example, the results by Kirsch et al. (which is cited) are very similar to what authors show, especially results on scaling effects. The main different is width scaling in that paper and no geometric analysis, but nonetheless the relationship warranted more emphasis and discussion. Similarly, several recent works have explored OOD generalization of toy ICL tasks defined in prior works (e.g., see Ahuja and Lopez-Paz [1] for work on linear regression tasks and Ramesh et al. [2] for group arithmetic tasks). Regarding grokking, there are several works exploring the phase transition-y nature of this task. For example, see Kumar et al. [3]. The transient nature of ICL also has negative results (see Reddy [4]), which are worth discussion since they are the primary conclusion in depth scaling as I see it.']]]"
Motivation-impact(RES),0.25,Limited impact of results,"[['Reviewer Jerg', [""The main selling point for me are the empirics though---I really like the results! The visualization of how the model represents concepts relevant to this paper's setup is quite beautiful: the circle of circles was fascinating to look at and, arguably, not something I expected. In retrospect, I can rationalize this as making sense---we get circular embeddings in grokking, so circle of circles is the logical geometrical extension here. Results on scaling are interesting in their own right as well.""]]]"
Motivation-impact(MET),0.25,Limited insights based on design choices,"[['Reviewer Jerg', ['Moreover, the proposed synthetic problem is both rich and elegant. I expect this framework will become a fruitful test-best for follow-up work studying emergence phenomena, helping the field to improve our empirical and theoretical understanding of these phenomena.', 'Note: I think the contribution the authors have given in terms of the setting, the generalisation phenomena, and the partial skill decomposition and mechanistic analysis are already significant.']]]"
Motivation-impact(DAT),0.25,none,"[['Reviewer Jerg', ['The paper studies the emergence of the in-context ability of the GPT-style transformer model trained using autoregressive loss and arithmetic modular datasets. It analyzes the influence of the number of tasks, number of in-context examples, model capacity, etc., on the ICL capability of an appropriately trained model (i.e., using early stopping). It also provides a persuasive “task decomposition hypothesis”, which is well supported by the ablation study and various experiments. The white-box analysis on the attention heads provides convincing evidence of the proposed explanation. Although there is a gap between the grokking settings (i.e., small model and toy dataset) and practical systems, the paper does a good job of explaining many important trends and concepts related to the emergence of compositional in-context ability. I enjoy reading this paper and suggest an acceptance.']]]"
Motivation-impact(ANA),0.25,Unfortunately the paper doesn't provide any qualitative analysis on how modulation is employed by the models after training.,"[['Reviewer Jerg', ['Note: I think the contribution the authors have given in terms of the setting, the generalisation phenomena, and the partial skill decomposition and mechanistic analysis are already significant.']]]"
Soundness-correctness(OAL),0.25,1. The presentation is somewhat convoluted.,"[['Reviewer Jerg', ['To be honest this part of the title has puzzled me since I first looked at the paper. Even if my understanding above is wrong and the title has an accurate interpretation, that I have failed to notice it might be one data point suggesting that if you are going for a title that is both short and informative, this might not be the right choice.']]]"
Soundness-correctness(MET),0.25,Correctness of algorithm proposed is questionable,"[['Reviewer Jerg', [""1. Why is the title 'learning to grok'? Is this meant in the sense that the grokking of a modular addition task is occurring in-context? If so, this seems a little inaccurate, since the phenomenon analogous to 'grokking' seems to still be occurring during pre-training.""]]]"
Substance(RWK),0.25,Limited improvement over baselines,"[['Reviewer Jerg', ['3. Relationship to prior work. The related work section does a good job of summarising the contributions of prior work in in-context linear regression and modular arithmetic in the context of transformer models.', 'However, I feel that this section could be improved if the authors attempted to offer greater insight into the relationship between these prior works and the present work. For example, the authors have an opportunity here to informally describe the in-context linear regression and the modular addition problem settings that the newly proposed setting generalises.']]]"
