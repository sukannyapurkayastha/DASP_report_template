- In Section 3.1 : “Across runs in Table 1, we observe that without Orthogonal Regularization, only 16% of models are amenable to truncation compared to 60% with Orthogonal Regularization.” For me, this is not particularly clear.
- In Appendix D, the Figures could be slightly clarified by using a colored heatmap to color the curve, with colors corresponding to the threshold values.
4) Table 1 difference between DNC and DNC (DM) is not clear. I am assuming it's the numbers reported in the paper, vs the author's implementation?
- Figures 1-4 are difficult to interpreted on a printed version.
- figures 2 & 3 should be a lot larger in order to be readable
4. Fig. 3 (right): It is not clear
On the other hand it is clear that using the confidence of the model to predict the dataset is a useful property, but the right side of the Fig. is very confusing.
2. Figure 3: it is confusing to call the cumulative distribution of the maximum classification score as the CDF of the model (y-axis fig. 3 left) as CDF means something else generally in such contexts, as the CDF of a predictor.
- Table 3 is a bit confusing as-is (lower is only better when controlling on the quality of the best sample.
- It isn't clear from the tables that OCE_0.1 outperforms REINFORCE_Z (as is mentioned in the discussion).
2. In the caption of figure 2, there should be a space after `":".
- In figure 3 (c) "number |T of input" should be  "number |T| of input"
- In figure 5 (a) "cencept" should be "concept"
- In figure 8 "Each column corresponds to ..." should be "Each row corresponds to ...".
Fig 4 is very confusing.
First, it doesn’t label the X axis.
Second, the caption mentions that early stopping is beneficial for the proposed method, but I can’t see it from the figure.
Third, I don’t get what is plotted on different subplots.
The input and output types of each block in Figure 1. should be clearly stated.
The figures are almost useless, because the captions contain very little information.
For example, the authors should at least say that the "D" in Figure 2. stands for delay, and the underline in Figure 4. indicates the bits that are not pruned.
Many more can be said in all the figures.
Furthermore, the usage of the evaluation method unclear as well, it seems to be designed for evaluating the effectiveness of different adversarial attacks in Figure 2.
-What’s the 3d plot supposed to represent?
=> The results shown in Figure-4 (Section-4.2) seems unclear to me.
* Figure 5 should appear after Figure 4.
The labels of figures are hard to read.
c. Figure 1 is over-complicated.
e. What are the two modalities in Table 2? The author should explain.
2. I don’t understand Figure 4.
I am confused by Figure 4, and in general with the relative rank metrics.
Weakness: the presentation of the tables/bar charts in the experiment is a bit unclear.
- Some of the figures your report are compelling but it is a bit unclear to the reader if the results are general (e.g., the examples could have been hand-picked). Are there any quantitative measures you could provide (in addition to Tables 1 and 2 which don't measure the quality of the approach)?
The explanation in Fig 2 on why this is the case seem to me not so clear. Are you trying to show that the Wave-U-Net does not work since there is no 1/f^2 law for clean audio signals?
Tiny detail: The axes of several of the plots given in the paper mis the lables which makes it hard to read. Straightforward to fix, but worth mentioning nevertheless.
- I am confused what is the fixed reference in Figure 6. It is not explained in the main paper.
Furthermore, I do not see legend in Figure 3 and thus I cannot figure out what the curves represent.
Typo:. The “Inf” in Tabel 1
If this is what these graphs show, consider using a different visualization to make it clearer that you're improving the final performance, not just the training process.
Also, Table 1 is really confused. I would not understand the meaning if I am not familiar with the experiment settings.
- The caption of Table 1 is a little vague. Please clearly state the meaning of the numbers in the table.
2. In Figure 3, the baseline got different perplexity between 3(a) and 3(b).
- There are two lines of text between Fig. 4 and Fig. 5, which is confusing.
- Text on experiment figures is much too small.
2. table 2: Dynamic -> Adaptive?
- The aspect ratio in Fig. 5 should be fixed.
-  Figure 2 are hard to read for different M's. It would be better if the authors can show the exact accuracy numbers rather than the overlapped lines
- Again, Figure 3, it is hard to see the benefits for increasing M from the visualizations for different clusterings.
The plot (Figure2 (d)) is very blurry and people cannot really tell local structure from it.
Some figures, like Figure 3 and 4, are hard to read.
• Not all of the arrows in Figure 1 are pointing to the right lines.
With the current table, one has to compare cells in the top half of the table to those in the bottom half of the table, which is quite difficult to do.
The plots in figure 4 are too small.
- the exposition could be improved, in particular the description of the plots is not very clear, I'm still not sure exactly what they show
The graphs were difficult to parse.
I was able to make them out, but perhaps separating the top row (FID and diversity graphs) into separate figures, separate lines, or something would have reduced some confusion.
3) I would suggest a different name other than Neural-LP-N, as it is somewhat underselling this work. Also it makes Table 2 not that easy to read.
-	Figures 1 is way too abstract given the complicated set-up of the proposed architecture.
