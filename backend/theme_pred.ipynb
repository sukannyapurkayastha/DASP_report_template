{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('sentences_author.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from torch.nn import Sigmoid\n",
    "\n",
    "# Load model and tokenizer (ensure they are already initialized)\n",
    "# checkpoint path: /home/nana/DASP_report_template/model_training/nlp/review_to_theme/results/checkpoint-1810\n",
    "# bert-base-uncased\n",
    "model = BertForSequenceClassification.from_pretrained(\"/home/nana/DASP_report_template/model_training/nlp/review_to_theme/results/final_model\", num_labels=11, problem_type=\"multi_label_classification\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/nana/DASP_report_template/model_training/nlp/review_to_theme/results/final_model\")\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def predict(input_text, threshold=0.5):\n",
    "    # Tokenize the input text using tokenizer (handles padding, truncation, etc.)\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "    # Run the model for prediction\n",
    "    with torch.no_grad():  # Disable gradient calculation during inference\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid to logits (since it's multi-label classification)\n",
    "    sigmoid = Sigmoid()\n",
    "    probabilities = sigmoid(logits)\n",
    "\n",
    "    # Apply threshold to get binary predictions (0 or 1)\n",
    "    predictions = (probabilities > threshold).int()\n",
    "\n",
    "    # Return the binary predictions (as a list)\n",
    "    return predictions.squeeze().tolist()\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Lack of limitations.\"\n",
    "predicted_labels = predict(input_text)\n",
    "\n",
    "print(\"Predicted Labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ANA', 'BIB', 'DAT', 'EXP', 'INT', 'MET', 'OAL', 'PDI', 'RES', 'RWK', 'TNF']\n",
    "# Find all indices of 1\n",
    "indices = [i for i, value in enumerate(predicted_labels) if value == 1]\n",
    "true_labels = [labels[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MET']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_theme_category(text):\n",
    "    # Load the pretrained model and tokenizer\n",
    "    model = BertForSequenceClassification.from_pretrained(\"/home/nana/DASP_report_template/model_training/nlp/review_to_theme/results/final_model\", num_labels=11, problem_type=\"multi_label_classification\")\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"/home/nana/DASP_report_template/model_training/nlp/review_to_theme/results/final_model\")\n",
    "    model.eval()\n",
    "    threshold = 0.5\n",
    "    # Tokenize the input text using tokenizer (handles padding, truncation, etc.)\n",
    "    inputs = tokenizer(text, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "    # Run the model for prediction\n",
    "    with torch.no_grad():  # Disable gradient calculation during inference\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Apply sigmoid to logits (since it's multi-label classification)\n",
    "    sigmoid = Sigmoid()\n",
    "    probabilities = sigmoid(logits)\n",
    "\n",
    "    # Apply threshold to get binary predictions (0 or 1)\n",
    "    predictions = (probabilities > threshold).int()\n",
    "    predictions = predictions.squeeze().tolist()\n",
    "\n",
    "    labels = ['ANA', 'BIB', 'DAT', 'EXP', 'INT', 'MET', 'OAL', 'PDI', 'RES', 'RWK', 'TNF']\n",
    "    # Find all indices of 1\n",
    "    indices = [i for i, value in enumerate(predictions) if value == 1]\n",
    "    true_labels = [labels[i] for i in indices]\n",
    "\n",
    "    # Return the binary predictions (as a list)\n",
    "    return true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attitude_themes'] = df['sentence'].apply(predict_theme_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>sentence</th>\n",
       "      <th>attitude_themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>This work proposes LSTNet, a self-supervised m...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>Specifically, LSTNet learns to formulate SO(3)...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>The proposed self-supervised training pipeline...</td>\n",
       "      <td>[EXP, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>The self- and cross-reconstruction training st...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>LSTNet demonstrates state-of-the-art performan...</td>\n",
       "      <td>[DAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>The performance of aligned shape pairs under t...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>The reason why other methods are much better t...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>Lack of limitations.</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>1) This paper proposes a self-supervised metho...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>2）The main idea is to decouple a point cloud f...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>3) Experiments on the KeypointNet dataset show...</td>\n",
       "      <td>[DAT, EXP, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>1) This paper is generally well-written.</td>\n",
       "      <td>[OAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>2) The idea of factorizing point cloud descrip...</td>\n",
       "      <td>[MET, PDI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>3) Experimental results are good.</td>\n",
       "      <td>[EXP, RES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>1) The main weakness of this paper could be al...</td>\n",
       "      <td>[DAT, EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>2) Since the proposed method can estimate dens...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>3) The running time and GPU memory cost is blu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>4) Please compare the proposed method with mor...</td>\n",
       "      <td>[MET, RWK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>Please refer to the weaknesses.</td>\n",
       "      <td>[OAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>This paper introduces LSTNet, which leverages ...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>1. The idea of cross-reconstruction for genera...</td>\n",
       "      <td>[PDI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>2. The overall writing is good and the methodo...</td>\n",
       "      <td>[OAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>1. The novelty of this work seems insufficient...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>2. Regarding the local shape transform: 2.1. F...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>2.2 The authors claimed that the local shape t...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>2.2.1 First, why are the features obtained by ...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>2.2.2 Second, the so-called local shape transf...</td>\n",
       "      <td>[EXP, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>3.2 As this paper also targets on corresponden...</td>\n",
       "      <td>[EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>3.3 In Tab.1, only CPAE proposed in 2021 is us...</td>\n",
       "      <td>[EXP, MET, RWK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>3.4 The method is claimed to generate SO(3)-in...</td>\n",
       "      <td>[EXP, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>4. For the SO(3)-equivariant and -invariant me...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>[1]. Zohaib et al. SC3K: Self-supervised and C...</td>\n",
       "      <td>[RWK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>[2]. Dent et al. PPF-FoldNet: Unsupervised Lea...</td>\n",
       "      <td>[RWK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>See weaknesses.</td>\n",
       "      <td>[OAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>This paper attempts to register point cloud pr...</td>\n",
       "      <td>[EXP, RES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>Valid motivation. Unlike the abused topic, van...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>The SO(3)-invariant network design intrinsical...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>The joint usage of a global descriptor and a l...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>The self-supervision scheme looks plausible by...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>My major concern is with the experimental setu...</td>\n",
       "      <td>[EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>In motivation, the authors talk about usage in...</td>\n",
       "      <td>[EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>The authors also take groundtruth keypoints an...</td>\n",
       "      <td>[DAT, EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>Following my points in the \"weaknesses\" sectio...</td>\n",
       "      <td>[PDI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>1. Would SO(3) invariance be sufficient? Do we...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>2. Will the network still be functional if the...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>3. Will it work out of the 16-category domain?...</td>\n",
       "      <td>[DAT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>4. Would non-gt and/or biased key points and s...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>It would be nice if the authors could conduct ...</td>\n",
       "      <td>[EXP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>This paper presents a method of learning dense...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>1. The paper is in general well organized and ...</td>\n",
       "      <td>[OAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>2. The proposed method is straightforward and ...</td>\n",
       "      <td>[DAT, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>1. The main issue of the proposed method lies ...</td>\n",
       "      <td>[DAT, EXP, MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>2. From Fig. 6 in the supplementary, we can se...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>3. How about the performance of other methods ...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>4. The whole method is mainly built upon the e...</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>Please refer to the Weaknees part.</td>\n",
       "      <td>[MET]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                           sentence  \\\n",
       "0   Reviewer eS3u  This work proposes LSTNet, a self-supervised m...   \n",
       "1   Reviewer eS3u  Specifically, LSTNet learns to formulate SO(3)...   \n",
       "2   Reviewer eS3u  The proposed self-supervised training pipeline...   \n",
       "3   Reviewer eS3u  The self- and cross-reconstruction training st...   \n",
       "4   Reviewer eS3u  LSTNet demonstrates state-of-the-art performan...   \n",
       "5   Reviewer eS3u  The performance of aligned shape pairs under t...   \n",
       "6   Reviewer eS3u  The reason why other methods are much better t...   \n",
       "7   Reviewer eS3u                               Lack of limitations.   \n",
       "8   Reviewer jP4i  1) This paper proposes a self-supervised metho...   \n",
       "9   Reviewer jP4i  2）The main idea is to decouple a point cloud f...   \n",
       "10  Reviewer jP4i  3) Experiments on the KeypointNet dataset show...   \n",
       "11  Reviewer jP4i           1) This paper is generally well-written.   \n",
       "12  Reviewer jP4i  2) The idea of factorizing point cloud descrip...   \n",
       "13  Reviewer jP4i                  3) Experimental results are good.   \n",
       "14  Reviewer jP4i  1) The main weakness of this paper could be al...   \n",
       "15  Reviewer jP4i  2) Since the proposed method can estimate dens...   \n",
       "16  Reviewer jP4i  3) The running time and GPU memory cost is blu...   \n",
       "17  Reviewer jP4i  4) Please compare the proposed method with mor...   \n",
       "18  Reviewer jP4i                    Please refer to the weaknesses.   \n",
       "19  Reviewer wiS9  This paper introduces LSTNet, which leverages ...   \n",
       "20  Reviewer wiS9  1. The idea of cross-reconstruction for genera...   \n",
       "21  Reviewer wiS9  2. The overall writing is good and the methodo...   \n",
       "22  Reviewer wiS9  1. The novelty of this work seems insufficient...   \n",
       "23  Reviewer wiS9  2. Regarding the local shape transform: 2.1. F...   \n",
       "24  Reviewer wiS9  2.2 The authors claimed that the local shape t...   \n",
       "25  Reviewer wiS9  2.2.1 First, why are the features obtained by ...   \n",
       "26  Reviewer wiS9  2.2.2 Second, the so-called local shape transf...   \n",
       "27  Reviewer wiS9  3.2 As this paper also targets on corresponden...   \n",
       "28  Reviewer wiS9  3.3 In Tab.1, only CPAE proposed in 2021 is us...   \n",
       "29  Reviewer wiS9  3.4 The method is claimed to generate SO(3)-in...   \n",
       "30  Reviewer wiS9  4. For the SO(3)-equivariant and -invariant me...   \n",
       "31  Reviewer wiS9  [1]. Zohaib et al. SC3K: Self-supervised and C...   \n",
       "32  Reviewer wiS9  [2]. Dent et al. PPF-FoldNet: Unsupervised Lea...   \n",
       "33  Reviewer wiS9                                    See weaknesses.   \n",
       "34  Reviewer a6Ps  This paper attempts to register point cloud pr...   \n",
       "35  Reviewer a6Ps  Valid motivation. Unlike the abused topic, van...   \n",
       "36  Reviewer a6Ps  The SO(3)-invariant network design intrinsical...   \n",
       "37  Reviewer a6Ps  The joint usage of a global descriptor and a l...   \n",
       "38  Reviewer a6Ps  The self-supervision scheme looks plausible by...   \n",
       "39  Reviewer a6Ps  My major concern is with the experimental setu...   \n",
       "40  Reviewer a6Ps  In motivation, the authors talk about usage in...   \n",
       "41  Reviewer a6Ps  The authors also take groundtruth keypoints an...   \n",
       "42  Reviewer a6Ps  Following my points in the \"weaknesses\" sectio...   \n",
       "43  Reviewer a6Ps  1. Would SO(3) invariance be sufficient? Do we...   \n",
       "44  Reviewer a6Ps  2. Will the network still be functional if the...   \n",
       "45  Reviewer a6Ps  3. Will it work out of the 16-category domain?...   \n",
       "46  Reviewer a6Ps  4. Would non-gt and/or biased key points and s...   \n",
       "47  Reviewer a6Ps  It would be nice if the authors could conduct ...   \n",
       "48  Reviewer Frem  This paper presents a method of learning dense...   \n",
       "49  Reviewer Frem  1. The paper is in general well organized and ...   \n",
       "50  Reviewer Frem  2. The proposed method is straightforward and ...   \n",
       "51  Reviewer Frem  1. The main issue of the proposed method lies ...   \n",
       "52  Reviewer Frem  2. From Fig. 6 in the supplementary, we can se...   \n",
       "53  Reviewer Frem  3. How about the performance of other methods ...   \n",
       "54  Reviewer Frem  4. The whole method is mainly built upon the e...   \n",
       "55  Reviewer Frem                 Please refer to the Weaknees part.   \n",
       "\n",
       "    attitude_themes  \n",
       "0             [MET]  \n",
       "1             [MET]  \n",
       "2        [EXP, MET]  \n",
       "3             [MET]  \n",
       "4             [DAT]  \n",
       "5             [MET]  \n",
       "6             [MET]  \n",
       "7             [MET]  \n",
       "8             [MET]  \n",
       "9             [MET]  \n",
       "10  [DAT, EXP, MET]  \n",
       "11            [OAL]  \n",
       "12       [MET, PDI]  \n",
       "13       [EXP, RES]  \n",
       "14       [DAT, EXP]  \n",
       "15            [MET]  \n",
       "16               []  \n",
       "17       [MET, RWK]  \n",
       "18            [OAL]  \n",
       "19            [MET]  \n",
       "20            [PDI]  \n",
       "21            [OAL]  \n",
       "22            [MET]  \n",
       "23            [MET]  \n",
       "24            [MET]  \n",
       "25            [MET]  \n",
       "26       [EXP, MET]  \n",
       "27            [EXP]  \n",
       "28  [EXP, MET, RWK]  \n",
       "29       [EXP, MET]  \n",
       "30            [MET]  \n",
       "31            [RWK]  \n",
       "32            [RWK]  \n",
       "33            [OAL]  \n",
       "34       [EXP, RES]  \n",
       "35            [MET]  \n",
       "36            [MET]  \n",
       "37            [MET]  \n",
       "38            [MET]  \n",
       "39            [EXP]  \n",
       "40            [EXP]  \n",
       "41       [DAT, EXP]  \n",
       "42            [PDI]  \n",
       "43            [MET]  \n",
       "44            [MET]  \n",
       "45            [DAT]  \n",
       "46            [MET]  \n",
       "47            [EXP]  \n",
       "48            [MET]  \n",
       "49            [OAL]  \n",
       "50       [DAT, MET]  \n",
       "51  [DAT, EXP, MET]  \n",
       "52            [MET]  \n",
       "53            [MET]  \n",
       "54            [MET]  \n",
       "55            [MET]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(row):\n",
    "    # Extract root and themes\n",
    "    root = row[\"attitude_root\"]\n",
    "    themes = row[\"attitude_theme\"]\n",
    "    \n",
    "    # Combine root with each theme\n",
    "    clusters = [f\"{root}({theme})\" for theme in themes]\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attitude_root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attitude_root'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the function to create clusters\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_cluster \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m----> 3\u001b[0m df_cluster[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Explode clusters to create one row per cluster\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_cluster \u001b[38;5;241m=\u001b[39m df_cluster\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mcreate_clusters\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_clusters\u001b[39m(row):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Extract root and themes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattitude_root\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     themes \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattitude_theme\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Combine root with each theme\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'attitude_root'"
     ]
    }
   ],
   "source": [
    "# Apply the function to create clusters\n",
    "df_cluster = df\n",
    "df_cluster[\"clusters\"] = df_cluster.apply(create_clusters, axis=1)\n",
    "# Explode clusters to create one row per cluster\n",
    "df_cluster = df_cluster.explode(\"clusters\", ignore_index=True)\n",
    "print(df_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jitsupeer_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
