{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\carme\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   data         labels\n",
      "0     With regard to my first negative point above a...      arg_other\n",
      "1     The cited paper 'Learning an adaptive learning...      arg_other\n",
      "2         The above papers are not cited in this paper.      arg_other\n",
      "3     Missing references - authors may want to consi...      arg_other\n",
      "4     Some of the experiments (eg. comparisons invol...      arg_other\n",
      "...                                                 ...            ...\n",
      "1806  - From Figure 9, we see the certificate radii ...  asp_substance\n",
      "1807  1. (Also AREA CHAIR NOTE): Another parallel su...  asp_substance\n",
      "1808  2. Even though Figure 2b shows that SVHN test ...  asp_substance\n",
      "1809  I don’t see a significant difference between R...  asp_substance\n",
      "1810  It is not clear how the compression ratio in t...  asp_substance\n",
      "\n",
      "[1811 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Pfad zum Verzeichnis, das die Attitude Roots enthält\n",
    "root_dir = r'../../../data/attitude_roots/' \n",
    "\n",
    "# Liste für die Ergebnisse\n",
    "data = []\n",
    "\n",
    "# Durchlaufe alle Unterverzeichnisse im Root-Verzeichnis\n",
    "for attitude_root in os.listdir(root_dir):\n",
    "    attitude_path = os.path.join(root_dir, attitude_root)\n",
    "    # Prüfe, ob es sich um ein Verzeichnis handelt\n",
    "    if os.path.isdir(attitude_path):\n",
    "        review_path = os.path.join(attitude_path, 'review')\n",
    "        # Prüfe, ob der 'review'-Ordner existiert\n",
    "        if os.path.exists(review_path):\n",
    "            # Durchlaufe alle Dateien im 'review'-Ordner\n",
    "            for filename in os.listdir(review_path):\n",
    "                file_path = os.path.join(review_path, filename)\n",
    "                # Nur Dateien berücksichtigen\n",
    "                if os.path.isfile(file_path):\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                        # Sätze durch Zeilenumbrüche getrennt\n",
    "                        sentences = content.strip().split('\\n')\n",
    "                        for sentence in sentences:\n",
    "                            # Überspringe leere Zeilen\n",
    "                            if sentence.strip():\n",
    "                                data.append({\n",
    "                                    'data': sentence.strip(),\n",
    "                                    'labels': attitude_root\n",
    "                                })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['arg_other', 'asp_clarity', 'asp_meaningful-comparison',\n",
       "       'asp_motivation-impact', 'asp_originality', 'asp_replicability',\n",
       "       'asp_substance'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"labels\"].unique()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verteilung der Labels:\n",
      "labels\n",
      "asp_substance                739\n",
      "asp_clarity                  440\n",
      "asp_replicability            191\n",
      "asp_originality              171\n",
      "asp_meaningful-comparison    154\n",
      "asp_motivation-impact         69\n",
      "arg_other                     47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Encode label for easy identification.\n",
    "df[\"encoded_cat\"] = df[\"labels\"].astype(\"category\").cat.codes\n",
    "#print(df)\n",
    "\n",
    "\n",
    "# Häufigkeit der Labels zählen\n",
    "label_counts = df['labels'].value_counts()\n",
    "\n",
    "print(\"Verteilung der Labels:\")\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_texts = df[\"data\"].to_list() # Features (not tokenized yet)\n",
    "data_labels = df[\"encoded_cat\"].to_list() # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split (train 79%, val 20%, test 1%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Split Train and Validation data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size=0.2, random_state=0, shuffle=True)\n",
    " \n",
    "# Keep some data for inference (testing)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=0.01, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912755383765875\n",
      "363\n",
      "0.008282716731087797\n",
      "['- Baseline missing: Random actions from expert', 'This is not so interesting, even though results are impressive.', '- Lack of a strong explanation for the results or a solution to the problem', 'Although a detailed discussion is provided related to the memory consumption between the proposed method and PipeDream, no detailed discussion is provided with respect to GPipe.', '- Please comment on the extra computation required for obtaining image data for MT sentences and for learning image representations.', 'This needs to be changed: a) you should run all the baselines for each of the current tasks b) you should also expand the experiments evaluated to include tasks where it is not obvious that a hierarchy would help/is necessary c) you should include more baselines.', 'Why, for example, did the authors only perform variational inference with the current and previous frames? Did conditioning on additional frames offer limited further improvement? Can the blurriness instead be attributable to the weak inference model?', '- The final method is a mixup of many different techniques, thus, not a strong contribution, but many smaller contributions.', '* There was some analysis of the augmented IMDB dataset, but none of the SNLI dataset.', '2. In Figure 3, the baseline got different perplexity between 3(a) and 3(b).', \"Language modeling is a fast-moving field, so the very latest and greatest techniques are not strictly necessary for this paper, but at least midsize LSTM models that get scores in the ~80 ppl range for Penn Treebank are important, otherwise it becomes very questionable whether the results will provide any practical impact in today's best models.\", 'If so, what was the methodology.', '(2) When viewed in this way, CW-distance introduced in Eq (2) closely resembles the unbiased U-statistic estimate of the MMD used in WAE-MMD [1, Algorithm 2].', 'The paper is not very self contained.', 'The paper used very restricted Gaussian distributions for the formulation.', 'I feel like in the paragraph in questions, a lot of causes and effects are mixed up and more careful descriptions of the benefits of the algorithm would help.', 'Because of this concern, I believe the results in the paper can only really characterize the learning close to convergence, since the network is already able to provide correct classification.', '- Your F and \\\\tilde{f} are introduced as infinite series.', 'I did not completely follow the arguments towards directed graph deconvolution operators.', 'Also, it is not clear from the discussion on z, whether sampling is performed once for each video of for each frame.', 'Moreover, the way classical models are casted under the InfoNCE principle is badly written: it assumes that readers have a very good knowledge of the models, and the paper does not show well the mapping between the loss function of each model and the InfoNCE criterion.', \"Why mention it here, if it's not being defined.\", 'For the modeling contribution, although it shows some improvements on the benchmarks and some nice analysis, the paper really doesn’t explain well the intuition of this “write” operation/Scratchpad (also the improvement of Scratchpad vs coverage is relatively limited). Is this something tailored to question generation? Why does it expect to improve on the question generation or it can improve any tasks which build on top of seq2seq+att framework (e.g., machine translation, summarization -- if some results can be shown on the most competitive benchmarks, that would be much more convincing)?', 'My major concern is whether the results are significant enough to deserve acceptance.', '- Page 14, Eqs(13, 14), w(\\\\mathbb{P}, \\\\mathbb{G}) should appear on the right.', 'The novelty of the algorithm itself is limited, since GAN and adversarial training are both minmax problems, and the original algorithm can be carried over easily.', 'To continue with the experimental evaluation, I found the plots with the predictive uncertainty in Figure 3 a bit confusing.', 'As a result, constraining the model will alter the mutual information and I think the effect of this should be remarked on.', 'It is well-written from a syntactical and grammatical point of view, but some key concepts are stated without being explained, which gives the impression that the authors have a clear understanding of the material presented in the paper but communicate only part of the full picture to the reader.', 'Though Kaleidoscope include these as special cases, it is not clear whether when given the same resources (either memory or computational cost), Kaleidoscope would outperform them.', '* p.4 first paragraph you claim that this method responds well to data which exhibits seasonality, but none of your datasets deal with data that would exhibit seasonality.', '* In the introduction, \"the classical approach\" is mentioned but to be the latter is', 'Along this direction, it is problematic that, in the synthetic examples, the relative  performance of methods changes significantly from experiment to experiment and there does not seem to be a simple way to control that.', 'I find the background on ELBO and GANs unnecessary occluding the clarity at this point.', 'What is G_t in Theorem 2.5. It should be defined in the theorem itself.', '- I believe one should not compare the distance shown between the left and right columns of Figure 3 as they are obtained from two different models.', '- For the squeezenet and latent permutation experiments, would be nice if there is a comparison to other parameterizations of permutation matrices, e.g. gumbel-sinkhorn.', \"It's then hard for me to square that with the +VR gains seen throughout this work on non-grounded datasets.\", 'Please comment on the choice, and its impact on the behavior of the model.', '-- The algorithm proposed in the paper is very straightforward and just removes heavy hitters using oracle advice and then hashes everything else using the standard CountMin sketch.', 'Even with the hybrid method, the accuracy still drops.', 'However, the real-world experiments are not necessarily the easiest to read.', 'However, the selected experiments on the cubic regression toy data (Section 5.1) and the out-of-distribution classification (Section 5.2) are clear examples of system’s noise, i.e. epistemic uncertainty.', 'There were some experimental details that were poorly explained but in general the paper was readable.', 'Instead only depth is provided.', '3. Can the authors show if the decomposition is also useful for trigger patterns that are not necessarily regular shapes?', 'For example, if rules contain quantifiers, how would this be extended?', 'From this perspective, the paper seems like an application of existing tools (such as CNN, graph convolutional network and binary classification).', 'The reviewer recommends the authors to read some literature review of the topic of GCN and re-organize the references, and use search engines to have a better view on the state of the art of (hyperbolic) geometric theories and graph convolutional networks.', 'The basic idea is very interesting, but I would have expect more interesting use cases as teased by the first sentence of the abstract \"find algorithms with strong worst-case guarantees for online combinatorial optimization problems\".', 'More experiments based on different transformations that the authors have mentioned would make this a stronger contribution.', 'The paper would gain in clarity', '- The centralized nature is also semantically improbable, as the observations might be high-dimensional in nature, so exchanging these between agents becomes impractical with complex problems.', '- what prior distributions p(z) and p(u) are used? What is the choice based on?', 'For example, [1] could be used to reduce the variance of gradient w.r.t. \\\\phi.', 'It leaves it unclear to the reader when someone should choose to utilize a spherical method or when the proposed method would then be preferred compared to other spherical methods.', 'It should be pointed out that the D in the hinge loss represents a neural network output without range restriction, while the D in the non-saturating loss represents sigmoid output, limiting to take in [0,1].', '- Experimental results provided in the paper are only qualitative -- as such, I do not find the comparisons (and improvements) over the existing approaches convincing enough.', 'It would be better if the authors were a little more careful in their use of terminology here.', 'Overall, the paper is a little confusing.', 'Overall, I quite liked the paper and think it is well-written, but I believe the authors need to highlight at least one practical advance introduced by the CW distance (in which case I will raise my score).', '-  The authors should compare to at least some popular previous approaches that use a feature engineering based methodology such as - IntPred', 'I highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks.', 'Comparisons against these more standard inference algorithms is essential for understanding what advantages are afforded by the objective proposed in the paper.', 'The main issue of this paper is the fair comparisons with other works.', 'I found the method section a bit difficult to read though, and even after several readings I cannot get my head around it. Specifically, here are some issues that I hope the Authors could clarify.', '- The WGAN-GP baseline is very weak, i.e. does not show any reasonable generated images (Fig. 9).', 'I found the paper confusing at times.', 'Specifically, which features are perturbed, what are the values assigned as the trigger, and what is the corresponding target label?', 'The second weakness is experimental design.', '- I am confused what is the fixed reference in Figure 6. It is not explained in the main paper.', 'As noted in the paper, this is a general element of SO(3) (and hence not in the set of alt-az rotations)', 'Also, please place the related work earlier on in the paper.', '- page 4, Sect. 4.4: Architecture of $\\\\alpha$ would be nice (more than a linear layer?)', 'The clarity of this paper needs to be strengthened.', 'That said, I would like to see more analysis on the behavior of the proposed method under various interesting cases not tested yet.', 'This is all further confused by the semantic topics used for clustering the images which ignores stop words and therefore spatial relations or any grammatical nuances.', '- I believe that in particular section 2 goes into too many mathematical details and subtleties that do not really add a lot.', 'Finally, the experimental part is also too weak to evaluate the proposed method.', 'Overall, this appears to be a board-line paper with weak novelty.', 'The MTurk experiment gives a qualitative picture, but it could be improved with comparisons to pairwise distances learned through alternative means using the RGB image itself (given that images would permit such a comparison).', '- Also, for MISC-r experiments, the weights between the intrinsic reward bonus and the extrinsic reward are not specified in the paper.', \"- The discussion/explanation of the differing performance of tying or not tying each part of the embedding weights for the different datasets is confusing; I think it could benefit from tightening up the wording but mostly I just had to read it a couple times. Perhaps all that's complicated is the distinction between embedding and projection weights; it would definitely be helpful to be as explicit about that as possible upfront.\", 'Yet their approach is only able to solve the fractional version of the AdWords problem.', 'Current representation is difficult to read / parse.', 'See http://www.stat.cmu.edu/~ryantibs/convexopt-S15/scribes/08-prox-grad-scribed.pdf for a reference.', 'Perhaps a cleaner definition would just be “A is full rank and there does not exist any X such that Ax < 0?', 'However, I am wondering whether this paper is perfectly suited to ICLR conference due to the lack of experiment, practical implication given by the theory, or theory in the non-convex setting (I know that the latter is a huge open question and I am not criticizing the absence of theory in the non-convex-concave setting).', 'In my opinion, due to how many researchers are and have been looking into improvements of language modeling, the authors may find it hard to break new ground in this direction.', 'Questions: I would like to see more discussion about difference between this work and [Z Hu, arXiv:1905.13728].', '10. Another related paper seems to be Spatial Transformer Networks (Jaderberg et al.).', 'Generally speaking it seems like a lot of technicalities for a relatively simple result:', 'This is a very good point, however the paper do not compare or contrast with existing methods.', '1. Even though K-matrices are aimed at structured matrices, it would be curious either to empirically compare K-matrices to linear transformations in fully-connected networks (i.e. dense matrices) or to provide some theoretical analysis.', 'What probability term does it correspond to? It is supposed to make probabilities of different cardinalities comparable, but the exact mechanism is unclear.', '* Some turns of phrase like \"recently gained a flourishing interest\", \"there is still a wide gap in quality of results\", \"which implies a variety of underlying factors\", ... are vague / do not make much sense and should probably be reformulated to enhance readability.', 'Though, I still think the contribution is incremental, since back-propagating gradients through values and dynamics has been studied in prior works (albeit with less empirical successes compared to Dreamer).', 'Moreover, authors should conduct experiments on state-of-the-art benchmarks, including natural images.', 'You mention that negative mining should improve over this strategy. What does negative mining correspond to in this context? Are there bad rewrites better than others?', 'However, my criticisms remain that the paper is a simple combination of cycle GAN and prototypical networks, and lacks new insights/novelty.', 'But the paper only provides empirical results on sentimental analysis and digit recognition.', '- impact: the results achieved in the experiments are very small improvements compared to the baseline of RGCN (~ +0.01 in two experiments and ~ -0.04 in another) and often these small variations in results can be compensated with better baselines training (e.g. better hyper-params, ...)', 'Unfortunately, it is riddled with grammatical errors and should be proof-read carefully. A lot of singular/plurals are off, and some formulations are odd or downright unclear.', 'Although the idea is interesting, I would like to see more experimental results showing the scalability of the proposed method and for evaluating defense strategies against different types of adversarial attacks.', 'RNN-based approaches are with better “complexity” comparing to your sum baseline and “Deepset” approach.', 'However, I think since this is few-shot learning with domain adaptation, there is no domain adaptation baselines being mentioned in comparison.', 'Overall, I think this paper is below the borderline of acceptance due to insufficient comparison with Sparsely-Gated MoE.', 'There is no value in being very confident if you are wrong and vice-versa, so unless there is an accompanying plot/table reporting the accuracy I see not much value from this plot alone.', 'Overall: this paper makes a convincing case that it can be used to generate higher quality images, but not that this improves the quality of the disentangled representations.', 'It would be interesting to see if the proposed method is competitive for training contemporary networks and w.r.t. simple schedule schemes.', 'While I wish there were more such studies -- as I believe reproducing past results experimentally is important, and so is providing practical advice for practitioners -- this work in many parts hard to follow, and it is hard to get lot of new insight from the results, or a better understanding of GANs.', 'The authors seems interchangeably using “runs” and “iterations”, which makes the concept more confusable.', 'Can the proposed approach perform just as well without a modified objective?', 'In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup.', '* The text is quite hard to read.', '- Experiments were conducted only using a few recent results as baselines (ICM, forward dynamics, RND).', 'How this proxy incentives the agent to explore poorly-understood regions?', '9.2.\\tIn formula (1.5) “<=>” seems to be used at different levels (?) it would be good to use brackets to make clear which level “<=>” refers to.', '- While the current experiments are a good start, I do not think they are extensive enough to count as strong evidence for the  power-law form of \\\\(\\\\epsilon(m,n)\\\\).', 'It would be interesting to know the evaluation times for the BA-net and more importantly to have some implementation details to ensure reproducibility.', '- Page 14, Eq(14), \\\\lambda should be s', '- for the experiment with Imagenet images, it is not very clear how many pictures are used. Is this number 2500?', '6. Similar as above question, on the object counting task, is there a way to compare with previous counting methods?', '2. The human score of 91.4% is based on majority vote, which should be compared with an ensemble of deep learning prediction.', 'For example, the two regimes mentioned in the paper has been identified by a few other works and the contribution of this paper is just to verify them again.', 'The submission could maybe improved by segmenting the work into intro / related / background (with clear equations presenting the existing GP) / analysis / approach / experiments', 'The KL divergence regularization introduces extra randomness to the auxiliary labels and thus mitigates the problem, but it hardly provides any useful information except randomness.', 'The structure is obtained by the shared and sparse rows of matrix A. I would like the authors to comment on how the studies will be affected by this property of the common networks.', 'Otherwise, it is impossible for a reader to correctly and objectively relate your proposed approach to previous literature.', 'Additionally, I believe the experimental tasks are new, and as a result all implementations of competing techniques are by the paper authors. This makes it difficult to have confidence in the higher reported performance of the proposed techniques.', '2.\\tThe experimental data set is too small, with only 635 problems.', 'The problem with this strategy is that the rigid composition only works for actions that can be split into consecutive temporal parts with prefixed duration and anchor points in time, which is clearly challenged by many works later when more complicated video events are studied.', 'First, this paper is not easy to follow.', '- Still it is unclear where \\'fj\\' comes from. You need to state in words eg \"C[b] contains the accumulation of all fj\\'s such that h(j)=b; i.e. for each sequence j \\\\in U, if the hash function h maps the sequence to bin b (ie $h(j)=b$), then we include the *corresponding frequency* in the sum.\"', 'Minor:  Since the action is denoted by \"a\",  it will be more clear if the authors use another symbol to denote the parameter of q(z) instead of \"\\\\alpha\" at Eq 10 and 15.', 'Section 3 too much redundancy -- it just explains that SVHN has a higher likelihood when trained on CIFAR, and a few variations of the same experiment.', 'Furthermore, I found the description ambiguous, preventing me from understanding how exactly the permutation head output is used in Eq 5.', 'In addition, I would like to see some discussions whether this technique could be applied to off-policy learning as well.', 'ii) In table 2, I don’t really see any promising results compared to baselines. There are', 'Hence, I am not very sure whether the novelty of the paper is significant.', 'Information similar (although not identical) to that summarized in table 5 could be captured by substituting the 3 metrics with the best performance after tuning for 4, 16 and 64 iterations respectively (just as examples).', 'positive - it unlikely to be true that an undefended network is predominantly', 'Here, the straightforward regression term means directly regress the output mask to the target densepose mask. Will the proposed mask term perform better?', 'Issues of convergence seem like they deserve some discussion here and potentially could be examined empirically (is CEM-TD3 converging in the swimmer?).', 'Hence it is unclear how large the running time improvement is compared to a well-tuned baseline.', 'The MNIST+SVHN dataset setup is described in detail, yet there is no summary of the experimental results, which are presented in the appendix.', 'This may also help to understand some of the limitations of this analysis.', 'What is the minimum/maximum size of the data set? Do we really need a large data set or just a subset that covers the data distribution?', '4) In the experiments, more comparisons with methods in [1] or [2] should be conducted given they are all parallelizing the backpropagation algorithm and achieve speedup in the training.', '2) Related work, although extensive in terms of the number of references, do not help to place this work in the literature.', '3- Is the key that you used only 679 patches containing 98% of occurrences in the dataset as the first stage? What if we vary this percentage? How sensitive are the results? Such experiments could be useful to understand better why your method appears to work well.', 'I believe that a more challenging experiment should be conducted e.g. using celebA dataset.', 'Furthermore, I had some trouble understanding how a SAT instance is solved using algorithm 1.', '1.\\tLack of technical novelty.', '- at the start of section 3: what is an \"experiment\"?', 'Since this is for ILCR, I think the authors should have taken a deeper dive into examining those latent representations and potentially visualizing those distances and how they correspond to different policy behaviors.', 'In terms of actual technical contributions, I believe much less significant.', 'Overall, while I find the proposed approach simple -- the paper needs to address some issues regarding the claims made and should provide more quantitative experimental results justifying the same.', 'There should be a better discussion of related work on the topic.', 'Second, the authors claim they are using/motivated by Choquet integral, but do not have any (appendix) sections to explain how this mathematical tool is really integrated into their models.', 'A weighted k-means solver is also used in [2], though the \"weighted\" in [2] comes from second-order information instead of minimizing reconstruction error.', 'As proposed in the comments, this should be assessed in the paper by replacing BERT representations by non-contextual representations such as GloVE.', '- Given the current form of the paper, the abstract and introduction should be modified to reflect the fact that only limited architectures and optimizers were experimented with, and the claims of the paper are not experimentally validated in general.', '- The paper mentions the MSVV algorithm twice but no reference or explanation is provided.', 'What are the differences to your approach?', 'Why do the authors directly average different loss for the discriminator and the classifer?', 'Furthermore, there are no experimental results demonstrating the effect of the permutation head and the design choices above — if we could get by with only using the Hungarian algorithm, why bother classifying an exponential number of permutations? Do they help when added as an auxiliary loss?', '- In the case of the search space II, how many GPU days does the proposed method require?', 'Fourth, please make it clear that the proposed method aims to estimate \"causality-in-mean\" because of the formulation in terms of regression.', 'The paper is overall well written and intuitive but limited in evaluation and novelty (see e.g. [1,2] ) with only limited modifications (sharing low-level controller) for the multi agent case.', '-  Why have you chosen the 4 operations at the bottom of page 4? It appears to be a subset of those used in DARTS.', 'Therefore, it may be a good idea for the authors to analyze the correlation between FSM changes and accuracy changes.', 'Then, the important hyperparameter of the method---threshold---seems to be hard to select (both in sections 4.1 and 4.2).', 'For example, it is not clear the strong emphasis on the robust MDP formalization and the fact that MCTS finds a Nash equilibrium.', 'I do not understand how the model is trained to solve multiple tasks.', \"For example, what is the number_iterations in the experiments? How are they chosen or what's the specific stopping criteria?\", 'It would probably help to position the VAE component more precisely w.r.t. one of the two baselines, by indicating the differences.', \"Unfortunately the paper doesn't provide any qualitative analysis on how modulation is employed by the models after training.\", 'Additionally, it is unclear how you will have vanishing rewards given the structure of the learned controller.', 'The results on real datasets are similar to the regular GCN.', 'What is the L1 loss defined in Section 4.4? To obtain the final separated audio waveform, an inverse STFT is applied on what?', 'Clarity: The clarity is below average.', '3) In its current form, the experimental results are extremely cherry-picked, with a very small number of tasks evaluated, and for each task a single selected baseline used.', '1. For the evaluation of DBA, I assume that there are 4 adversarial parties, controlling each of the 4 local triggers. When using centralized attacks, are there still 4 adversarial parties, although they share the same global trigger, or if there is only 1 adversarial party?', 'Moreover, the performance reported in this paper seems to be much inferior to the state-of-the-art results reported in the literature.', 'However, this does not take into account the time already spent on pre-training. Perhaps the authors can include some results as to the total time taken as well as amortized total time over a number of different downstream tasks.', 'Beyond the core findings, the other settings are less convincingly supported by seem more like work in progress and this paper is really just a scaling-up of [Pathak, et al., ICML17] without generating any strong results regarding questions around representation, what to do about stochasticity (although the discussion regarding something like ‘curiosity honeypots’ is interesting).', 'Why is the random seed being used to compare the performance of different arms? Do you instead mean that s and s’ are two values of the arm in Figure 4?', 'It would be nice to see a better case made for spherical convolutions within the experimental section.', '- The egocentric velocity field is not described (section 5)', 'While I could imagine human judges preferring them as they are fluent, I think they are wrong as they express a different meaning than the SPARQL query they are supposed to express.', '- the method is not applicable to episodes of different length', 'The graphs were difficult to parse.', 'The problem of image classification is considered only, while authors claimed the method can be easily applied to other problems as well.', '- Table 3 is a bit confusing as-is (lower is only better when controlling on the quality of the best sample.', 'The remaining components of the proposed method are not very new.', 'The results  are overall not very impressive.', 'However, the idea is very related to Yeh et al.’s work which has already published but not mentioned at all.', 'Unfortunately this paper offers only weak results.', 'Indeed, without referencing the original Pointer Network and (and especially the) Transformer papers, it would not be possible to understand this paper at all.', '1. (Also AREA CHAIR NOTE): Another parallel submission to ICLR titled “Generative Ensembles for Robust Anomaly Detection” makes similar observations and seemed to suggest that ensembling can help counter the observed CIFAR/SVHN phenomena unlike what we see in Figure 10.', 'I would like to see a convergence proof where the batch size $B_{t}$ is treated as a small constant like other SGD proofs assume.', '3. The architecture of the neural networks used for the Generator and Discriminator is very non-standard, which', 'A naive approach to estimate coefficient with single-source domain discrepancy measures such as [1]Mansour (2009), [2,3] Ben-David(2007, 2010), [4] Kuroki et al (2019), and W1-distance is not considered.', 'For example, authors could implement pGAN by ignoring the detectability of the discriminator (i.e. \\\\alpha=0) or typical pGAN when they compare with the label-flip operation.', '- In particular, Section 4 is a series of empirical analyses, based on one dataset pair.', 'The method is difficult to understand, missing many details and essential explanation, and generally does not support a significant contribution.', \"2) Beware of overstating: the argument that the framework is broadly applicable is not that useful, given that it's a lot of work to derive closed-form marginalized estimators.\", 'It is in the end plugged into a continual learning algorithm which also performs domain transformation.', '- There is no need for such repetitive citing (esp paragraph 2 on page 2).', 'Similarly, figure 3 as well as figures 5-7 and 8 in the appendix provide very good information about the tunability of the various optimizers without using the introduced metrics.', '2. Figure 3: it is confusing to call the cumulative distribution of the maximum classification score as the CDF of the model (y-axis fig. 3 left) as CDF means something else generally in such contexts, as the CDF of a predictor.', 'In terms of presentation, the notation and statement of theorems are precise, however, the presentation is rather dry, and I think the paper can be significantly more accessible.', 'However, the function of interest is limited to a small family of affine equivariant transformations.', '2) although there must be some small innovations, I thought that all the results had more or less been proven by Dupuis and co-authors:', 'I would suggest comparing with CW attack under different sets of hyper-parameters.', '- Section 4.4.1: “DSO-NAS can also search architecture [...]”  -> “DSO-NAS can also search for architectures [...]”', 'Overall, I think this paper has some interesting ideas, but those need to be fleshed out and clearly explained in a future revision.', 'Though fundamental understanding can happen asynchronously, I reserve my concern that such empirical method is not substantial enough to motivate acceptance in ICLR, especially considering that in (only) 124/144 (86%) of the studied settings, the results are improved. And there is no analysis of the failure settings.', 'I would strongly recommend including the computational cost of each method in the evaluation section.', '- What is the difference between the result of Theorem 4.3 and the result from (Lacoste-Julien 2016)?', '(2) The paper does not do a great job of convincing the reader that the problem it is trying to solve is an important matter, or the proposed method is indeed effective in some applications.', '(3) The experiment section lacks more detailed analysis which can intuitively explain how well the proposed method performs on the benchmarks.', 'Regarding the presentation, I found odd having some experimental results (page 5) before the Section on experience even have started.', 'Yet the metrics proposed depend on supervision in the target domain.', '- Very little details (apart from the optimization algorithm) are given regarding the architecture used (types of input, output, neural units, activation functions, number of hidden layers, loss function, etc...), which makes it very hard to reproduce this approach.', 'Generative replay also brings the time complexity problem since it is time consuming to generate previous data.', '- the higher-order features T*a*b are useful only when a is noun and b is an adjective: why not investigate using T to model higher-order interaction for all (a,b) pairs regardless of the syntactic relationships between a and b?', 'Tiny detail: The axes of several of the plots given in the paper mis the lables which makes it hard to read. Straightforward to fix, but worth mentioning nevertheless.', 'Is Harmonic Convolution applicable to complex STFT coefficients as well?', 'p2-3, Section 3.1 - I found the equations impossible to read. What', '3) I would suggest a different name other than Neural-LP-N, as it is somewhat underselling this work. Also it makes Table 2 not that easy to read.', 'I don’t understand the claim that “GANs prioritize matching joint distributions of pixels over per-pixel reconstruction” and its implication that VAEs do not prioritize joint distribution matching.', 'Without doing so, it leaves the reader wondering why not simply a standard RBM trained using a standard method (e.g. contrastive divergence).', '- comparison should be made to the linear composition method in the Arora, Liang, Ma ICLR 2017 paper', 'Could we say that the advantage of the Gumbel Softmax technique is two-fold? i) make the loss differentiable with respect to the arch parameters; ii) reduce the variance of the estimate of the loss gradients with respect to the network weights.', 'First, the novelty of the approach is limited -- the approach amounts to using a sparse integer layer instead of a floating-point layer within a feed-forward architecture.', 'In particular there is not any theoretical not experimental evidence that the approach would scale to any instances where a pure optimization approach would be slow to provide any meaningful solutions.', '- The term p(w) disappears on the left hand side of Eq 2.', \"2. I think that the claim that the use of neural networks with discrete inputs can approximately solve NP-hard optimization problems is an exciting one, which likely necessitates more experiments (or theoretical results), but as it stands I don't think it is a fundamentally different conclusion from the fact that this method provides a great scalable solution for the ordinal embedding problem.\", 'However, this only affects the method of drawing the samples from a fixed known distribution and should have no more effect on the results than say a choice of a pseudo-random number generator.', '- In Appendix D, the Figures could be slightly clarified by using a colored heatmap to color the curve, with colors corresponding to the threshold values.', 'While the authors say \"attributing a deep network’s prediction to its input is well-studied\" they don\\'t compare directly against these methods.', 'Are there any other advantages for F-pooling s.t. people might want to use it as opposed to AA-pooling?', '5. Adaptive kernels have only been tested in the first convolutional layer, would the adaptive kernels work well also in different layers?', 'There is a little typo in Formula 1 for the STFT spectrogram, I would use the modulus |.| rather than || . ||.', 'In summary, the quality of the paper is poor and the originality of the work is low.', 'compared two schemes of this work, the ones with attentions are “almost” identical with ones', \"Third, it is rather surprising that the authors didn't mention anything about the traditional causal discovery methods based on conditional independence relations in the data, known as constraint-based methods, such as the PC algorithm (Spirtes et al., 1993), IC algorithm (Pearl, 2000), and FCI (Spirtes et al., 1993).\", '- The model G_theta does not appear in the training objective function (4), how is this module trained precisely?', '4. Even when the authors formally introduce \\\\sigma and \\\\omega in 4.2, it is still not clear that why both of them are used for modelling the success probability.', '5. On relational detection task, is there a way to compare with the STOA method on some specific data split? This will leads to much more convincing results.', '3. Scenario discussed in Sec. 4 seems somewhat impractical.', 'I vote for rejection for four major weaknesses explained as follows.', \"I don't understand what is meant by cognitively plausible but not human-like; perhaps an example of a cognitively implausible mechanism would help clarify this issue.\", 'Because, the results are only shown on one dataset, it is harder to see how one might extend this work to other form of questions on slightly harder datasets.', 'While the generation of this type of explanations is somewhat novel, from the text it seems that the proposed method may not be able to indicate what part of the image content drove the model to predict class A. Is this indeed the case?', 'In general, the space that was used to explain the Transformer baselines---which are essentially straightforward ways to adapt transformers to this task---could have been used to give more detail on the dataset.', 'I think the paper could benefit from having this in the earlier sections.', '5. The term \"PowerSGD\" seems to have been used by other papers.', 'However, the fact that models with less parameters perform better than BERT-based models in the low-resource case is not very surprising.', \"I don't think this is really a fair comparison; I would have liked to have seen results for the unmodified reward function.\", \"3. In the introduction, the Authors point that prior methods have trouble dealing with textureless, reflective or transparent approaches, but it's not clear form the paper where it addresses these cases, and if yes, what is the mechanism for that.\", 'Is it a combination of DGR and HAT with some capacity expansion?', 'The method provides impressive compression ratios (in the order of x20-30) but at the cost of a lower performance.', 'Consider doing cross validation over those 42-49 data points, and report the mean of deviations computed on the test folds.', 'If the two NNs used in DNN and DNN(resized) are different, I believe it’s still possible to apply the algorithm in DNN(resized) to the NN used in DNN, and get a full trace in the figure as noise and projection changes, which would lead to more fair comparison.', 'I am a bit unclear about how comparisons are made to other methods that do not optimize for small numbers of parameters? Do you compare against the lowest error network found by LEMONADE? The closest match in # of parameters?', 'While I found the derivation of the Cramer-Wold distance interesting, the final form of this distance (Eq. 2), to me, looks very similar to the MMD with a particular kernel.', 'It might be beneficial to include comparison to this approach in the experimental section.', \"Doesn't the classification loss have a dependency on the input condition?\", 'More details should be provided, and when comparisons to past works or inter-life curiosity are made, this should be controlled for.', 'The experimental settings, e.g. how the train:test datasets are split, and hyperparameter settings, are not clearly given.', 'It is better to explain the major difference and the motivation of updating the hidden states.', '2. In the caption of figure 2, there should be a space after `\":\".', 'In its current state, I am not sure that it adds a lot to the manuscript.', 'It is fine, but it seems weird that the author still mentioned the setup of MNIST+SVHN in the main text.', 'The work is rather incremental from current state-of-the-art methods.', '1. the difficult to train the network', 'Overall, the method looks incremental and experimental results are mixed on small datasets so I vote for rejection.', '- It would be better to provide the details of the procedure of the proposed method (e.g., Algorithm 1 and each processing of Algorithm 1) in the paper, not in the Appendix.', 'There are many typos and unclear statements.', '1. In Section 2, I find the sentence \"We follow a similar intuition but instead of decomposing a 1D signal of time into its components, we transform the time itself and feed its transformation into the model that is to consume the time information\" really unclear. Could you rephrase it?', '- the sentence \"Bacause the identity of the datapoint can never be learned by ...\" What is the identity of a dat point?', '- The use of random exploration for the discoverer is underwhelming. Have you tried different approaches? Would more advanced exploration techniques work or improve the performance?', 'The inference algorithm builds on standard techniques of deep generative models and, also, on previously proposed methods (Wand and Blei, 2003) for dealing with the complex hierarchical priors involved in this kind of models.', 'What happen for Meta-RevGrad + idt or Meta-RevGrad + revMap?', '- Why does structured exploration reduce the number of network parameters that need to be learned?', '- Grammatical errors and odd formulations all over the place', '* The BiLSTM they use is very small (embedding and hidden dimension 50).', 'This paper presents non-trivial theoretical results that are worth to be published but as I argue below its has a weak relevance to practice and the applicability of the obtained results is unclear.', 'In 3/4 of the pairs the author tried, this phenomenon is not there. Whether the findings generalize to other situations where the phenomenon appears is uncertain.', 'However, I found that the contribution of this paper is fairly small.', 'How are the lambda and threshold parameters tuned? The authors mention a validation set, are they just exhaustively explored on a 3D grid on the validation set?', 'A reader’s most natural question is whether there is a large enough improvement to offset the extra computational cost, so the fact that wall-clock times are relegated to the appendix is a significant weakness.', 'What is the L1 norm applied on?', '- In the empirical results, the performance of the proposed method and Reg-GAN (from the numerics of GAN paper) are quite similar. Are there instances that the proposed approach significantly improves the stability of practical GAN architectures?', 'Meanwhile the actual method used in the paper is hidden in Appendices A.1.1-A.2.', 'section 6.3, the authors show an experiments in this case, but only on a dense', '-The proposed technique does not seem to be original enough, and it does not handle the problem foundationally well.', '- Fitting 6 parameters to 42-49 data points raises concerns about overfitting.', 'A proper baseline should have been compared.', '- Judging from Table 1, the proposed method does not seem to provide a large contribution.', 'Also perhaps better to use the curly sign for vector inequality.', 'While the motivation is nice, I find the results (especially in the unguided setup) underwhelming.', 'It is also not clear to me how domain translation is relevant to continual learning.', 'The paper would need to be improved substantially in order to appear at a conference like ICLR.', 'The technical approach of using a Lagrangian relaxation is the standard way one goes about handling constrained optimization problems, and thus I do not see any novelty there either.', '* The connections to deep learning seem arbitrary in some of the experiments.', 'Have the authors considered to use categorical or binary variables?', '-- It is not clear how the  per-example scalar sigma-i is learned. (for Eq 2)', \"5. In fact, I don't know why \\\\omega needs to output p. It's never mentioned in the experiment section.\", 'In this regard, I encourage the authors to update the supplementary material in order to show extended qualitative results of the explanations produced by their method.', '- Lack of sufficient technical detail on models and dataset', 'I think the paper does not fit this conference. It is better to be presented in a Demonstration section at a *ACL conference.', 'Simply because for continuous variables similar experiments have been reported before', 'These classification datasets are often so close, that I do wonder whether even simpler methods would work just as well.', '- Architecture choice unclear: Why are $\\\\sigma$ and $\\\\omega$ separate networks.', 'Clarification of the connections/differences, and comparison with these related methods should be made to show the efficacy of the proposed method.', 'Therefore, I recommend to accept the paper but after revision because the presentation and explanation of the ideas contain multiple typos and lacking some details (see bellow).', 'https://arxiv.org/abs/1802.05983', 'Additional experiments on at least ImageNet would have made the paper stronger.', '11. Baseline 2 is actually referred to as \"usage baseline\" but this name is not introduced in the itemized part.', 'But this is too similar to the cited findings on page 6 (models assign high likelihood to constant images).', 'It reads very much like a STOC theory paper, and a lot of the key ML details that would be relevant to audience at this conference seem to have been shoved under the rug in a way.', 'Unfortunately, the results are quite disappointing in terms of sound quality, and feature many artifacts.', 'Can you explain somewhere exactly what you mean when you say \"learning dynamics of deep learning\"? Given the specific nature of the results presented in the paper it would be nice to be precise also when it comes to the overall topic under study.', 'The reasons for the use of the energy-based formulation are not clear to me.', 'Specifically, the first contribution listed in the introduction makes it look like this paper introduces the idea of not learning the decoder on the dataset (the one that starts with “The network is not learned and itself incorporates all assumptions on the data.”).', 'The experimental sections look rather mechanical. I would have put some results on the learned embedding. Or some demonstration of the embedded history or probability to intuitively convey the idea and how it works.', 'As is, the counter example proof itself is quite confusing: it would really help if the proof was more formal.', 'Overall, the idea is simple, the explanation is clear and experimentation is extensive. I would like to see more commentary on why this method might have long-term impact (or not).', \"In sec. 4, there's a reference to an initial set of experiments with count-based methods without much details.\", 'For example, the number of labeled examples in Table 1 is fairly large and inconsistent (4K, 1K, 10K for the 3 organic datasets).', '- the more interesting problem, RL + auxiliary loss isn’t evaluated in detail', '* minor: in figure 8 in the appendix, the results after 100 iterations is, as far as I understand, over a single replication, so is not particularly reliable (and will always be 100% of a single optimizer)', 'It would be good to know how $\\\\gamma$ varies across tasks.', 'Missing references - authors may want to consider citing https://arxiv.org/abs/1906.06187 as well in Sec. 2 - it seems very related to this work.', '- Again, Figure 3, it is hard to see the benefits for increasing M from the visualizations for different clusterings.', 'It is hard to support this motivation when no experiments are done in its favor.', '- In Equation (2), How is P_ij defined exactly, are they parameters? I am quite confused about this part', 'Finally, the style (font) of the paper does not adhere to the ICLR style template, and must be changed.', 'In terms of method, the guidance for learning Siamese networks are designed heuristically (e.g. edges, colors, etc.) which limits its applicability over various datasets; I think that designing more principled approach to build such guidances from data should be one of the key contributions of the paper.', 'Though the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed.', 'There are also concerns about the motivations behind parts of the technique.', 'It is unclear how the model actually operates and uses attention during execution.', 'I understand how the game theoretic framework is established but how does this manifest itself in the algorithm described in Section 3.1 needs more explanation.', 'For instance, how deep should a model be for a classification or regression task?', 'Specifically, how can mutual information in this context be formally linked to generalization/overfitting?', '- Pioneering work is not necessarily equivalent to \"using all the GPUs\"', 'One of the main area which is missing in the paper is the comparison to two other class of RL methods: count-based exploration and novelty search.', 'In addition, the subindex ‘1’ of the point ‘q’ is not explained.', 'The authors do not thoroughly explain the motivation of this paper.', 'We think that this is not enough, and more extensive experimental results would provide a better paper.', '-I find the experimental studies a bit limited and I would expect larger studies which would have improve the interest of the paper.', 'Since each domain may have different number of classes, it is not clear how the number of classes (L) is set in the classification module (maximum number of classes in all domain?).', 'It would be nice if the authors pointed to a git repository with their code an experiments.', 'More discussions on these questions can be very helpful to further understand the proposed method.', '- There are better words than \"decent\" to describe the performance of DARTS, as it\\'s very similar to the results in this work!', '2. As the problem is formulated as an RL problem, which is well-known for its difficulty in training, did we encounter similar issues? More details in the implementation can be very helpful for reproducibility.', 'However, these were done using 1 dataset and also a simple feed-forward network (rather than LSTM).', 'I believe that the presentation of the proposed method can be significantly improved.', '3. This apart, I think that the experiment section is pretty hard to read, given all the metrics and methodology is in the Appendix.', 'Also, it seems quite strange to me that making the FW overshot and then projecting back would be beneficial.', '1) I wonder if the proposed method work for most GAN models, more experiments evaluated on more recent GAN-based  models should be added to verify the superiority claimed in this paper, e.g., TP-GAN [Huang et al., ICCV 2017], PIM [Zhao et al., CVPR 2018], DR-GAN [Tran et al., CVPR 2017], DA-GAN [Zhao et al., NIPS 2017], MH-Parser [Li et al., 2017], 3D-PIM [Zhao et al., IJCAI 2018], SimGAN [Shrivastava et al., CVPR 2016], AIM [Zhao et al., AAAI 2019].', 'Also, the compared methods don’t really use the validation set from the complex data for training at all.', '- it is not really clear to be what data the graphs show: the boxplots show 5% of what data? does it also include the models obtained by gaussian process regression? and what about the line plots, is it the best model so far as you train more and more models? if so, how are those models chosen and ordered? are they the results of single models or average of multiple ones?', 'I identify this ambiguity between BERTScore versions as an important weakness of the paper.', 'First of all, the setup for the AE and VAE is not specified.', 'At the end of the subsection, the authors argue that 4D convolution is just k times larger than 3D kernels, which sounds like contradicting.', 'However, they state they loosely follow this approach. What does that entail? What kind of theoretical guarantees are given up due to not following this, a better exposition on this topic would help to support the claims.', 'However, my concern is about the experiments.', 'The idea to extend the use of VAE-GANs to the video prediction setting is a pretty natural one and not especially novel.', 'It would be nice to see how a “gold standard” HMC based inference does on at least the small toy problem of Sec 5.1?', 'The paper can benefit from a proofreading.', '2. Although the experiments are detailed and interesting they support poor theoretical developments and use a very classical benchmark', 'Therefore, I cannot find any advantage in the proposed method, compared with these existing MAP based image restoration approaches.', '- Notation in Sec. 3.2 is very cumbersome, making it hard to follow.', 'Since the paper relies so heavily on Lee et al., the authors should make an effort to summarize the approach in a mathematically precise way.', 'There should be some kind of comparison with test set results from other state-of-the-art work on these datasets.', 'However, the method they propose offers very little that is new when compared to e.g. Vaswani (https://arxiv.org/pdf/1706.03762.pdf, section 3.5) (the authors acknowledge this work several times).', '- In Equation (6), the posterior distribution should be P(X|G) since X is the latent variable to be inferred, right', 'In the last paragraph in Related Work, \"provide\" should be \"provides\".', '- The end of the 2nd line of lemma 1: P, G should be \\\\mathbb{P}, \\\\mathbb{G}', '‘Our proposed approach represents the first physics-based simulation of its kind that supports MARL.’ This sentence remains unclear as the authors do not propose a simulation engine.', 'The only issue with this paper is its degree of novelty, which is narrow.', 'I would suggest the authors to either introduce the two problems earlier or to simply say that near-optimal results are achieved, without giving detailed results, because it is very hard to understand them without any introduction of the task being achieved.', \"- it wasn't clear how the sparsity percentage on page 3 was defined?\", 'It is hard to understand the results without discussing it.', 'Hence, I kindly do not think the outcome is truly a research result.', '1) Provide stronger empirical results (these are not too convincing).', 'Assessment: Overall, this is a borderline paper, as the task is interesting and novel, but the presentation is lacking in technical detail and there is a lack of novelty on the modeling side.', '1) The critical issue of this paper is that the algorithm is designed to minimize the upper bound.', 'The main problem I see with these approaches is that they rely on sufficiently large batch sizes which could be (currently) problematic for many real-world applications.', 'If this is the case, authors should state it more clearly in the paper that a large proportion of the gap in performance between MixMatch and ReMixMatch is the introduction of stronger transformations (Autoaugment style).', 'There are some well-cited works that the authors may have missed. These are ultimately different approaches, but perhaps the authors can obtain some inspiration from these:', '- For the speed processing experiment, did you test what the performance would be if K matrix is replaced by a fully connected layer?', 'Thus, the evidence of the experiments is not enough.', 'It is thus unclear whether the advantage can be maintained after applying these standard regularsisers.', '2. Section 3.3 argues that K-matrices allow to obtain an improvement of inference speed, however, providing the results of convergence speed (e.g. training plots with a number of epochs) will allow a better understanding of the proposed approach and will improve the quality of the paper.', '- The network architecture is never described, especially the transition from Conv to Dense and the layer sizes, making the work hard to reproduce.', 'As noted by the authors, transfer is most attractive in low-supervision regimes, w.r.t. the target task.', 'However, since quantitative exploration of large real-world datasets may be challenging and expensive to collect, the synthetic experiments could have been more detailed.', 'I would suggest rewriting this paragraph to make it clearer and less speculative, and acknowledge that although rotating filters might increase computational complexity, it has often been shown very effective.', 'It would also be interesting to see an experiment where the labeled data has a skewed distribution of classes, but we provide the method with information about the true class distribution, and demonstrating that this information helps predictive performance.', 'Experiments are on toy domains with very few goals and sub-task dependencies.', '- It is unclear how MISC-p is performed. Please elaborate on how MISC-p works for prioritization.', 'Recommendations for the authors: Would it be possible to provide an analysis of the cases when TabNN is expected to outperform GBDT by a sizable margin? Or, if not, are there other reasons why using a neural network would make more sense than just simply running GBDT?', 'The paper does not talk about settings where states of interest are not known, so all of the experiments are based on this strong assumption.', 'A missing empirical analysis is on class-conditional noise (see for example Patrini et al. 17 for a definition).', '- I might have missed that, but are the authors offering an interpretation of their observation that the performance of the self-modulation model performs worse in the combination of spectral normalization and the SNDC architecture?', '- little methodological innovation or analytical explanations', 'It seems that the discriminator takes a whole sequence as input, but some precision on how this done could be added.', 'In addition, only the transformer baselines were considered, and it would seem natural to consider LSTM-based baselines, or some other related techniques.', '- In figure 5 (a) \"cencept\" should be \"concept\"', 'However, the evaluation of the proposed adaptive kernels is rather limited.', 'The paper not only claims \\'large scale representation learning\\' but also utilizing the described idea to use neural networks to \"directly, approximately solve non-convex NP-hard optimization problems that arise naturally in unsupervised learning problems.\" Both claims are not really shown in the paper: (i) The experiments are not large scale and (ii)  it becomes not clear how any substantiate insight with respect to NP-hard problems can be gained here apart from the fact that it tackles a ML problem, which many seem to be computationally hard problems.', '3) The novelty of this paper is incremental as the theoretical results are extended from Cortes et al (2019) and Zhao et al (2018).', 'However, the paper contains only little novelty and does not provide sufficiently new scientific insights.', 'It’s not obvious to me how useful the ME bias would be when there is a large number of classes since the probability assigned to the true novel class with a perfect ME bias would be 1 / (# unseen classes).', 'I enjoyed reading the submission, which is very clearly written, but due to the relatively limited value of the contributions, and excessive focus on the tunability metric which I do not feel is giustified, I slightly lean against acceptance here at ICLR. I do think, however, that it would make a great submission to a smaller venue or workshop.', '- Experimental results are provided only on MNIST and Fashion-MNIST.', 'While this paper is acknowledged in the related work, it would be helpful to expand further on the relationship between these works, so the originality and contribution of this paper can be better evaluated.', 'Since the latent models are learned based on existing techniques, the paper presents an incremental contribution.', 'The writing is understandable for the most part, but the paper seems to lack focus - there is no clear take home message.', 'The second order analysis is good but it seems to come down to just a measure of the empirical variances of the datasets.', 'Although some promising', '- That learning simple functions and composing them to compute more complex functions would be more data efficient than directly learning the complex functions does not seem very surprising.', '5. The paper is imprecise and unpolished and the presentation needs improvement.', 'Suppose we rotated these representations. Now the signal from the original dimension is split across multiple dimensions and hence the CFS may be deceivingly high.', \"-3 For image-to-image translation experiments, no quantitative analysis whatsoever is offered so the reader can't really conclude anything about the effect of the proposed method in this domain.\", 'The main criticism I have is that I found the paper harder to read.', 'This needs more elaboration. Is this way of training results expected? What is the lesson learned?', '- For semi-supervised classification, the paper did not report the best results in other baselines.', 'Third, the writing in the paper has some significant lapses in clarity.', \"I don't have a good sense of whether this is a reasonable theoretical model to explore and a lot of very basic questions remain unanswered for me.\", 'I am not convinced that the measure theoretic perspective is always', 'I believe that this paper is thus not in its final form and could be largely improved.', 'This change is noted, but it would be useful to make a least a brief (i.e. one sentence) comment on the motivation for this change.', 'I believe that the paper should currently be rejected, but I encourage the authors to revise the paper.', '- (W2) Related to the last line: I did not see any experiments / analysis showing how stable these different numbers are across different runs of the representation technique. Nor did I see any error bars in the experiments.', 'It is unclear, why one should use the proposed duality gap GAN.', 'The fact that HAT-like masks are used for a generative replay approach is clear, but the actual mechanism of \"growing capacity\" is not made clear at all especially in the beginning of the paper.', 'Yet the authors stop at only solving this version with a machine learning approach, which does not hit the bar for me.', '- (W4) Metrics for ranking of transfer don\\'t make sense (and some are missing) : I also don\\'t understand how \"precision\" and NDCG are used as metrics.', 'In most cases I would care about how well my model would perform on transfer not just which tasks I should transfer from. I would have wanted to understand something like the correlation of these produced scores with the actual ground truth performance numbers.', 'My main question is that: what is the main advantage of the Cramer-Wold distance to an MMD with a proper kernel?', \"But I'm concerned with the novelty and contributions of this paper.\", 'However, the experiments feel like they are missing motivation as to why this method is being used.', 'But the problem settings are not clear to me.', '2- Why is a two-stage pre-training (Figure 2) process needed? Why not just a single stage?', '(c) The authors should present what they mean by a dilated convolution using the notation of the paper.', 'The result does not at all apply to all of them.', 'The paper has an interesting potential but seems a bit limited in its present form.', '- Since the proposed method starts from Laplace transform, it would be helpful to further discuss the connection between other methods that regularises the eigenvalues of the Jacobian (such as spectral-normalisation), which work in the frequency domain from a different perspective.', 'Q1: Has the authors tried more complicated datasets such as CIFAR-10 to evaluate the pGAN method? It would make the paper more convincing to add results on more complex datasets.', '- in section 4.3 how is the reconstruction built (Figure 3b)?', 'The results and discussions in the main part of the paper are too light in my opinion; the average model accuracy across modules is not an interesting metric at all, although it does show that the Transformer performs better than recurrent networks.', 'The related work section looks incomplete with some missing related references as mentioned above, and copy of a segment that appears in the introduction.', 'This assertion is not justified, and seems surprising to me; we have very useful natural language processing systems that do not perform in a way that is comparable to humans (the hedge \"some degree of\" is really neither here nor there).', 'that (except the minor small section of streaming data), the paper is more like a proper verification of how tree-based learning algorithms work very well in tabular data--which is far from the basis of the paper and does not make the paper novel enough for ICLR.', '3. The experimental study is weak.', '2. The authors should provide ablation study and analysis of their CTAugment.', 'With regards to the fMRI experiments, good baselines are missing: DEMINE is compared to Pearson correlation.', '- The paper is over the hard page limit for ICLR so needs to be edit to reduce the length.', '-  From the plots of learning curves in appendix, the proposed methods doesn’t seem to show a huge boost of performance comparing to the uniform bandit. Could you show aggregated comparison between the proposed method and uniform bandit similarly to what is done in Figure 4 ?', 'I take issue with the usage of the phrase \"skill discovery\".', '- Minor grammatical mistakes (missing \"a\" or \"the\" in front of some terms, suggest proofread.)', '- The problem setting description is neither formal nor intuitive which made it very hard for me to understand exactly the problem you are trying to solve.', \"- it's better to show time v.s. testing accuracy as well.\", 'The originality is relative low though, since it is mainly an application of  deep InfoMax to language modeling, not inventing a new algorithm and applying to language modeling.', 'Is it better to decay learning rates for toy data sets?', 'As of now, the greedy nature of the algorithm is hidden across a number of sections (not introduced when presenting the main algorithm).', 'The improvement from the baselines is also limited.', 'The comparisons are also absent in experiments.', '7. The evaluation on two datasets seems to be rather limited, additional comparisons should be included.', 'Although I personally enjoyed reading the results that from control theory perspective are inline with GAN literature, the paper does not provide novel surprising results.', 'For e.g. the results on the oscillating behavior of Dirac-GAN are described in related works (e.g. Mescheder et al. 2018), and in practice, WGAN with no regularization is not used (as well as GAN with momentum, as normally beta1=0 in practice).', 'ReLU network with 2 hidden layers, and it is unknown if it works in general.', '- I would like to see some more interpretation on why this method works.', 'First, In Theorem 2, which seems to be a main result of the paper, the authors were concerned with the condition when W_{ji} >0, but there is not conclusion if W_{ji} =0.', 'While sensible, this seems to me to be too minor a contribution to stand alone as a paper.', 'The proposed approach seems reasonable but it is mostly a work of engineering and provides little insights into the problem nor the proposed model.', 'To be honest, the theoretical contribution of the paper is limited.', 'This paper looks very hastily put together, especially pages 7 and 8.', 'For example, the original GNN, ChebNet, etc. that leads to GCN can be mentioned.', \"For example, the related works paper would read better if it wasn't one long block (i.e. break it into several paragraphs)\", '- the complexity of the proposed algorithm seems to be very high', 'They would have a very low weight difference score though they are ideal representations for each other.', 'However, the results are not enough to be accepted to ICLR having a very high standard.', 'My question here is that how is this method better than the standard VAE, where we also have an analytic form for the ELBO when the prior is Gaussian, an no sampling is required.', 'After reading, the reviewer cannot understand why the user should bother to use hyperbolic representations that are more complex to compute in GCNs, given that the experimental results are roughly the same.', 'This issues makes reviewing this paper very difficult.', \"4) Table 1 difference between DNC and DNC (DM) is not clear. I am assuming it's the numbers reported in the paper, vs the author's implementation?\", 'I like the directions using surrogate to speed up HPO in general but I feel the learning curve prediction part can be improved. There are already some works, not using deep learning method, for example the following:', 'If this all is indeed the case, it is not surprising that the numbers the authors get in the experiments are so similar to WAE-MMD, because CWAE would be exactly WAE-MMD with a specific choice of the kernel.', 'It is thus very hard to know if this new approach brings any improvement to previous work.', 'I would introduce the notation for t2v(tau) upfront and use that to define a(tau, k)[j] and f_j', 'For the language translation results, were there any other state-of-the-art methods that the authors could compare against? It seems they are only comparing against their own implementations.', 'It does intuitively makes sense, but more mathematical definition (e.g., dimensionality) may be needed.', 'It is also not clear how the loss function proposed differs from that of the CDVAE, etc.', 'That is, authors assumed that they have a degradation function F and all the inference process is just based on this known function.', 'Weaknesses: Paper could have been written better. I had hard time understanding it.', \"However, I don't understand the use of $\\\\alpha$ here.\", 'Here are a few examples: The ICLR citation style needs to use sometimes \\\\citep.', '- The aspect ratio in Fig. 5 should be fixed.', '- Section 3.3: “Different from pruning, which the search space is usually quite limited”. “which” should be “whose”?', 'Spare few lines of equations to define what are DeepSets and PointNetSeg in the paper and point out the difference since these networks are used throughout the paper extensively without proper mathematical definition.', 'However, this task is an instance of natural language generation: given a meaning representation (quite often a database record), generate the natural language text correspoding to it. And previous work on this topic has proposed very similar ideas to the scratchpad proposed here in order to keep track of what the neural decoder has already generated, here are two of them:', '- Sec 3.4 can you recap all the parameters after eq.11? going through Sec 3.2 and 2.2 to find them is quite annoying.', 'I think that the current draft lacks strong experimental results to properly demonstrate the usefulness of the method.', '- It would be nice to have an experiment that varies the size of the external paired sentence-image dataset and tested the impact on performance.', 'So any insights on the nature of these bounds will be valuable, especially with some comments on how these bounds change if the teacher model is itself realized as a 2-layer neural network.', 'Besides, in the experiments, the proposed method is not compared to other transfer learning methods.', 'This very much limits the utility of the method.', '4. Why not use continuous actions with a parameterized policy (e.g. Gaussian)?', 'In terms of evaluation, the authors only presented a few qualitative results on simple datasets, which is not comprehensive and convincing.', 'To me this is a big concern as different runs of the same representation technique can likely have very different CFS scores based on initializations and random seeds.', 'It is known that SGD with fixed step-size can not find the optimal for convex (perhaps, also simple) problems.', 'The purpose of the public set is explained only in section 5.2.', \"The many-to-many results are clearly better than the pairwise results in this regard, but in the context of musical timbre transfer, I don't feel that this model successfully achieves its goal -- the results of Mor et al. (2018), although not perfect either, were better in this regard.\", 'I vote to reject the paper at this stage, mainly because of the following three points:', 'For example, for baseline 1, it is very hard to understand why would we want to use such an unusual baseline, and why it is called a \"random baseline\".', '- very incremental improvements on PTB over a very simple baseline (far from SotA)', '1. If we do not have access to the model parameter, the training data, or the artifacts during training like the discriminator, what are some of the real world situations that fit this description? In those cases, is it too much to assume that we can control the random seed input to G?', 'In conclusion, I suggest a reject of this paper due to the lacks of comprehensive study and evaluation.', \"For the bAbi task, although there is a significant improvement (43%) in the mean error rate compared to the original DNC, it's important to note that performance in this task has improved a lot since the DNC paper was release. Since this is the only non-toy task in the paper, in my opinion, the authors have to discuss current SOTA on it, and have to cite, for example the universal transformer[1], entnet[2], relational nets [3], among others architectures that shown recent advances on this benchmark.\", 'While the general description of the model is clear, details are lacking.', 'Taking a random example (there are others by simple searching), in the ECCV paper \"DFT-based Transformation Invariant Pooling Layer for Visual Classification, Ryu et al., 2018\" The DFT magnitude pooling is almost the same as the authors\\' propositions, where the \"Fourier coefficients are cropped by cutting off high-frequency components\".', 'Also pervasive is the use of the asterisk to denote multiplication, again as if it was code and not math.', '1) Although the ensemble idea is new, the idea of selective self-training is not novel in self-training or co-training of SSL as in the following survey.', \"There isn't a tested hypothesis, but rather it's a feat of engineering to get this to work.\", 'The overall presentation could be better, and I would encourage the authors to tidy the paper up in any subsequent submission.', 'I can understand the point that training NNLM accelerates the experiments, but the author(s) should consider trying a simply LSTM model after the best settings had been discovered (e.g. Table 1).', '* \\\\sigma is not given in Figure 3(a)', 'Is there a reason why the authors do not introduce their objective by following the variational framework?', 'What would the pairing-based strategy look like in Figure 6 right? Are there not significance tests that could be used to more carefully quantify the level of support for the two alternative strategies?', 'and bounded failure rate, otherwise it is not really a verification method.', 'Another baseline could be to simply model the imitator and probing policies as RNNs and let them communicate with each other via the hidden states.', 'A good paper overall, but the experiments were relatively weak (common for most ICLR submissions) and the novelty was somewhat limited.', \"- I didn't understand the motivation for testing only very general-purpose models (this is described in Section 3).\", 'The experiment section needs significant improvement, especially when there is space left.', 'Further, it seems that the results in Table 4 might be a bit obscured by the size of the downstream task dataset.', 'Overall, the paper requires significant improvement.', \"In particular I do not think the satement 'all the pre-training methods are at most linear with respect to the number of edges' made in appendix F is correct.\", 'Originality: Given the existing body of literature, I found the technical novelty of this paper rather weak. However, it seems the experiments are thoroughly conducted.', 'A more rigorous setting is to, for N runs, each run splitting the validation and testing set differently.', '* The use of the name \"batch-norm\" for the layer wise normalization is both wrong and misleading.', 'However, the experiments conducted generally show that SAVP offers only a trade-off between the visual quality of GANs and the coverage of VAEs, and does not show a clear advantage over current VAE models (Denton & Fergus, 2018) that with simpler architectures obtain similar results.', 'Why not compare with Sparsely-Gated MoE?', 'Also how many steps are required to learn the linear interpolation ? How much the does it influence the quality of the interpolation ?', 'If one reframes the convergence rate in terms of FLOPs U=T^2 instead of iterations, then the convergence rate drops from 1/T to 1/sqrt(U), which undermines the claim in remark 3.4 that this analysis is superior to that of Yan et al. (2018).', 'but the way the paper is written makes it very difficult to follow, and the description of the proposed model is unclear (making the experiments difficult to reproduce) and lacks of a better discussion about the interest of mixing multiple loss.', '- It is a bit unclear to me how the authors propose to obtain independent posteriors over z and c. Is it purely empirical or is there a formal reason that guarantees it?', 'The authors acknowledge this connection, but I think they should begin by introducing CE and then explain how Cakewalk generalizes it.', '1: The authors show no benefit of this scheme except perhaps faster convergence.', 'The experiments on synthetic data could be improved: for reproducibility, many works on GANs used the same synthetic data as VEEGAN.', 'Besides, the results on the sentimental analysis are comparable with the compared baselines.', 'I also was not convinced by the experiments which are mostly qualitative. I did not find that this set of experiments provide enough support to the proposed method.', 'Since this work takes the approach of allowing stale weight updates, the author should also compare with existing distributed training approaches that use asynchronous updates, with or without model parallelism, for example, Dean et al., 2012.', '1. I do not get the point of bringing up NCE. Did you actually use NCE loss? Did you only refer to NCE as a weight tying which can be used in a standard XENT loss [3]? The first paragraph of 3.3 did not help clarify this point either.', 'The description of consistency regularisation methods in section 2.2 is not very clear and I would like to get better understanding of temporal ensembling and SNTG methods here as they play an important role in the experiments.', 'In particular, if the goal is to use this method to augment the data we use to train NLP systems in order to make them more robust, it seems that the time cost of the process will be prohibitive.', '3. The structure of the meta-training loop was unclear to me.', 'The paper also misses several powerful baselines of semi-supervised learning, e.g. [1,2].', 'Typo:. The “Inf” in Tabel 1', '--What does a \"heavy classifier\" imply concretely?', '- The approach also seems to add a lot of complexity and heuristics/hyper-parameters.', 'I agree that local SO(2) invariance is too limiting. But it is not true that rotating filters is not effective in planar/volumetric CNNs, as shown by many recent papers on equivariant networks.', 'Overall, I think this paper is not good enough for an ICLR paper and the presentation is confusing in both its contributions and its technical novelty.', 'In summary, I think this is interesting work, but a clearer explanation of the relationship between HRL and MARL, as well as a clearer main argument, supported by experimental evidence, would greatly improve this paper.', 'Negative points: (1) The authors should provide more justification on equation-3.', 'I have no idea that what is the propose of defining a new evaluation method and how this new evaluation method helps in the further design of the MaxConfidence method.', 'Some statements don\\'t make sense, however, eg. \"HSIC-based estimators tend to have loose confidence intervals due to the need to bound generalization error of kernels f and g on unseen data points.', '(2) Eq. (3): is there a superscription \"(j)\" on z_canon in decoder?', 'It is not clear to me that the classifier difference metric is well-defined.', 'Why? If we are learning the distribution, would not it make sense to sample all architectures only after training the supernet at our best?', '2)\\tIt is not clear what the “replicates” refer to in the experiments.', '- figures 2 & 3 should be a lot larger in order to be readable', 'Furthermore, it may be informative to show the saliency maps in Figure 5 not only for cases in which the learner classified the image correctly in both time steps, but also cases in which the learner classified the image correctly the first time and incorrectly the second time.', 'BSD 500 only contains 500 images, and it would be good if more diverse set of images are considered.', 'For example, how to compute the gradient w.r.t. \\\\phi? Since the mean policy is used, it is not apparent that how to compute the gradient w.r.t. \\\\phi.', 'In sum, the paper has a very good application but not good enough as a research paper.', '- My main concern is reproducibility: the authors employ a number of large architectures, complex loss functions, and regularizers / \"additional improvements\".', 'The plot (Figure2 (d)) is very blurry and people cannot really tell local structure from it.', 'Spectrum pooling has been used in the community of computer vision and machine learning.', 'First, many details are missing, especially in the experiments, which makes the proposed method suspicious and non-convincing.', 'The evaluation section lacks experiments that evaluate the computational savings.', 'A stronger contribution is 1., which however is somewhat incremental compared to similar comparisons made in the past.', '- no downstream applications are given which show that these higher order interactions can be useful for downstream tasks.', '- in section 2.2, please explain more how gradients w.r.t hyper-parameters are computed.', 'Why larger reconstruction error achieves stronger privacy protection? I could not find any formal relationship between reconstruction error and privacy.', '-\\tHow the first camera pose is initialized?', 'The main drawback of the paper is that it seems to be more engineering-focused, and doesn’t provide much insight into semi-supervised learning.', '- In Section 3.1 : “Across runs in Table 1, we observe that without Orthogonal Regularization, only 16% of models are amenable to truncation compared to 60% with Orthogonal Regularization.” For me, this is not particularly clear.', 'Listing related work is no the same as describing similarities and differences compared to previous methods.', '- Missed opportunity of better analysis of which theorem/rewrite rule properties are more likely to fail', 'One thing that puts me off is that, in Table 2, AnyBurl (the single one baseline authors considered other than the original NeuralLP) yields better Hits@10 values than Neural-LP-N, but the corresponding bold in the results is conveniently omitted.', '3) The experiments lack comparisons to several important baselines from self-supervised learning community, and methods using soft labels for training (as mentioned in 2) above).', 'Summarizing, the paper addresses a relevant problem but they do not state which their main contributions are, and reintroduce some ideas previously published in the literature.', 'Since this paper is about distributed robustness and distributed attacks, it would be very informative to the community to illustrate DBA attack on these methods to have a more compelling message.', 'More experiments based on other types of data sets with clear global structures such as faces or stop signs will', 'For instance, I would like to see the comparison between DeepCS and SmartHash by Tang et al 2017.', 'Although the method the authors suggest is a plausible way to explicitly model the relationship between syntactic pairs and to create a combined embedding for them, their presentation does not make this obvious and it takes effort to reach the conclusion above.', 'On the other hand, the authors give no evidence, empirical or otherwise, that their method is useful on any downstream tasks.', '1. Are e_{i,t} and lambda_{i,t} vectors?', '3. how are predicted labels embedded? Do you learn a vector of each tag of BIOES and then take a weighted sum of these vectors with predicted probabilities as weights?', '9. It is not clear that baseline 1 and 2 correspond to which baselines in later experiments.', '1. The focus of this paper is the hyper-parameter, please focus and explain more on the usage with hyper-parameters.', 'Similarly, you did not indicate what the deterministic version of your model is.', 'Lemma 3 is too trivial.', 'With the current table, one has to compare cells in the top half of the table to those in the bottom half of the table, which is quite difficult to do.', '1. The proxy f(z) does not bear any resemblance to LP(z).', 'For example, the authors did not justify why VGMM model was chosen and how does it compare to other density estimators.', '* first paragraph page 2: some references to causality literature and definition of spuriousness as common cause', '2. Even though Figure 2b shows that SVHN test likelihoods are higher than CIFAR test likelihoods, the overlap in the histograms of CIFAR-train and CIFAR-test is much higher than the overlap in CIFAR-train and SVHN-test.', 'I do not understand why making use of labels is important for solving the catastrophic forgetting problem and how the labels are useful in the generative replay process.', '5, Although there is a notable difference, one may properly mention previous work Yamamoto et al. (2019), which uses GAN as an auxiliary loss within ClariNet and obtains high-fidelity speech ( https://r9y9.github.io/demos/projects/interspeech2019/ ).', 'I am not sure if this is the first work in this direction of proving bounds assuming an oracle or if there is some background work that the authors could provide to put this into context.', 'On the other hand it is clear that using the confidence of the model to predict the dataset is a useful property, but the right side of the Fig. is very confusing.', 'My main concerns are about the evaluation and comparison of standard neural models.', 'Currently it is still missing discussion such as, when SASNet would perform better and when it would perform worse, what it is that the state of the art features can’t capture while SASNet can.', '1. In the experimental study, the authors present the value of their tuning parameters (learning rate, target rate, discount rate…) at the initialisation phase without any justifications. And the experiments are limited to simulated data obtained from MUJOCO physics engine - a very classical benchmark.', 'In other words, although in the present results, the proposed NF-SGAN/WGAN outperforms the baseline, the reported performance of the baselines is worse than in related works on CIFAR10.', 'In fact, the separate training seems to make this unlikely.', 'I feel that the idea deserves a broader analysis beyond just a single choice of disentanglement.', 'c. Figure 1 is over-complicated.', 'For example, I have trouble understanding the sentence \"So the existed algorithms should be heuristic or it can get a bad result even we train the neural networks with lots of datasets.\" in the introduction.', 'However, the results are a bit misleading in their reporting of the std error.', 'Weakness: It would be good to see some comparison to the state of the art', 'However, there are papers empirically analyzing novelty detection using generative model -- should analyze or at least cite:', 'The experiments use fairly small datasets, where the performance can be largely influenced by how good the feature extractor backbone is (e.g. training on more data and using deeper architecture would warrant better performance, and thus may change the conclusion).', 'I think that this is the crux of the paper that should be significantly expanded and experimentally validated.', 'More experiments on datasets', '- The arguments for why the experimental evidence actually supports the existance of an approximate number system (ANS) could be made more clear.', '- Paper is often hard to follow, and contains a significant number of typos.', 'Not sure why Eqns. 2 and 9 need any parentheses', '1. Can you comment on the quantization time of the suggested method? Repeatedly solving the EM steps can add up to quite an overhead.', '\"reverse view on adversarial examples\" --- what this means isn\\'t clear from the preceding text.', 'From the supplementary, it seems Epsilon means the environment?', \"There are probably many other ways to trade BLEU score for efficiency, and without showing those other methods (and the point drops they have), it's not clear that K-matrices are a good way to speed up decoding a bit.\", 'The proposed technique is heavily dependent on GBDT (Indeed the algorithm and the learned trees are used at least three times).', 'It would have been useful to compare the general models here with some specific math problem-focused ones as well.', '* Figure 5 should appear after Figure 4.', 'In this case, the paper proves that no careful selection of the learning rate is necessary.', 'Significance: It is hard to assess given the current submission.', 'Cons:  unclear transfer learning model, insufficient experiments.', '- The experiments were entirely focused on uncertainty quality but we are always interested in both performance on the task at hand as as well as good uncertainty estimates. What was the performance based on e.g. classification accuracy on each of these tasks compared to the baselines? I believe that including these results will strengthen the paper and provide a more complete picture.', \"6. On a lighter note, I don't believe using a coffe-brewing machine has a 'universally invariant structure' of coffee-making. That's a luxurious way of making coffee :) In the developing world, we still need to boil water, pour coffee powder in it, etc., all without a coffee-brewing machine.\", \"Authors should clarify the justification behind experimenting only on 'first 500 test images'.\", '- Lambda sim and lambda s are used interchangeably. Please make it consistent.', 'Fourth, there are some grammar mistakes and typos.', '-\\tFigures 1 is way too abstract given the complicated set-up of the proposed architecture.', 'The weight sharing was also needed further investigation and experimental data on sharing different parts.', 'However, the weakness is that the condition is opaque and it is not entirely clear how broad of class of problems this condition would apply to.', 'More precisely, for the digit datasets, the reviewer was interested to see how the proposed MDL performs on jointly adapting SVHN, MNIST, MNIST-M, and USPS or jointly adapting DSLR, Amazon, and Webcam for OFFICE dataset.', '1) The motivation is unclear and overall structure of the paper is confusing.', 'Furthermore, the usage of the evaluation method unclear as well, it seems to be designed for evaluating the effectiveness of different adversarial attacks in Figure 2.', 'However, it looks to me that the authors need to better explain the motivation of DiVA, the differences of DiVA from existing supervised VAE, and the experimental settings, before the acceptance of this paper.', '- No comparison has been made between their approach and other previous approaches.', 'Finally, the experimental results do not show any significant advantage over PGD, either in running time (they are slower) or norm perturbation.', 'The theoretical proof depends on the convexity assumption, I would also suggest comparing the proposed attack with CW and other benchmarks on some simple models that satisfy the assumptions.', 'I don’t think it is of any practical use to show that a new algorithm (such at DDGD) provide some defence compared to no defence.', 'Weaknesses: The dataset created here is entirely synthetic, and the paper only includes one single small real-world case; it seems like it would be easy to generate a larger and more varied real world dataset as well (possibly from the large literature of extant solved problems in workbooks).', \"1. The experiment uses a single run each of the baseline and DG-GAN, when it's well-known that GAN training runs\", 'Results on more scenes will make the performance more convincing.', \"Moreover, I  don't think that the data sets in experiments are good enough to cover the importance and the nature of the problem.\", '- The parameter count of a 2-layer network with $h$ hidden units and input dimension $d$ is $O(dh)$. So perhaps it makes sense to study an asymptotic regime where $dh/n$ approaches $\\\\gamma$, instead of both d and h growing linearly in n. While this issue is hinted at in the discussion section, I don\\'t understand the statement \"the mechanism that provably gives rise to double descent from previous works Hastie et al. (2019); Belkin et al. (2019) might not translate to optimizing two-layer neural networks.\"', 'I had trouble to understand some parts of this paper, since some of the sentences do not make sense to me. For example', 'Further, no proper convergence analysis of the proposed approach is provided and is desired due to the likely divergence in the optimization.', 'This seems like an unnecessary bottleneck in the model, and could partly explain the relatively poor quality of the results.', 'However, in its current state the work lacks sufficiently strong baselines to support the paper’s claims; thus, the merits of this approach cannot yet be properly assessed.', 'I think this is a very interesting direction, but the present paper is somewhat unclear.', 'The primary difficulty in reviewing this paper is the poor presentation of the paper.', '1) The only comparison to another non-fixed sampling baseline is Kool et al. 2019.', 'The drawback in this model here is that ultimately networks are embedded, but not really generated during test time.', 'In particular, the exact difference between the proposed method and the ES baseline is not as clear as it could be.', 'As previously mentioned in public comments on this forum, some points in the paper are not very clear; specifically regarding the loss function, the definition of \"edge-to-edge\" convolutions and generally the architectural choice related to the conditional GAN discriminator.', 'There is however a misunderstanding about the properties of the alt-az convolution that must be cleared up before this paper can be published.', 'For instance, the omission of a results discussion section or a conclusion are clearly not reader friendly.', '*It is not clear why the latent variables modelling the generative factors are defined using a Gaussian prior.', 'The proposed method PowerSGD is an extension of the method in Yuan et al. (extended to handle stochastic gradient and momentum).', \"The paper is well-written but the structure is a bit disconnected; most notably, I didn't see clearly how Section 2 and 3 fit together.\", 'One could understand the use of \"selection network\" as a way to automatically select a threshold of what to consider confident, however, in this case, the prediction of \"selection network\" should be thresholded at 0.5 (correct prediction or not), but the experiments use complex thresholds.', 'In Figure 6 there seem to be unnecessary discrepancies between the y-axis and colorbar of subplots (a) and (b), and keeping those more consistent would improve readability.', 'Overall, I am not sure what we could gain from this research direction.', 'The tasks are explicitly designed to exploit these additional parameters - so framing the synthetic experiments as, \"here are some simple functions for which we would need the additional parameters that we define\" makes sense; but arguing that Hartford et al. \"fail approximating rather simple functions\" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al. to fail (because it\\'s designed for a different setting).', 'However, the un-standard design of the LSTM models makes it unclear whether the comparisons are solid enough.', '2. Missed citation: MnasNet [2] also incorporates the cost of architectures in their search process.', 'The paper misses the key baseline in Bayesian optimisation using tree structure [1] which can perform the prediction under the tree-structure dependencies.', 'In the absence of citation or comparison with any of the prior work on multivariate statistical dependence testing, the current submission is not suitable for publication.', 'Regarding the experimental evaluation of the model rather confusing.', 'Then to state to which of these cases the results of the paper are applicable, allow for an improvement of the variance and at what additional computational cost (considering the cost of evaluating the discrete derivatives).', 'Moreover, in spite of the authors writing that their goal is “completely different” from [Lee at al 18a, Ma et al 18a], I found the two cited papers having a similar intent and approach to the problem, but a comparison is completely missing.', 'In terms of writing, the paper is a bit confusing in terms of motivations and notations.', 'I believe that\\'s what \"Pred (One Step)\" expresses, but it would maybe be generally helpful to be more precise about the notation', '- What is dt in Algorithm 1 description?', 'The connections of the proposed approach with existing literature should be better explained.', 'Without the comparison it’s not clear how much improvement this approach provides compared to existing work that perform stale updates.', 'The improved training procedures for MI estimation are of interest, however the hypothesis testing parts of the paper could still be improved.', 'I believe it will not be great, but I think for completeness, you should add such a baseline.', 'Also, I find the experiments done in section 3 and 4 are similar to previous works and even the conclusions are similar.', 'The experimental results are actually less impressive than what are claimed in contribution and conclusion.', \"While the authors are using an existing model, they shouldn't assume that the reader has read the paper describing that model.\", 'But there is no attempt to generalize the findings (e.g. new datasets not from original study, changing other parameters and then evaluating again if these techniques help etc.), not clear', 'Weaknesses: Not all model modifications are studied in all the algorithmic tasks.', '- The counter example at the bottom of page 2 is limited, in the sense that the oracle assumption seems highly non-realistic, casting doubt on the relevance of the argument.', '|_{y>0} x + b |_{y>0}  <— what is the purpose of the subscripts here? Why is this notation never introduced?', 'I think all claims about running time should be corroborated by controlled experiments.', 'However, there is no comparison against existing work.', 'Citations used for Gradcam are wrong -- Sundarajan et al., 2016 should be changed to Selvaraju et al., 2017.', 'The proposed diversity measuring metric is lacking both in terms of experimental proofs and intuitive motivations.', 'Although the concept of \"task\" is not explicitly defined in this paper, the authors seem to associate each task with a specific class.', 'It is important to place the contributions in this paper in context of these other works.', '2. I am not convinced this method is sufficiently new, given that there are other methods that try to directly reward visiting new states.', '- As said in the my main comments, I am not convinced by the use of the term Axiom. They are not use as building blocks, and are rather used as desirable properties for which the authors prove that only \"path methods\" can satisfy.', 'First, the technical contribution is lean. Neither the multi-agent learning or the hierarchical learning of the algorithm is novel.', 'If the novelty is in applying to continual learning and new datasets, it is not clear that this is sufficient.', 'Third, the comparison to baseline and “DeepSet” is not fair.', '3) The simulation is not convincing.', '- The importance mixing does not seem to provide a better performance and could therefore be shortened in the paper', 'It would have been very interesting to study the quality of interpolations on more models and datasets, and compare their generalization capabilities as well as the bias present in the different datasets.', 'So how importance of each component to the whole framework? I would ask for the ablation study/additional experiments of using each component.', \"However, the experimental results are weak in justifying the paper's claims.\", 'The paper is relatively well-written, although the description of the neural models can be improved.', \"-I'm not going to trudge through the proofs, because I don't think this is self-contained (and I'm clearly not an expert in the area).\", '- The 3rd line of lemma 1: epsilon1 -> epsilon_1', '- q_theta was introduced in Eq. (8) before it is defined in Eq. (11).', '(a) a comparison to other methods (outside the current framework) for sound separation', 'It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model.', 'The paper is not very self-contained, and I have to constantly go back to Lee et al. and Xu et al. in order to read through the paper.', '- Given the small size of the dataset, I would propose experimenting with non-neural approaches as well, which are also quite common in NLG.', 'Lemma 2.4, Point 1: The proof is confusing.', 'Furthermore, the experimental section does not compare to other forms of hierarchical approaches for MARL, and generally only provides a single comparison to PPO & MADDPG.', '3) The experiments are completely preliminary and not reasonable:', \"Similarly, I'd have expected baselines that included those models in the evaluation section showing the differences in performance between the newly proposed Transformer model for trees and previously used methods.\", 'I assume something similar to an a* algorithm was probably used for the passing task, but what about the maze navigation task?', '1. Where is L_da in Figure 2? In Figure 2, what’s the unlabelled data from which testing tasks are drawn? Is it from meta-test data training set?', 'This does not seem surprising to me, as in the unguided case, the constrative loss seems not strong enough to encourage the latent partitions to be different.', '(3) FGSM is a quite weak adversarial attack method, which makes evaluating adversarial robustness on FGSM may be misleading.', 'In addition, minimizing reconstruction error has already been used in low-rank approximation[3] and network pruning[4].', 'Due to the different objects used in the different datasets, some of the experiments have a smaller set of words.', 'I have some concerns regarding the presentation of the main objective and the lack of justification in certain parts of the methodology.', 'The author can perhaps consider the datasets used by Tsai et al. There are seven datasets, and they can all be modified to the setting of partially-observable multimodal data.', 'How do “we choose a specific number of assignments based on prediction probabilities”?', 'The idea of having a separate class for out-distribution is a very interesting idea but unfortunately previously explored.', 'I feel that this discussion devolved into a discussion, again, about normalization rather than the architectural differences in performance.', '(W7b) Likewise I wonder if we could just measure transfer more directly as well and why we need to go via these CFS sets', '- The baseline scores of Reg-SGAN and Reg-WGAN seem to be worse than those reported in Mescheder et al. (2018), which have inception scores above 6 according to Figure 6 of their paper.', '- the data sets used in the experiments are very small', 'How the case where two images have a very similar latent factor is avoided while generating pairs of images for the Siamese network?', '- As shown in the ablation study, the main contribution on the obtained results seems to be the use of stronger transformations than in MixMatch.', '-- The overall error model in this paper, which is borrowed from Roy et al. is quite restrictive as at it assumes that the queries to the frequency estimation data structure are coming from the same distribution as that given by f_i’s themselves.', 'For example, I don\\'t understand what does it mean in \"However, if training data is complete, ..... handle during missing data during test.\" Another example would be the last few paragraphs on page 4; they are very unclear.', 'The current experimental settings are not matched with the practice environment.', 'The advantage of this random encoding was to reduce the number of parameters for an embedding layer, but the results showed we gained much PPL from a 25% reduction in embedding size (Table 1).', 'This could have made the paper much stronger.', 'For example, one question is how often a single partial tree has multiple possible completions in the data.', 'As pointed out by R2, with depth there are a lot more number of possible ways in which one could carve out decision boundaries to separate data points, thus, it is not clear that the loose linear upper bound holds Specifically, as one might expect with depth it could be possible that linear capacity increase is a lower bound (I am not suggesting that it is, but that possibility should be considered and explained in the paper).', 'J_MLM is also not clear since x_i is never defined (I assume it is x_{i:i}).', 'o feedforward rather than recurrent network;', 'Three of these methods, i.e. Lime, GradCam, PDA, are not designed for producing contrastive explanations, so I am not sure to what extend this comparison is appropriate.', 'With regard to my first negative point above about the lack of discussions, it seems the analysis of Section 4 is disproportionate compared to other places.', 'Thus, I suggest the authors could show the space and time comparisons with the baseline methods to show effectiveness of the proposed method.', '- experiments are performed using a synthetic setup on a single data set, so it remains unclear if the algorithm would be successful in a real life scenario', 'Specifically the text in Section 3.3 that explains Algorithm 1 is a bit confusing.', 'The real data experiments (sections 4.2 and 4.3) are not very convincing, not only because of the very small size of N, but also because there is no comparison with the other approaches.', '- sigmoid belief networks: q is a Bayesian network where each conditional distribution is a logistic regression model.', '- It would be nice if more network architectures were analysed (such as VGG and DenseNets).', 'The proposed method adapt a previously presented hierarchical clustering method in the \"standard space\" (Griffiths et al., 2004) to an embedding space defined by a variational autoencoder model.', '4. From Figure 6 and Figure 8-11, it looks like the bandit is more or less on par with fixed exploration policies.', 'Additionally, the previously mentioned evaluation steps, i.e., using a fixed attention map as baseline for the evaluation and evaluating the correlation between FSM and accuracy may be informative to illustrate the advantages of the proposed approach.', '* Another vague concept that is used without clarification: it is argued that if the network implements something like the Approximate Number System, that shows that it can \"learn and utilize higher-level concepts than mere pattern matching\".', 'Overall, the proposed method is elegant; however, the presentation, the claim, and the experiments suffer from significant flaws.', 'So overall I have the feeling that the authors have not succeeded to evaluate the model’s power with these two experiments and we cannot draw any strong conclusions regarding the benefit of the proposed mixing approach.', 'Even though the proposed approach seems to have significant potential, the experimental', 'Both the results on the development set and on the test set should be reported for the validity of the experiments.', 'And the analysis of the \"dynamic range\" of the algorithim is missing.', 'However, I think the relative novelty of the paper does not meet ICLR standards, and it’s better suited as a whitepaper attached to an open dataset release.', 'Since positional encoding with Fourier transforms is well known, this seems like the relevant benchmark but it receives only a brief treatment.', 'Specifically, the policy update in Dreamer resembles that of SVG (Heess et al., 2015), which also backpropagates re-parameterized gradients through a value function and a transition model.', '1. What are the key limitations of AutoLoss ? Did we observe some undesirable behavior of the learned optimization schedule, especially when transfer between different datasets or different models ?', '1. The formulation uses REINFORCE, which is often known with high variance.', 'Furthermore, the claims of the model working for non-MCAR missingness are not substantiated by the experiments.', '- In Table 4, it is hard to compare DeepTwist with the other methods because activation quantization is not used.', 'Weakness: the presentation of the tables/bar charts in the experiment is a bit unclear.', 'The details of the approach is not entirely clear and no theoritcal results are provided to support the approach.', 'hence, there is no connection between the theoretical results on MDL generalization bound and the proposed method MULANN.', 'i.e., omniglot <-> omniglot-M. I wonder whether the proposed approach can still work in large domain shift such as omniglot to fashion-mnist etc.', 'This latter baseline is a zero-cost baseline as it is not even dependent on the method.', '2) How are the rules from in Eq (2)? i.e., how is \\\\beta_i selected for each i?', '2. First paragraph in related work is very unrelated to the current subject, please remove.', 'As pointed out in the weakness section, many design choices are not well motivated, and the effects of those designs are not well studied.', 'The connection between mutual information and generalization has been studied in several contexts [see, e.g., the references in this paper and https://arxiv.org/abs/1511.05219 https://arxiv.org/abs/1705.07809 https://arxiv.org/abs/1712.07196 https://arxiv.org/pdf/1605.02277.pdf https://arxiv.org/abs/1710.05233 https://arxiv.org/pdf/1706.00820.pdf ] and further exploration is desirable.', '* The architecture of the particular model is described very briefly, and at multiple points there’s an implication that this is an investigation of “deep learning models” more generally, even though those models may vary widely.', 'The experiments of this paper lack comparisons to certified verification', \"* CodeSLAM (best paper at CVPR'18) is referenced but there is no comparison with it, while a comparison on the EuRoC dataset should be possible.\", 'In the current form of evaluation, it is hard to say if there is any benefit of using the \"selection network\" that is the main novelty of the paper.', 'When it comes to experiments, constant epoch budget is also fairly well understood and the behavior in Figure 1 is not really surprising (as the eventual training performance gets worse with large batches).', '- The conclusions focus on the importance of section 3 and', 'An example of lack of mathematical rigor is equation 4 in which the same variable name is used to describe the weights before and after pruning, as if it was computer code instead of an equation.', 'As a final point; the hyper parameters that were tuned for the MNF, noisy K-FAC and KFLA baselines are not on common ground.', 'More importantly: (1) It does not show any advantage of replica exchange over standard dynamics; (2) It does not provide any quantitative insight for high-dimensional problems.', 'While the authors do report some interesting results, they do a poor job of motivating the proposed extensions.', 'The paragraph motivating the alt-az convolution on page 4 is not very clear, and some claims are questionable.', 'Particularly the \"fusion\" module remains extremely unclear.', \"2) The evaluation metrics used while borrowed from the language or IR fields doesn't seem to translate to UI design.\", 'I wonder why the authors didn’t compare or mention optimizers such as ADAM and ADAGRAD which adapt their parameters on-the-fly as well.', 'Con: not clear to me how strong and wide the implications are, beyond the analogies and the reinterpretation', 'In particular, the qualitative results are too limited and no quantitative evaluations is provided.', 'The model is not well motivated and the optimization algorithm is also not well described.', '5. Clarity: The first half of this paper was easy to follow and clear. The experimental section had a couple of areas that left me confused. In particular:', 'While the presentation is clear and the evaluation of the model is thorough, I am unsure of the significance of the proposed method.', '(2) The method is not well motivated.', 'o use of the Penn Treebank dataset only;', 'https://arxiv.org/abs/1802.05822', 'The experiments on SHREC17 show all three spherical methods under-performing other approaches.', 'In particular it is not applicable to learning e.g. sigmoid belief networks [Neal, 92] (with conditional Bernoulli units) and many other problems.', '- The shown inception scores are far from state-of-the-art.', '-The strategy proposed to provide weak-supervision to the model is too ad-hoc and it is not clear how to apply it in general applications', 'I think it is necessary to make it clearer how s_{post_read} and attn_copy are computed with the updated {h^i_t} and what u^i is expected to encode.', 'However image captioning datasets are not mentioned.', \"2. I might have missed it, but I couldn't find any motivation on why tanh is used as nonlinearity. Would the method work with relu?\", '- The technical contribution of the proposed method is not high, because the architecture space of neural network is similar to the prior works.', '- the problem assumptions are too simplistic and unrealistic (feature distributions of target and auxiliary data are identical), so it is questionable if the proposed algorithm has practical importance', 'The novelty of this method is minimal.', 'Overall, I think the novelty of the paper is very limited, as all the weight distortion algorithms in the paper can be formulated as the proximal function in proximal gradient descent.', '- Why does temporal correlation reduce the non-stationarity of the MARL problem?', '-The conclusions of the study were suggested by previous papers or are rather expected: adversarial transfer is not symmetric: Deep models less transferable than shallow ones, averaging gradient is better', 'For example, Narayanaswamy et al. [1] also propose to utilize labels to VAE.', 'https://arxiv.org/abs/1802.04942', '3. The key contribution of the paper that the authors could highlight better is that they do not add new hyper-parameters.', 'It does not seem sensible to drop X^{j}_{t-1} + \\\\eta_X \\\\cdot \\\\epsilon_X and attain a smaller value of the cost function at the same time.', '- Did the experiments on CIFAR-10 and ImageNet use the cosine learning rate schedule [1]? If or if not, either way, you should specify it in a revised version of this paper, e.g. did you use the cosine schedule in the first 120 steps to train the shared parameters W, did you use it in the retraining from scratch?', 'Since the results are far from state of the art, a clean and neat presentation of the theoretical advantages and contributions is crucial.', 'For example, it is curious to see how denoising Auto encoders would perform.', 'It would be helpful to have a brief paragraph describing this architecture, for readers not familiar with the referenced paper.', 'This is true throughout; as stated before it is not clear how many parameters and how much memory these methods need, which makes it impossible to compare.', 'The only set of experiments are comparisons on first 500 MNIST test images.', 'For example, the authors should at least say that the \"D\" in Figure 2. stands for delay, and the underline in Figure 4. indicates the bits that are not pruned.', 'I would imagine that even if an embedding X is a bit noisy, because not exactly equal to gamma(P) where P is the expression it represents, you could consider doing the propagation with gamma(G(X)).', 'My main concern with the paper is its limited applicability to robotic manipulation tasks with a clear divide between states of interest vs others.', 'It is also not clear to me why these problems are important.', '2. In experiments, the authors explored many existing methods on improving', 'However, their algorithm--while much less computationally expensive than true full-matrix adaptive preconditioning---is still far more expensive than the usual diagonal version.', 'The paper motivates the problem that we need to pick out an exploration sequence that optimizes learning progress, but then approximates it as simply measuring the return.', '-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher’18.', 'I recommend adjust the language to be more consistent throughout.', 'It gives technical details that could (in my opinion) get ignored, and I would clearly prefer to catch the main differences between the different models that being flooded by technical details.', 'However, it looks like authors only compared with VIB which is similar to the proposed method in terms of the objective function.', '- The CFS metric depends on a hyperparameter (the \"retention ratio\"), which here is arbitrarily set to 80% without any justification.', 'One drawback is that it is highly specific to language models.', 'The authors should try to find a real-world domain which can really demonstrate the effectiveness of the method.', 'Here, there is only a single (unconditioned) policy, and the different \"skills\" come from modifications of the environment -- the number of skills is tied to the number of environments.', '13. Reproducibility seems like it would be hard. There are a few parameters (meta-learning rates, meta-optimizers) that I could not find for example and there is a lot of complexity.', 'In summary, the paper presents what seems like an effective strategy for continual learning, by combining some existing methods together, but does not make it precise what the contributions are and the methodology/analysis make it hard to determine if the comparisons are fair or not.', 'But the only negative aspect is the basis competitor algorithms are very simple in nature without any form of learning and that are very old.', 'This is clearly interested in as far as solving this particular task but does not provide any general insights for the design of (MA)RL algorithms.', 'Due to several shortcomings of the paper, most important of which is on presentation of the paper, this manuscript requires a significant revision by the authors to reach the necessary standards for publication, moreover it would be helpful to clarify the modeling choices and consequences of these choices more clearly.', 'Dual-1 and Dual-5 are introduced without explanation.', 'First, the labeled data portion is fixed and is relatively high', '3. The paper is not nicely written or rather easy to follow.', 'Since the paper focuses explicitly on providing contrastive explanations for choosing a class A over another class B -- experiments on datasets which do not have real-images seem insufficient.', 'Hence the theoretical sample complexities contributed are not comparable to those of MIME.', 'The reviewer votes for rejection as the method has limited novelty.', 'Because of the above many discussions about discrete vs. continuous variables are missleading.', 'The two ideas (use of grids, and intra-life curiosity vs inter-life curiosity) should be independently investigated and put in context of past work.', '#9) I think that MNIST is almost a toy experiment, since the crucial component of the proposed method is the prior modeling with the GAN.', 'However, it’s noteworthy that embedding to a vector could be useful too if the embedding espace is representative of the entire history and the timing of the events.', 'As far as I understand, this involves only minor changes in the code since reasonable hyperparameters required for the convergence of Adam have been extensively studied.', '-- The analysis is relatively straightforward and boils down to bucketing the error and integration over the buckets.', 'In particular, the example in section 3.1 says that a noisy information bottleneck is introduced, but then says that the modified and unmodified models have \"training algorithms that are exactly equivalent.\" I think this example needs to be clarified.', 'Authors claim adding one layer of DeepSet layer to a PointNet becomes PointNetST, but I see this as a special DeepSet with a single transmission layer.', '3. How do PPO and SimPLe handle partial observability? Is it principled to apply them to partially-observable environments?', 'Overall, I do not feel the comparisons dramatically change the qualitative understanding the field has of the different optimizers and their tunability.', '-Something is a bit weird with the FGM results. While it is a weaker attack, a 0%/100% disparity between it and every other', 'First of all, only a small number of qualitative results are reported and, therefore, it is very difficult to assess the proposed method and draw any conclusion.', '-- While the overall claim of the paper in the introduction seems to be to speed up frequency estimation using machine learned advice, results are only given for the Zipfian distribution.', '- The definition of g should depend on only \\\\theta_k^I and \\\\hat{\\\\delta}_k^M, not \\\\theta_k^k.', 'The mode of language modeling evaluation presented here, without considering an actual language or speech processing task, provides limited insight w.r.t. its utility in actual applications.', 'In addition, the paper would also need to show that such a model does not generalize to a validation set of images.', '- The paper does not have a significant novel contribution, but rather extends GANs (improved-GAN mostly) with a manifold regularization, which has been explored in many other works Kumar et al. (2017) and Qi et al. (2018).', 'I feel the baseline in domain adaptation area is a bit limited.', 'Compressability is evaluated, but that was already present in the previous work.', 'First, larger data sets such as Wikitext-2 and Wikitext-103, and/or the billion-word benchmark, are needed to understand how well the approach works in practical LM settings.', '- How easy is it to train with K matrices? Did you have to change optimizer hyperparameter compared to existing baselines?', 'It should be better motivated why one should use the duality gap as an upper bound for the \"F-distance\".', 'Alternatively why not try using a factorization technique to reduce the rank and then see how well the method does for different ranks?', '- The setup for the learning to permute experiment is not as general as it would imply in the main text.', 'Thus we may only apply the proposed model on a few tasks with exactly known F.', 'It is highly recommended to provide the pseudocode of the proposed method.', 'If the authors claim that the proposed MaxConfidence attack method is more powerful than the MaxLoss based attacks, they should provide more comparisons between these methods.', '- Authors do not visualize the attention (as is common in previous work involving attention in e.g., NLP).', 'This appears to be very restrictive, since typically the values of time series j at time t-1 are typically depending say of those that time t-2, t-3 etc.', '2. Can you elaborate more on the metric for measuring the learning progress LP? Why does the myopic metric make sense in spite of the there being plateaus in the training curves?', 'The authors should clearly explain how to update \\\\phi when optimizing Eq 12.', '- How general is the proposed approach? How likely is it to generalize to other approaches such as Jigsaw (Doersch et al., 2015) and Exemplar (Dosovitskiy et al., 2016)? It would be good to comment on this.', 'It is limited, however, in the sense that it (only) measures auto-encoding capabilities: to what extent can the shape be reproduced given a sample point cloud from the given shape.', '- Consequently why did not you compare simple projected gradient method ?', 'For example, the proposed method does not achieve high \"privacy\" as \"noisy\" does.', 'Moreover, it is the prediction performance that matters to such task, but the authors remove the non-structure features from the compared methods.', '- I’d also like to see more extensive comparisons between FICM and ICM across different datasets, for example, Super Mario Bros. and the Atari games, instead of only comparing FICM against ICM on ViZDoom.', '* The biggest problem for me was the unconvincing results.', 'In the experiment there is no details on how you set the hyperparameters of CW and EAD.', '- Detailed experimental setups are missing.', 'However, what was not clear to me is how this reduces the non-stationarity of MARL.', 'something that is either deterministic, or a probabilistic result with a small', 'At a high level, the idea of imposing a mixture of gaussian structure in the feature space of a deep neural network classifier is not new.', 'The proposed approach should compared to other stronger methods such as graph convolution neural network/message passing neural networks/structure2vec.', 'The main problems come from the experiments, which I would ask for more things.', \"Lastly, if the authors are not planning to release the code, the implementation details section is a bit too high-level and does not contain enough details to reimplement the Author's technique.\", \"The authors also rely mostly on the FID metric, but do not show if and how there is improvement upon visual inspection of the generated images (i.e. is resolution improved, is fraction of images that look clearly 'unnatural' reduced etc.)\", \"It's hard to ascertain what exactly the contributions are, and how they might not be a straightforward consequence of prior work (for example, combining results from Bietti and Mairal; and generalization bounds for linear models).\", '- It would greatly benefit the reader if eq. 5 were expanded.', 'This makes the contribution of this paper in terms of the method', 'Second, I notice that compared to the result in Table 1, PGD attack can yield better results [1].', 'What is the minimum/maximum layers of a deep model? How much data is sufficient for a model to learn?', 'Given the title of the paper, it would have been nice if this paper explored more than just MNIST vs NotMNIST and SVHN vs CIFAR10, so that the readers can gain a better feel for when generative models will be able to detect outliers.', 'However, there are some key issues with the paper that are not clear.', 'While most (or all) of the paper is devoted to illustrate the effectiveness of the approach against *non-protected* ML. My only and biggest concern with this paper is that no defense mechanism has been tested against, and there are many in the literature. (see e.g. Diakonikolas et al ICML 2019).', \"If that's the goal, however, a more detailed error analysis would need to be included.\", 'E.g., in Table 1 and 2,  the best result of VAT (Miyato et al., 2017) is VAT+Ent, 13.15 for CIFAR-10 (4000 labels) and 4.28 for SVHN (1000 labels).', 'I would like to suggest to use the state-of-the-arts classifier for the principal task and to evaluate how much gain your method can get with the help of auxiliary tasks.', 'Overall, I find the paper a promising contribution. But until the authors provide a more thorough experimental evaluation, I hesitate to recommend acceptance.', '- the reasoning behind picking VGMM as the density estimator is not fully convincing and (dis)advantages of other candidate density estimators are almost not highlighted.', 'I would have expected the authors to at least elaborate on why the current framework is not suitable for the non-relaxed problem.', 'There exists more principled approaches for selecting out-distribution images that has not considered here like those based on uncertainty estimation or recently proposed direct out-distribution detectors.', \"I like the area of research the authors are looking into and I think it's an important application. However, the paper doesn't answer key questions about both the application and the models:\", 'I believe the results all relate to inference but it would be good to get an overview of the impact of training time as well.', 'The above papers are not cited in this paper.', '- How much does the image matter for the single-image data set?', \"But again, it's not super clear how the paper estimates this derivative.\", 'There are a few grammatical/spelling errors that need ironing out.', 'While it’s great that so much prior work was acknowledged, mentioning a paper once per paragraph is (usually) sufficient and increases readability.', '4. Missing experiments to validate nature of bounds: Bartlett et al. [3] performed extensive experiments to exhibit the correct scaling of the generalization bounds with the \"model complexity\" introduced upto numerical constants.', '- how to tune lambda? it is an important hyper-parameter, but it is set without a good principle, e.g., \"For SGD-APO, we used lambda = 0.001, while for SGDm-APO, we used lambda = 0.01\", \"while for RMSprop-APO, the best lambda was 0.0001', 'Is that also true in this domain?', 'My question is a bit philosophical: The only thing which I was concerned about when reading the paper is projection of the embeddings back to the d-dimensional space.', 'An example is presented in Figure 3 but is not expanded upon in the main text.', 'Also, to demonstrate the superiority of the proposed method an appropriate comparison against previous work is needed.', 'Minor comment: An interesting line of work is that of [3] which could be included in the discussion.', 'In Fig. 3 the author claim that the proposed method dominates the other methods in terms of privacy and utility but this is not correct.', 'This is a very strong initial assumption, I am not sure how likely this assumption would be satisfied.', 'However, the explanation of the strategy wasn’t very clear for me, and the authors didn’t frame it as a major contribution.', '-The experimental section do not clarify the benefits of the proposed approach.', 'However, the derivations about \\\\phi are missing.', \"2. While the primary motivation of the work is claimed to be 'mode collapse', it does not turn out from the submission what mode collapse is.\", 'Including at least one set of black box attacks is necessary to verify to what degree the vanishing gradient is the case here.', 'have you thought about how it would be possible to avoid this step and keep the original variable-size embeddings?', 'It would be useful to have a table, like the one on the last page, which clearly shows the baseline vs. the random-projection model, with some description of the results in the main body of the text.', 'The descriptions of the datasets used are not clear, e.g., the number of classes for each data.', 'Particularly, the authors mixed their observations up with the results of published works, making it hard to identify the contributions of this paper.', 'However, what the authors implicitly did was to perform variational inference for maximising their likelihood by introducing a variational distribution q(\\\\theta) = p(\\\\theta | g(x_n; \\\\psi).', 'Also, the sentence, \"We demonstrate the implementation and performance of our pipelined backpropagation in PyTorch on 2 GPUs using ResNet, achieving speedups of up to 1.8X over a 1-GPU baseline, with a small drop in inference accuracy.\", is confusing. If I use data parallelization, the gain should be also around 2.', 'There should be sufficient details for a reader to implement this model, thought there are some minor details missing regarding the experimental setup, which will be addressed below.', '2) The presentation is not professional, hard to follow and the submission overall looks very rushed:', 'While the model seems to perform well, the originality and the improvement w.r.t. baselines are somewhat limited.', 'The input and output types of each block in Figure 1. should be clearly stated.', 'Given there is no theoretical justification for the approximation, I believe the paper claims more than what it delivers and should change the presentation, so as not to claim that it is measuring and capturing learning progress to learn faster.', 'Better literature review to reflect the relevant previous video action recognitions, especially those on video compositional models.', '--The notation for the proposed parameters theta, theta’, phi, phi’ are not consistent with the notation in the intro section, where phi was used for the encoder and theta for the decoder.', 'There are a few typos throughout the paper such as:', 'The author never explains. E.g., link to NRMSE and PFC to the Table.', 'Although the paper proposes an interesting framework I would argue that it is a “green apple” in the sense that authors need to motivate the approach better and expand the contribution beyond solving a particular instance.', 'It’s not obvious to me that ME bias will provide a significant advantage in a one-shot or few-shot learning setting - i.e. how useful is having made a better initial guess (which is random amongst the unseen classes) after you gain some specific information about the target class? Perhaps the benefit is small relative to that of the one-shot or few-shot information gained - I think this needs to be quantified empirically.', '* In related work, no reference to previous work on \"statistical\" approaches to NN', 'Thus, it might be helpful to test the result on another dataset (e.g. WikiText).', 'So at the end, I am a bit puzzled. I really like the idea, but I have the feeling that this technique should have been developed for more complicated setting. Or maybe it is actually not working on more difficult combinatorial problem (and this is hidden in the paper).', \"Isn't this just restating the point made in the first sentence?\", '- The digression at the bottom of the first page about neural architecture search seem out of context and interrupts the flow of the introduction.', 'The Gamma approximation has no statistical guarantees, as stated explicitly in the HSIC testing paper of NeurIPS 2007.', '(5) Due to the mean policy approximation, does the mean policy depend on \\\\phi?', 'Although this extension seems to be easily derived using the contributions made at point 2.', \"4. How large is the training set of (T, P) pairs? I don't think this is mentioned in the paper.\", '4. Can the authors show concrete examples on how the attacks are generated?', 'Even with no data augmentation, and even with the original networks, membership can only be assessed with a 90% accuracy.', '- it is unclear and possibly could be better explained why one needs to concatenate the goals (what would change if we would not concatenate but estimate state densities rather than trajectories?)', 'It is difficult to judge the performance of the proposed model based on so small data set.', '(1) using codes and codebooks to compress weights; and', 'In my opinion, to support the above claim, shouldn’t the authors provide a similar table as Table 1, directly comparing the certified radii of the natural images and adversarial images?', 'Therefore, I am not convinced that the power-law form of the generalization error would hold when the experimental settings are marginally different (like when using the Adam optimizer or a VGG-like architecture).', '4. Comparison with past works.', 'How to understand this phenomenon? Does this mean that the distribution of the layer outputs will not change too much if the layer is deep enough?', '- Although disc can be easily estimated in the regression task (differently from d_A distance which is a special case of disc), there are no experimental results of the regression task even in the synthetic data.', '4. How sensitive are the results to the number of adaptive kernels in the layers.', 'Therefore, the paper cannot be qualified for ``meta domain adaptation’’ and has very limited novelty in terms of its contribution to meta-learning; however, the combination of domain adaptation and few-shot learning is fair.', 'However, the motivation and benefits of introducing a parent and child variational approximation are not discussed adequately.', '- there is no attempt to provide a theoretical insight into the performance of the algorithm', 'How do you guarantee that the representation learned by the neural network still obeys the property of Choquet integral? What is your loss or your algorithm?', 'Towards this, how does the computational complexity scale wrt to the connectedness?', 'Third, the datasets used in this paper are rather limited.', '- VAE, GAN: q is the generative model defined as a mapping of a standard multivariate normal distribution by a NN.', 'This shows itself in the results; i.e., the proposed algorithm is either negligibly performing better than GBDT or when  GBDT dependence removed, it performs worse. It seems to me', '- limited amount of new insight, which is limiting as new and better understanding of GANs and practical guidelines are arguably the main contribution of a work of this type', 'In that regard, I would like the authors to comment on the worst-case computational complexity of the numerical analysis for determining the volume of a preimage through multiple layers.', \"The first point would be: what's the meaning of synthetically generating training curves other than proving that transformer achieves good performance in modeling discrete distribution? Most practical problems would not have the same distribution as the previously gathered public dataset, thus the data is not representative, and synthetic training curves just does not make sence.\", \"The cited paper 'Learning an adaptive learning rate schedule' does not appear online.\", 'Since q_rel require one hot vector as input, how to sample the q_rel given the importance score and how backprob the gradient in this case?', 'Attacking CRBMs is highly relevant and should be included as a baseline.', 'However such problems are entirely missing in the results section.', 'Regarding contrastive explanations, experiments on datasets where distractor classes (y_probe) are present in addition to the class interest (y_true) seem important -- PASCAL VOC, COCO, etc.', '* the idea of smoothing gradients is not new', 'Also, G could be used to check whether you obtain the expected formula after 4 steps, which would be a more informative information than the L2 distance between the resulting embedding and the embedding of the final formula.', 'What is the relationship between $\\\\theta$ and $\\\\tilde\\\\theta$ exactly?', 'However, I believe the assumptions needed to show this point force the analysis to only characterize learning close to convergence.', 'The authors do not explicitly define continual learning, incremental learning, and catastrophic forgetting problem.', '4) There are several typos/grammar issues e.g. \"believed to occurs\", \"important parameters sections\", \"capacity that if efficiently allocated\", etc.).', 'A minor comment is that the mutual information I(., .) being a function of two variables suddenly became a function of a single variable in Eq. (1) and in the text which precedes it.', 'In terms of modeling, since the input into the prior network has finite possible discrete values, we do not need a fully connected network to generate $\\\\hat{\\\\mu}_c$ and $\\\\hat{\\\\sigma}_c$. Instead, we can directly optimize $\\\\hat{\\\\mu}_c$ and $\\\\hat{\\\\sigma}_c$ for each $c$ as parameters.', '*The strategy proposed to introduce weak-supervision is too ad-hoc.', 'However, as presented these ideas are poorly justified and careful comparisons against sensible baselines are missing.', '3) The paper only conducts comparison experiments with fixed-alpha baselines.', 'Moreover, comparison with some of the DA baselines (ADDA[1], DSN[2]) is missing.', '- While there seems to be a consistent improvement over TD3, this improvement is in some cases small (e,g. ants).', 'One main concern is, how general this approach would be? As it is a good extension for Neural LP, it is not clear that the framework of Neural LP is flexible or powerful enough in general.', 'It is unclear whether the data augmentation techniques is applied only at training time or also at test time.', 'The drawbacks  of the work include the following: (1) There is not much technical contribution.', 'The notations are overall confusing and not explained well.', \"Edit (leaving everything else unchanged for now): After reading R3's assessment, I agree with them that it's worrying that the Deterministic Meta-Dropout performs better than baseline MAML - maybe it's an effect of a larger number of parameters in the model?\", 'In summary, I find there is no novelty involved apart from combining the already existing SOTA model in disentangled feature learning (beta-VAE) and image generation (StackGAN).', 'Thus, it is hard to say whether the results are applicable in practice.', 'Given that, the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search.', 'The paper’s primary drawback is the restrictive setting under which the experiments are performed.', 'I think it needs to be made clearer how reconstruction error works as a measure of privacy.', 'Given that BERT is most robust against their manipulation, it would be good to see a more powerful recurrent model for comparison.', 'The paper also misses relevant citations of similar questions from the field of (probabilistic) matrix factorization and relational learning.', '2:    The authors should compare against several costs/algorithms (e.g. l_0 with OMP, l_1 with LARS, etc.), and across various N_0/sparsity penalties, and across several datasets.', 'The labels of figures are hard to read.', '3)\\tThe authors use a certain number of warmup steps to train the network weights without updating the architecture parameters to ensure that “the weights are sufficiently trained”. Can the authors discuss the choice on the number of warmup epochs?', 'How does the proposed method perform in more complicated tasks such as', '- The idea is a simple extension of existing work.', 'But the authors do not seem to describe how they chose the hyperparameters for the baselines algorithms.', 'Presumably, whether the benefit scales well will depend on the loss function - in any case, this warrants some analysis/discussion especially given that there are no experiments to test it.', 'Thus I believe that it would be better if you consider the same hyper parameter on all of these methods, e.g. the precision of the Gaussian prior.', \"It's hard for me to judge of the experimental results of section 5.3, given that there are no other\", '2. Is it reasonable to assume some constraints on how much data we can get from the blackbox generator?', 'The figures are almost useless, because the captions contain very little information.', 'The proposed dual-BCFW still contains a hyperparameter (eta) due to the need to introduce a convex subproblem, which makes its number of hyperparameters still the same to SGD.', 'The experimental results are not very convincing because many importance baselines are neglected.', 'As a minor note, were different feature extractors compared?', 'The paper offers some analysis, suggesting when each of the conditions occurs, upper bounds the smallest singular value of D A (where the example dependent diagonal matrix D incorporates the ReLU activation (shouldn’t this be more clearly introduced and notated?).', 'It is necessary to test it on datasets with much more fine classes and much-complicated hierarchy, e.g., ImageNet, MS COCO or their subsets, which have ideal class hierarchy structures.', 'Apart from combining these to existing ideas, what can be considered as an added novelty to improve the quality of the disentangled features?', 'How do we choose a proper beta, and will the algorithm be sensitive to beta?', '- The caption of Table 1 is a little vague. Please clearly state the meaning of the numbers in the table.', 'However, given that the achieved performance gains over the state-of-the-art are fairly small, it would be good to assess if the obtained improvements are statistically significant.', 'Finally, it is unclear how the authors have picked the best \\\\lambda parameter for their approach? On page 5 they state that they “pick the value that results in a good trade-off between high uncertainty estimates and high prediction accuracy.” Does this mean that you get to observe the performance in the test in order to select the appropriate value for \\\\lambda? If this is the case this is completely undesirable and is considered a bad practice.', '- Table 1: Not sure why there is only one model that employs beam search (with beam size = 2) among all the comparisons. It looks strange.', 'The explanation for underperforming on SVHM (page 7) may be valid, but you could easily prove it right or wrong by adding an option to SST for \"stratified SSL.\" Without this extra work, your claim is just a conjecture.', \"That's a very simple kind of question; more generally, I'd like to see more analysis of the new dataset.\", 'Apart from global vs. local, can the authors provide more examples of what sort of information this approach can disentangle? (Even for global vs. local, is there a transformation that can remove local information as opposed to global information?)', '3) The paper needs a thorough proof-reading. There are many grammar mistakes, typos, missing citations. For example,', 'Third, I don’t get what is plotted on different subplots.', 'But there are no comparisons between the proposed training method and previous related works.', 'For example, there are two \"the\" in the end of the third paragraph in Related Work.', 'It is not clear to me what the point of Sec. 5 is, given a trained model, one wants to figure out if an image was present in the training of the model.', '- From Figure 9, we see the certificate radii of the natural have at least two peaks. Though on average the certificate radii of the adversarial attacks is higher than that of the natural images, it is smaller than the right peak. Could the authors elaborate more of the results?', '- MAAC does not consistently outperform baselines, and it is not clear how the stated explanations about the difference in performance apply to other problems.', '10. Reading the baselines before the experiments is very confusing.', 'How do we take a limit of M -> ∞ ? Does k also go ∞?', 'On page 4, State update function, what is the meaning of variable \"Epsilon\" in the equation?', '- Section 1.1 presents results with too many details without introducing the problem.', \"Unlike Arora's original work, the assumptions they make on their subject material are not supported enough, as in their lack of explanation of why linear addition of two word embeddings should be a bad idea for composition of the embedding vectors of two syntactically related words, and why the corrective term produced by their method makes this a good idea.\", '3. It would be helpful to show the $\\\\gamma$ value on each experiment with different tasks.', '2) The writing is poor and hard to follow.', '2. table 2: Dynamic -> Adaptive?', '6. On CIFAR10 the results seem to be worse that other methods.', 'I’m also confused by the presentation of the results.', '* Comparison with other methods did not take into account a variety of hyperparameters.', 'Did the authors also examine the relationship between mutual information and generalization error for CIFAR data sets? Does it not make sense to examine this for all (most of) the setups considered in Table 4, 8, and 9.', 'Without an empirical example in a realistic setting, it is hard to judge whether the benefits of introducing an ME bias for better classification of new inputs belonging to new classes can outweigh the negatives via a potential increase in misclassification of those belonging to old classes.', 'methods. There are some scalable property verification methods that can give a', 'The proofs are quite dense and I was unable to verify them carefully.', 'The message of synthetic experiments would be stronger if more of them were available and if the comparison between LOE, TSTE, and OENN was made on more of them.', 'While I like the premise of the paper, I feel that it needs more work.', 'This is not to say that this way of doing things is wrong, but rather that it is misleading in the context of prior work.', '- The equation (1) should contain \\\\rho, not p.', 'The only new result seem to be Theorem 4.7 which is a natural extension to theorem 4.3 to zeroth-order methods.', '- Figures 1-4 are difficult to interpreted on a printed version.', 'They need to elaborate how their method overcomes these issues better.', 'In this simple model, can we not calculate the mutual information directly (i.e., without the bottleneck)?', '(1) My main problem with this paper is that the novel objective proposed by the authors in Eq. 7 is equivalent to the objective of WAEs appearing in Eq. 4 of [1] (up to a heuristic of applying logarithm to the divergence measure, which is not justified but meant to \"improve the balance between two terms\", see footnote 2), where the authors use the newly introduced Cramer-Wold divergence as a choice of the penalty term in Eq. 4 of [1].', 'The authors use numerous jargon words to describe the techniques studied (e.g. dragon penalty, gradient penalty, spectral normalization, Gaussian process regression in the bandit setting) but they do not explain them,', 'First, it doesn’t label the X axis.', \"- Gradient starvation, Kaggle experiment: I'm not too convinced about the novelty/usefulness of this result. In the end, even a decision tree stump would stop growing after learning the dark/light feature as a discriminator.\", 'However there are a few key weaknesses in my view, not least that the practical utility of these metrics is not obvious, since they require supervision in the target domain.', 'The authors explain how they trained their own model but there is no mention on how they trained benchmark models.', 'However, as the \"selection network\" uses exactly the same input as \"classification network\", it is hard to imagine how it can learn additional information.', 'Why these methods are not considered in the beginning? In my opinion, transformer is good for modeling long term dependency and concurrent predictions which is not necessarily the case for learning curves.', 'So, I have some doubts about the experimental results.', 'It would be nice to position the ideas from the paper w.r.t. this line of research too.', '- The term \"sketch\" is used in Algorithm1, like 10, before \\'sketch\\' is defined!!', \"- The authors haven't come up with a recommendation for a single configuration of their approach.\", 'Moreover, due to the trace based loss function, the computational cost will also be very high.', 'However, unlike as advertised, the paper does not address the domain shift issue in meta-learning, and the experiments lack thorough evaluation as the paper considers itself as a meta-learning paper and only compares to other meta-learning approaches without much comparison to domain adaptation papers.', '* Section 5.3 (Fig. 6) is the part most relevant to the generalisation problem.', 'Overall, this paper is good, but is not novel or important enough for acceptance.', \"I also had a hard time going through the paper - there aren't many details.\", 'Generalizing this to the multi-channel input as the next step could make the proof more accessible.', 'In addition, Procedure 1 is not referenced in the text which makes is hard to understand the utility of the same.', '- Although the authors discussed the experiment setting in detail in supplements, I believe open-sourcing the code / software used to conduct the experiments would be greatly help with the reproducibility of the proposed method for researchers or practitioners.', 'There are several weaknesses in this paper.', '1) The introduction makes it seem the generative replay is new, without citing approaches such as DGR (which are cited in the related work).', 'For the learnable data augmentation it would be great if the authors could provide more insight into the method, how it works, and why is it better than the alternatives.', 'The combination of these two methods seems straightforward.', 'In terms of the difference between vanilla SGD and SGD with momentum, Zhang et al. (2019) already argued that the difference depends on specific batch sizes and SGD with momentum only outperforms SGD in the curvature dominated regime.', '-\\tThe experimental results of section 5.2 are somewhat disappointing.', 'While I agree with the authors that it is generally desirable for a model to be more confident when predicting in MNIST (since it has already seen samples of it) compared to when predicting in notMNIST (completely different data), these plots tells us nothing regarding the predictive power of the model.', 'It would therefore be instructive to add experiments for ResNet to see how well the results generalize to other network architectures.', 'Is a simple algorithm enough? What algorithms should we ideally use in practice?', '- Lack of theoretical analysis. It could have been nice if the authors could show the observed phenomenon analytically on some simple distribution.', '- The paper should refer to 1) the reward shaping literature, 2) the growing line of works concerned with control variates for REINFORCE (such as VIMCO, MuProp, REBAR) and 3) the growing line of works concerned about combinatorial optimization with reinforcement learning (Neural Combinatorial Optimization with Reinforcement Learning, etc.)', 'I have doubts on applying the proposed method to higher dimensional inputs.', 'However, given that the datasets used in the experiments were not used in the associated benchmark papers, it is necessary for authors to explain how they trained competing models.', 'Then, there will be another question: how the two networks are trained? Are they trained separately or jointly?', 'Q2: Can the authors structure the experimental results with different sections? Currently it is just a single section which is difficult to read.', '- the notation q appeared in the middle part of page 3 before the definition of q is shown in the last paragraph of p.3.', 'Those seem to be quite limiting features of these methods, which is not to say that they are not useful in that realm, but only to clarify my understanding of their possible scope of application.', 'In the main text (up to Section 7), there is no mentioning of how the low-level controllers are learned, and how to combine PPO in a MARL partial parameter sharing setting.', 'The use of beta>1 is fine if it helps alongside the use of this approach, but it would have been better to see the effects of this approach and beta>1 (and other hyperparameters such as k in Table 1) in isolation.', 'I do not think that there is enough justification/demonstration for the fact that a general NN solution for Tabular Data invented.', 'The empirical evaluation is quite weak- one sparsity setting, two baselines, one dataset', 'If the goal is to learn representation for low-shot setting, the method needs to be compared with other representation learning methods such as jigsaw[1], colorization[2] and rotation[3].', '=> The results shown in Figure-4 (Section-4.2) seems unclear to me.', 'For example, it is unclear to me why some larger models are not amenable to truncation.', 'If the paper cannot compare various architecture, it is more convincing to at least use some standard architecture, like DCGAN. Or at least report the parameter tuning effort made for getting the results.', 'In such a situation, there are better strategies for higher-order tests of independence than estimating mutual information, in particular estimator that give a control p-value.', '-\\tTalking about depth parametrization use ‘basis’ or ‘bases’ not both and clearly defined the meaning of this important notion.', \"I'd encourage the authors to extend the intro and position the ideas w.r.t. existing works and extend the evaluation.\", '-\\tAttention should be given to the notation in formulas (3) and (4).', '- Contribution overall may be a bit limited', 'Some details are missing, which is hardly reproduced by the other researchers.', 'I don’t see a significant difference between RAN and DNN in Figure 5. Maybe more explanation or better visualization would help.', 'Since quantitative real-world results are challenging to obtain, improved presentation of the qualitative results would be helpful as well.', 'However, the experiments are overall not very useful to the comprehension of the paper and not that illustrative.', 'However, there is no comparison with ENAS and DARTS in experiments.', \"You have 3 datasets worth of data for the regression task (it is still unclear, however, what is being used for evaluation), but it doesn't look like this is addressed in the larger scale experiments at all.\", 'In Section 3, the authors compare the game scores of DeepCS proposed in this paper only against to A2C.', 'Many of the parameters here are also unclear and not properly defined/introduced.', '- (W5) Multi-task learning: I did not see any mention or experiments of what can be expected when the representations are themselves trained on multiple tasks.', '- I have trouble understanding the overall idea behind Algorithm 1 and Eq. (22).', '- Lack of an extensive exploration of datasets', 'I think this work would have much greater impact if the authors can show that the power-law form holds for a larger variety of architectures and optimizers thus allowing researchers to more confidently incorporate the results of this work into the design and training deep neural networks.', 'The idea that introduces labels in VAE is not novel.', 'It will be also interesting to see how does the proposed method perform on large-scale datasets such as DomainNet and Office-Home dataset:', 'No baseline comparison with GraphNets.', 'Especially given the very specific nature of the topic I miss a strong and clear path through the paper.', '2. The paper never clearly demonstrates the problem they are trying to solve (nor well differentiates it from the compressed sensing problem  or sample selection problem)', 'It is unknown the used model is a new model or existing model.', 'However, attack in Wasserstein distance and some other methods can also do so.', 'The rest experiments', 'I am also not entirely satisfied by using accuracy as the only metric; how about using something like beam search to build a \"soft\", secondary metric?', 'And finally, the discussion of this figure makes claims about the behaviour of the model that seems to be too strong to be based on a single image experiment.', 'If these networks can truly solve these problems, authors should report the success rate while varying the threshold, not individual accuracy of the items which can be arbitrarily high by violating constraints.', '10.\\tThe title suggests that the paper studies multiple VQA models but only a single model is studied.', '2.\\tThe experiments are rather insufficient.', '(4) The writing quality is not satisfactory.', '1. The paper should also talk about the details of ARNet and discuss the difference, as I assume they are the most related work', 'Do the same model is trained for multiple tasks? Is each of the tasks trained sequentially or simultaneously?', 'However, I found the contribution of the actor-critic model is insufficient and requires additional experimental validation (see below).', 'On the other hand, the obtained results are very weak: only one layered version of the paper is analysed and the theorem applies only to networks with less than some threshold of parameters.', 'Also, try using the consistent dimension for x throughout the paper, it confuses the reader.', 'However, it is not further discussed how the overall KL-based data similarity measure would help in this case since it seems likely that it would also exhibit the same issue.', 'Results are much lower in less favorable cases, sometimes close to random (see last line of Table 3).', '- (W3) Baselines for transfer learning: I felt this was another notable oversight.', 'Many more can be said in all the figures.', 'The idea is an interesting one, but', 'Also, I had to go through a large chunk of the paper before coming across the exact setup.', 'Section 4 seems to lack a high-level idea of what it want to prove -- the hypothesis around the volume term is dismissed shortly after, and it ultimately proves that we do not know what is the reason behind the high SVHN likelihood, making it look like a distracting side-experiment.', '- some parts of the paper are quite unclear', 'Theorem 1 does not take account for the above conditions.', 'These issues would maybe be excusable if not for the totally inadequate experimental validation.', 'This would be an effective baseline to compare. (Correct me if I am wrong here.)', '- for Figure 6, there is not a clear conclusion.', \"Also it's not clear from the details in the paper what are the architectures for the VAE and RFs (there's a reference to the code but would've been better to have sufficient details in the paper).\", 'Results and discussion about how the previous methods with full features perform compared to SASNet, and also how we can include those features into SASNet should complete the paper.', 'Ablation studies that show the proposed algorithm can improve upon the baseline in all settings would make this a stronger paper.', 'It is still not clear why self-modulation stabilizes the generator towards small conditioning values.', '1. What is M in Algorithm 1 ?', 'The proposed approach is very similar to the CE method by Rubinstein (as stated by the authors in the related work section), limiting the contributions of this paper.', 'At the conceptual level, the idea of jointly modeling local video events is not novel, and can date back to at least ten years ago in the paper “Learning realistic human actions from movies”, where the temporal pyramid matching was combined with the bag-of-visual-words framework to capture long-term temporal structure.', '- evaluated models (feed-forward NNs and LSTMs) are very basic and far from current SotA architectures', 'Also experiment figures are extremely compact. Try using log scale or other lines to make the gaps wider.', 'The main appeal is the idea of using T to model syntactic interactions, and the algorithm for learning T. Given that the main attraction of the paper is the potential for more performant word embeddings, I do not believe the work will have wide appeal to ICLR attendees, because no evidence is provided that the features from the learned tensor, say [a, b, T*a*b], are more useful in downstream applications than [a,b] (one experiment in sentiment analysis is tried in the supplementary material with no compelling difference shown).', '- The notion of divergence D(P|G) is not made concrete in section 3 and 3.1, which makes the notation of rather little use.', 'The main problem is that directly predicting the context is intractable because of combinatorial explosion.', \"I don't think Cakewalk is different enough from the cross-entropy method to warrant acceptance in ICLR.\", '(4) For the error-specific attack task, it would be better to provide an ablation experiment.', 'Clearly, replaying data accurately from all tasks will work well, but why is it harder to guard against the generative forgetting problem than the discriminative one?', 'However, I am unable to assess the technical novelty of this work as it seems to heavily rely on prior work which in turn use techniques from random matrix theory.', 'I am concerned though why the authors didn’t compare to adaptive optimizers such as ADAM and ADAGRAD and how the performance compares with population based training techniques.', '4. The scores achieved by the baseline are very far from state of the art, making the comparison mostly useless,', 'For example, in Table 2, the F-pooling only wins at either accuracy (marginally) or consistency, but not both.', 'Nevertheless, I believe that it still has to address some points in order to be better suited for publication:', 'My main concern comes from the novelty of this paper.', '4. Mean field analysis, although it lends an insight into the statistics of the activations, needs to connected with empirical observations.', 'In Section 3.2.2, the authors only explain how they learn example-based \\\\sigma, but details on how to make graph construction end-to-end trainable are missing.', '- The method is very confusingly presented and requires both knowledge of HAT as well as more than one reading to understand.', 'The introduction can start at a lower level (such as flat/hyperbolic neural networks).', 'I maintain my concerns that the experiments are limited and do not showcase the individual benefit of using explicit information placement.', 'For instance, using codes and codebooks to compress the weights has already been used in [1,2].', '2. Why were more baselines from the related work not included? I understand the experiments are a proof of concept, but it would be nice to get a feeling for what some of the other methods do.', '- All the variations considered for the behaviour policy performs only myopic exploration and thus provably inefficient in RL.', 'The paper should compare the proposed work to the InfoGAN work both quantitatively and qualitatively to justify its novelty.', '- Jointly learning an inference network (Q) has certainly been done before, and I am not sure authors provide an elaborate enough explanation of what is the difference with adversarially learned inference /  adversarial feature learning.', \"I understand why a human who needs to saccade back and forth between the two groups of objects might lose track of the objects that have been paired so far, but I don't understand why that would affect the architecture in question.\", 'All in all, the results show that the proposed method provides a significant speedup with respect to Shim et al., but it lacks comparison with other methods in the literature.', \"This reduces the paper to an empirical exercise rather than a true understanding of their method's advantages and limitations.\", 'Moreover, said the analysis is in my opinion not sufficiently rigorous, with hand-wavy arguments, no formal proof and unclear terms (e.g. how do you define near-optimal?)', 'It would be very interesting to contrast the proposed method with other previously proposed MF based method, in particular using Free energy to approximate the expectation of the model without constraints.', 'The contributions of the method could also be underlined more clearly in the abstract and introduction.', 'While it seems ok to estimate these different metrics using only linear models, my concern with this is that the linear models are only given a subset of the **exact** dimensions of the original representations.', 'Is the energy-based model particularly well-suited to the random-projection setup, or are there other reasons for using it, independent of the use of random projections?', 'Compared to using just a very simple dense reward (e.g. negative L2 distance between the robot and the object), what would be the advantage of using MI discriminator? It would be great to show the comparison between using simple dense reward and MI discriminator for each Push, Pick&Place, and Slide task.', '1 The implementation steps of the proposed method (MoVE) are not clear.', 'While this assumption seems plausible,  no analysis has been done to verify it in a systematic way.', 'The explanation in Fig 2 on why this is the case seem to me not so clear. Are you trying to show that the Wave-U-Net does not work since there is no 1/f^2 law for clean audio signals?', 'It is not clear how the noise is introduced in the graphs.', \"6. Did you consider using an inverse function (say G), that maps an embedding in L / L' back to S (i.e. the inverse function of gamma / gamma').\", 'in practice. For most of newly proposed graph embedding algorithms, it is hard to convince', 'First of all, the proposed SST algorithm alone only performs better than baselines in 1 case, equal to them in 1 case and worse in 1 (table 3).', 'Moreover, it seems strange that significant space was used to give equations describing simple embedding lookups (i.e., matrix multiplications with one-hot vectors), but the basic technical foundations of Transformers were not adequately explained.', 'Overall, I like the approach of the proposed method, especially tuning coefficient during training procedure although novelty in the theoretical analysis is somewhat limited.', '- Baseline missing: Simple RNN policies that communicate hidden states.', 'Repeated equations usually indicate that there is something new happening, but all of these are just restatements of your theta sin(omega tau + phi) term.', 'While the experiments across several domains convincingly show the presence of an anti-ME bias in neural network training, I recommend that the paper be rejected because it falls short in demonstrating to what extent performance could be improved by correcting or reversing this bias.', '- U^m in Eq 1 is undefined and un-discussed.', 'My concern for this paper is reproducibility.', 'The clarity of the presentation (in particular the description of when the method is applicable) and the technical correctness of the paper are somewhat lacking.', 'The language around skills and the extent of prior knowledge still downplays things a bit too much for my liking.', 'Given this, I wonder why all experiments are conducted on sets of two to five images, even for Kitti where standard evaluation protocols would demand predicting entire sequences.', 'A. You demonstrate the results on CIFAR-10 for 10% error rates which corresponds to networks which are far from what is currently used in deep learning.', 'There are many typos (see below).', 'Also, Table 1 is really confused. I would not understand the meaning if I am not familiar with the experiment settings.', '- One thing I am confused about is the residual model, which seems quite important for the pipeline but I cannot find details describing it and much analysis on this component.', 'I do not think this work is ready for publication.', '(W7) Alternatives to CFS / Computational concerns: A big concern I had was the computational expense of the proposed approach. Unfortunately I did not see any discussion about this in the paper or empirically.', '- Does training the generator and interpolation jointly improve the quality of the generator in general ? It would have been nice to run this method on more complicated dataset like CIFAR10 and see if this method increase the overall FID score.', '1a. Comparison to other exploration methods.', 'It’s also unclear if the proposed method is more memory efficient, since the authors only unroll 4 iterations of it.', 'Thus the experiment comparison is not really fair.', '* It is unclear to me whether the \"efficient method for SN in convolutional nets\" is more efficient than the power iteration algorithm employed in previous work, such as Miyato et al. 2018, which also used SN in conv nets with different strides.', 'My only issue here is that very little information was given about the size of the training sets. Did they use all the samples?', 'However, as the authors acknowledge the overall simplicity of the tasks being evaluated with mostly marginal improvements makes the overall evaluation fall short.', 'Besides having closed form in the case of a Gaussian prior (which other statistical distances could potentially also achieve), it would be nice to see some discussion of why the authors believe their CW-distance is conceptually superior to such alternatives.', '- What if the desired factors are not clearly disjoint and collectively exhaustive? (e.g. mustache vs. gender on human faces.)', 'Authors should scope the paper to the specific function family these networks can approximate.', '* Equations (1, 2): z and \\\\phi are not consistently boldfaced', 'The index over which the sum happens is n, but n is fixed? So this looks like a sum with just one component in it, namely the first n-gram.', '- It would be nice if different stopping criteria were analysed.', 'To change to a firm accept, I think the paper needs some changes in written style mainly, to make it friendlier to newcomers to the area, which can easily be implemented in the camera ready stage of paper preparation.', 'I would have expected to see some analysis and results on the translation quality over systematic noise applied to the input graph.', 'I was able to make them out, but perhaps separating the top row (FID and diversity graphs) into separate figures, separate lines, or something would have reduced some confusion.', \"The method presented is interesting; but it is not clear that it is present with enough detail for it's results to be replicated.\", 'Also, from the three Tables in the experimental part, the improvement of F-pooling over AA-pooling (developed by the main reference of this work) does not seem to be significant or consistent.', 'The testbeds all existed previously and this is mostly the effort of pulling then together.', 'As the authors admit, the main result is not especially surprising.', 'The IDF scores would be stronger if they were computed on a bigger in-domain corpus than the gold test set.', 'The authors need to describe in detail the algorithmic novelty of their work.', '- novelty is low: the proposed algorithm is a heuristic similar to previously proposed algorithms in the transfer learning and auxiliary learning space', 'These points remain me puzzled regarding either practical or theoretical application of the result. It would be great if authors could elaborate.', 'The empirical evaluation is limited in considering only one task (clique finding), and the results seem to be quite sensitive to the chosen optimizer.', 'The results are not strong. And, unfortunately, the model contribution currently is too modest.', '- The writing looks very rushed, and should be improved.', 'Thus I believe authors must compare their method with these state-of-the-art approaches.', \"3. Shouldn't random indexing produce non-uniform numbers of non-zero entries depending on alpha? Why did you have an exact number of non-zero entries, s, in the experiments?\", 'Apart from the assumption H1 of linear separability of the data (which I don\\'t mind), the results require very strong assumptions, in particular hypothesis H2 stating \"at the beginning of training data points from different classes do not activate the same neurons\".', '“From a high-level perspective both of these approaches” --> missing comma after “perspective”', 'Although the idea behind this paper is fairly simple, the paper is very difficult to understand.', '3. The graph neural networks used in the model are not described in the paper, only a reference to Paliwal et al (2019) is given.', 'More importantly, the results presented are quite meager.', 'These regimes are fairly well covered by previous works (e.g. Belkin et al as well as others).', '\\\\alpha^i_t and u^i are also pretty complex and it would be good to conduct some ablation analysis.', 'this analysis is not currently included in the main body of the manuscript, but rather in the appendix, which I find rather annoying.', \"In section 4.1 the authors have a good discussion on what is wrong with other methods in order to motivate their approach but then they don't deliver significant evidence in the later part of the section.\", 'In the start of Section 3, it is not clear why having the projection be sparse is desired.', 'My biggest concern in the methodology, however, has to do with the selection of the matrix variate normal prior for the weights and the imposition of diagonal covariances (diag(a) and diag(b)).', '- There are two lines of text between Fig. 4 and Fig. 5, which is confusing.', 'The paper is also littered with typos and vague statements (many enumerated below under *small issues*).', 'While the black-box calibration of a GAN model may be attractive under specific settings, the authors did not consider the restrictions under those situations and their design may be hard to implement as a result.', \"Also, the plus-one smoothing handles unknown words (or word piece?) and I'm not sure why. If we're using the test set to compute IDF, and the sentences we're looking *are* in the test set, then there shouldn't be unknown words and no smoothing is required.\", 'Some figures, like Figure 3 and 4, are hard to read.', 'In terms of learning rate scaling, this paper gets similar conclusions as Shallue et al. (2018).', 'Second, the caption mentions that early stopping is beneficial for the proposed method, but I can’t see it from the figure.', '- The experiments seem very similar to Wu et al. 2018, which is considered to be prior work under the ICLR guidelines.', '-\\tWhile this is a new and interesting task, the contribution (as discussed above in “pros” above) is somewhat limited.', 'Last comment is that, although the concept of `deficiency` in a bottleneck setting is novel, the similar idea for tighter bound of log likelihood has already been pursed in the following paper:', '- The authors report only negative results for the fully-unsupervised version of UD-GAN The paper lacks and in-depth discussion about why this negative result is interesting.', 'The WGAN framework is built upon a loss that can be optimized, and should be optimized, until convergence (the discriminator loss is non-saturating) -- not the reverse (more G steps than D steps) as suggested here.', 'Here again, the article moves from technical details (e.g \"hidden state of the first token (assumed to be a special start of sentence symbol \") without providing formal definitions.', '6, the experimental design of Sec. 4.2 is also a bit unfair.', '2) Does the proposed method store immediate activations or recompute the activations in the backward pass?', 'Given the paper title, the reviewer would have expected more experiments in a multiple domain context.', 'The authors do not focus (in the main paper) on GAN variants used currently, and it is not clear if the proposed approach provides improvement relative to the current state of the art implementations (see next paragraph)', '- Can this approach learn multiple factors as opposed to just two?', '1) I do not really understand the emphasis on optimisation while all the proofs are related to the convergence to the stationary distributions.', 'The main theorem of this paper is an extension of existing methods, so the novelty of theoretical analysis is somewhat limited.', 'How does the transformer based method comparing to others?', '(2) The function of the discriminator is not very clear, especially for the classification error test.', 'The idea in this paper is novel but experiments do not seem to be enough.', 'Since finding an adversarial with smaller perturbation is a harder problem, it is unclear how the algorithms compare for finding adversarial examples with similar distortion.', 'It would make sense to use image captioning data to create the image lookup.', 'However, the novelty is rather limited as similar ideas have been undertaken (e.g., Mescheder et al 2018), but in different contexts.', 'It also adds capacity and it is not at all made clear whether the comparison is fair since no analysis on number of parameters are shown.', '1. The regularization techniques in reproducing kernel Hilbert space (RKHS) has', 'While, the paper is a plaisant read, I find difficult to access its importance and the applicability of the ideas presented beyond the analogy with the capacity computation. Perhaps other referee will have a clearer opinion.', 'I think these issues are against the goal of evaluating standard neural models on the benchmark and will raise doubts about the comparison between different models.', 'The imagenet experiment lacks details.', 'They are an exercise in applying standard formalism to this problem, without really showing any significative advantage of replica exchange.', '2. It is hard to understand what the model has learned compared to hand-crafted schedule. Are there any analysis other than the results alone?', 'The idea of using a constrained formulation is not novel either (constrained MDPs have been thoroughly studied since Altman (1999)).', 'However, only 1 dataset pair is experimented -- there should be more to ensure the findings generalize, since Sections 3 and 4 rely completely on empirical analysis.', '#3) There are several Equations that can be combined, such that to save enough white space in order to discuss further some actual technical details.', 'Overall it would be helpful for reproducibility if authors can visualize all the layers of all the different parts of the network as it is commonly done in the DL papers.', 'In general, I feel this section could use some tighter formalism and justifications.', 'However, there are a few, though not many, works in the literature trying to combine Choquet integral with deep learning.', 'However, memory overhead is still an issue compared to existing method.', 'It seems there is no conclusion to take away from the experiments in section 5 (convolutions).', 'In particular, the node-level pretraining described in section 3.1.1. seems rather complicated to implement as a context graph needs to be computed for each node in the graph.', 'Finally, the CNN architecture should be compared with modern SAT solvers which have been participating to SAT competitions.', '- Some of the datasets the authors currently test on are quite toy, especially for the image-based MNIST and SVHN datasets.', 'Yeh, Raymond A., et al. \"Image Restoration with Deep Generative Models.\" 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018.', \"Indeed, in VAEs, the prior does not have to be Gaussian, and as long as the density of the prior can be evaluated, we can efficiently optimize the ELBO without sampling the prior; which I don't think is the case for the Cramer-Wold autoencoder.\", 'My biggest concern is the lack of comparison with other representation learning methods, which is a very well studied problem.', '3. [Presentation.] The presentation is undesirable. It may make the readers hard to follow the paper.', '2. As to the results of the Pose2Pose network, I wonder if there are some artifacts that will affect the performance of the Pose2Frame network.', 'Yet, in Fig.1 some difference is observed between the methods, why is that so?', 'Is it because the ML solution would be faster to compute with big instances? Is it because with the proposed approach one can curate sophisticated heuristic solutions when provable optimality is out of reach?', 'There are many typos and grammar errors', 'If this is a method for image recognition, it would be better to present results for a more substantial image recognition problem than MNIST and CIFAR-10.', 'The main reason is that from the narration, I cannot figure out what is the idea or technique of other works and what is the contribution of this paper.', 'This second part is indeed what is used in the proof of the universality of the permutation invariant version of DeepSets, making the connection more visible.', 'Given that previous works [1,2,3] have successfully addressed this problem using a completely unsupervised approach, it would be necessary to give more insights about: (i) why the proposed method is failing (ii) why this negative result is interesting and (iii) if the method could be useful in other potential scenarios.', 'If I were to go through the computation of then why not just train a smaller version of that representation technique instead and **directly** see how well it can encode data in k dimensions via that technique / for that task?', 'The authors could run each WAE training process K times (with random initialization) to see if the closed-form distance enables more stable results.', 'Since the novelty of this work lies in the introduction of the CW distance, I would like to see an independent evaluation of this distance as a  general statistical distance measure (independently of its use in CWAE).', 'Finally, the paper needs to compare its parameter-reduction approaches against other compression and hyperparameter optimization techniques.', 'There is in fact no experimental evidence that the practical advantages of BN are relevant to the results proven.', 'All of the testbeds have been used previously.', 'Specifically, there is some confusion about estimation of w~, which seems based on frequency estimation from past SGD iterations (Eq 3).', 'I do not see much insight into the problem.', '- What is the choice of beta in the beta-VAE training objective?', '*The experimental section is too limited.', '=> Environment: The experimental section of the paper can be further improved.', 'I believe in the second paragraph of 4.1 the authors provide some insight into this matter, however, I have to admit I do not understand this paragraph:', '- in 3.1 towards the end of the first paragraph, what is a \"study\", is that the same as experiment or something different?', 'From this viewpoint, the actor-critic component in Dreamer is an incremental contribution.', '- Page 7 offers a result (expression for the Dirichlet form), which is hardly more than an exercise for anybody familiar with Markov Chains theory.', 'If faster training of dictionary learning models was a bottleneck in practical applications, this might be of interest, but it is not.', 'It seems to me just a combination of several mature techniques.', '- The interchangeable use of the term \"conductance of neuron j\" for equations 2 and 3 is confusing.', 'Therefore, an interesting baseline for the evaluation of the ICL approach would be a predefined, fixed attention map consisting of concentric circles with the image center as their center, to show that the proposed approach does more than just deemphasizing the corners of the image)', '- Lack of clarity in the following passage: “In our setting, each point xi in the point cloud can be considered to correspond to single images when we train GANs over images”', '- the authors fix the number of layers of the used network based on \"our experience\". For the sake of completeness, more experiments in this area would be nice.', 'My concern is, given this is an empirical work,  the number of datasets used in evolution is a bit small.', 'I find the observations interesting, but the contribution is empirical and not entirely new. It would be nice if there were some theoretical results to back up the observations.', 'Plugging this distance into the WAE produces similar performance to existing WAE variants, but does not really advance the existing achievable performance.', 'This paper should be rejected because proposed method demonstrates that an instance of one class of problems, Fractional Adwords, can be learned to solve without domain expertise, however fails to prove that the approach would be beneficial for any other instances of the same problem.', 'Three datasets cannot make the experiments convincing.', '- (top of p. 2) \"encourage parameter sharing\" - between what and what? at which level? [reading on, I realized this applies to groups of features; it should maybe be made clear earlier]', 'Clarification regarding lemma 1: it seems that if the true posterior cannot be expressed by q, a gap will necessarily remain, even in the “limit” of perfect learning. Is this correct?', 'Do they here refer to the gradients with respect to the weights ONLY?', '- The evaluation of the proposed method is not complete.', \"While the paper shows experimentally that they aren't as successful as the RFs or IDFs, there's no further discussion on the reasons for poor performance.\", 'Without a proper comparison (formal and experimental) with these lines of work, the paper is incomplete.', 'Why not compare results to WGAN-GP in this case? Since the proposal of GANs, many papers addressed the mode collapse problem.', '- Text on experiment figures is much too small.', 'The model-based method achieves better validation error than the other baselines that use actual data.', 'Originality: The work is moderately original.', 'Did you try to have a single network?', 'Ultimately this paper is interesting but falls well below the standards of exposition that I expect from a theory paper and doesn’t go very far at connecting the analysis back to the claimed motivation of investigating practical invariances. If the authors significantly improve the quality of the draft, I’ll be happy to revisit it and re-evaluate my score.', 'Section 2.2 mentioned how different kind of layers would help with the encoder’s utility and privacy. It would be better to back up the argument with some experiments.', 'In addition, it could be worthwhile to compare and benchmark on existing evaluations: https://arxiv.org/pdf/1802.06806.pdf', 'Second, and more importantly, the experiments need to be re-done to better measure the practical impact of the techniques.', 'Furthermore, there are several similar ideas already published, so comparison against those (for example by J. Peng, N. Heess or J. Mere) either as argument or even better as experiment, would be helpful to evaluate the quality of the proposed hierarchy.', 'It also shows itself in the results that final algorithm is almost indistinguishable from GBDT regarding results.', 'However, there are significant limitations in demonstrating the effectiveness/impact of the proposed technique:', '3)\\tSome discussion on why the “SASNet ensemble” would yield better performance would be good; could it be overfitting?', 'This matters, because the notion of equivariance really only makes sense for a group.', '- This paper is a slightly difficult read - not because of the', 'Once a low-level walking controller is trained, the high-level multi-agent navigation control is not much different from simple environments, e.g. point mass control, used in the previous works.', 'Given that you observed that SVHN has higher likelihood on all three model types (PixelCNN, VAE, Glow), why investigate a component specific to just flow-based models (the volume term)?', 'Hence, the effectiveness and advantage of the proposed methods are not clear.', 'Minimizing the F-distance as is usually done seems like the more direct and simple approach.', 'Additionally, in section 6.4, the results in Figure 2 also does not look very', '(1) The experimental results cannot show the usefulness of the proposed GCN.', 'For example using LASSO / LARS like methods you can perhaps figure out a good reduced dimension set more efficiently.', 'The method has intuitive appeal and the experimental results are suggestive, but the experiments do not conclusively show that the method achieves something that ordinary machine learning does not.', 'https://openreview.net/references/pdf?id=Sy2fzU9gl', 'Since this paper is an application paper, rather than a theoretical paper that bears theoretical findings, I would expect much more thorough experimental setup and analysis.', '1. Can you clarify why the proposed approach is better than the Meta-RevGrad baseline?', 'In addition, I observe that in Table 1, the proposed method does not outperform the Joint Training in SVHN with A_10.', \"- (W6) Motivation for CFS: I still don't fully understand the need to understand the density of the representation (especially in the manner proposed in the paper). Why is this an important problem? Perhaps expanding on this would be helpful\", 'Besides, as the base classifier is different for various baselines, it is hard to compare the methods.', '1- Why not use a single Boltzmann machine with 128 fully connected latent variables? Could you add this experiment please.', '- It is unclear why the results on WikiSQL is presented in Appendix. Combining the results on both datasets in the experiments section would be more convincing.', '2.\\tData size is too small, and the baselines', '- The equation (1) should hold for any \\\\theta’, not \\\\theta.', 'In my view, they do not even show that the distribution of atom usage will be better with their algorithm after the learning has converged, as at least according to their learning curves, the baselines have not finished converging.', \"The authors discuss their results on k-medoids in the appendices, but it seems like these results aren't quite complete yet.\", \"I'm not sure I understand the PCA figures. Can you please explain how the first principal component was used to generate them?\", 'Can one walk the latent distribution of the algorithm agent and draw insights, which might lead into tailoring some algorithms that would be appropriate for some input distribution although in general inferior in terms of worst case guarantees?', '- (top of p. 2) What exactly is the difference between \"implicit feature combinations\" and \"explicit (?), expressive feature combinations\"', '3. Technical contribution: While the authors propose the first bounds for LSTMs and MGUs, most of the analysis seems to be a marginal contribution over the work of Bartlett et al. [3]', 'Equation (4). What is d_{k,l}? A pixel-wise target label? Where does it come from?', 'This paper fails to account for a vast amount of literature on modeling natural images that predates the post-AlexNet deep-learning era.', 'The reviewer is also interested to see how the the generalization bound introduced in this paper is related to the recent theoretical works [3],[4] on MDL.', 'The gain of using a sufficiently more complicated approach to assess the overall distance between the test and training dataset is not clear, comparing it to the very insightful histograms.', 'If this solution can be proven to improve a valuable metric (e.g. accuracy, interpretability, theoretical understanding, or computational efficiency) of a setup, it is then worthwhile being published.', 'Furthermore PTB is not a \"challenging\" LM benchmark.', 'However I find the white-box experiments lacking as almost every method has 100% success rate.', 'Perhaps I missed it, but I believe Dan Ciresan\\'s paper \"Multi-Column Deep Neural Networks for Image Classification\" should be cited.', 'How big is the generalization gap for the tested models when adaptive kernel is used?', 'My main concern about the paper is that, currently, the experiments do not include any strong baseline (the ES currently is not a strong baseline, see comments below).', 'Authors acknowledge the fact that their experimental setup is rather limited in Appendix C.1, which I agree with and they also claim that there is a representation for a uniform algorithm for any number of advertisers for the AdWords problem, however they leave this as a future work, which I find unfortunate. I would recommend taking this direction rigorously and expand the contribution, which would prove to be a very sound contribution.', 'I must probably be missing something, and I encourage the authors to clarify what the main novelties are when compared to the several papers by Dupuis & al.', 'The authors could provide a similar evaluation for their method by using the feature representations learned by the siamese networks in order to evaluate how much information they convey about real factors of variation.', 'It looks like neither the experiments nor Theorem 3.2 show any benefit to PowerSGDM over PowerSGD.', '- White-box attack experiments don’t really prove the strength of the method, even with imagenet experiments, as almost all attacks get 100% success rate making it hard to compare.', 'The method description was a bit confusing and unclear to me.', 'Similarly, the paper mentions that the \"general approach to solving these combinatorial optimization problems is to recognize the atomic unit necessary to solve the problem\", but at that point the reader has no concrete example of what combinatorial optimization problem would be mapped onto training and inference in RBMS.', 'Many of the results have been already presented in', 'The MNIST is a relatively simple experiment, and I would like to see how the method works in more challenging problems.', '* There is still no comparison with competing nonparametric tests on the fMRI data.', 'It is unclear how well the proposed method works in general.', '- About line 10 in Algorithm 1, how does the proposed method update the population P? Please elaborate on this procedure.', 'Comparing to this approach, I wonder if it would be better to provide samples that exhibit a particular factor, or samples that conceal the factor?', 'In the current experiments there is a comparison only with CO algorithm and SGDA.', \"A clearer explanation of the theory here would help, as I think Fourier's theorem nicely supports your claims.\", \"Moreover, I don't think some of the presented experiments are necessary.\", 'The combination of ideas is ok, however, it is unclear how novel or how good is the proposed MF training of the RBMs.', 'Some baseline DA methods [A, B] and datasets [C, D] are not considered.', 'However, it is unclear how a similar strategy could be applied if we are interested in learning variables with higher-level semantics such as the expression of a face or its pose.']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts)/1811)\n",
    "print(len(val_texts))\n",
    "print(len(test_texts)/1811)\n",
    "\n",
    "print(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "dict(train_encodings),\n",
    "train_labels\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "dict(val_encodings),\n",
    "val_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=7)\n",
    " \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\carme\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\carme\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "49/90 [===============>..............] - ETA: 3:17 - loss: 1.6151 - accuracy: 0.4260"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    " \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    " \n",
    "model.fit(\n",
    "    train_dataset.shuffle(1000).batch(16),\n",
    "    epochs=2,\n",
    "    batch_size=16,\n",
    "    validation_data=val_dataset.shuffle(1000).batch(16),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.04943598 -0.03148741  0.01636142  0.07095795  0.02438408  0.07774305\n",
      "   0.05042113]], shape=(1, 7), dtype=float32)\n",
      "🤖Predicted Category: Replicability\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "predict_input = tokenizer.encode(val_texts[2],\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\")\n",
    " \n",
    "output = model(predict_input)[0]\n",
    "print(output)\n",
    " \n",
    "prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    " \n",
    "# Convert numeric prediction to category label\n",
    "if prediction_value == 0:\n",
    "    prediction_label = \"Other\"\n",
    "elif prediction_value == 1:\n",
    "    prediction_label = \"Clarity\"\n",
    "elif prediction_value == 2:\n",
    "    prediction_label = \"Comparison\"\n",
    "elif prediction_value == 3:\n",
    "    prediction_label = \"Motivation\"\n",
    "elif prediction_value == 4:\n",
    "    prediction_label = \"Orginality\"\n",
    "elif prediction_value == 5:\n",
    "    prediction_label = \"Replicability\"\n",
    "else:\n",
    "    prediction_label = \"Substance\" \n",
    " \n",
    "print(\"🤖Predicted Category:\", prediction_label)\n",
    "print(val_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    predict_input = tokenizer.encode(text,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\")\n",
    "    output = model(predict_input)[0]\n",
    "    prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    "    return prediction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 0, 6, 6, 4, 4, 5, 6, 6, 2, 6, 5, 1, 5]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "0 true:  6\n",
      "6 true:  2\n",
      "5 true:  4\n",
      "5 true:  5\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  0\n",
      "3 true:  6\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "3 true:  5\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "0 true:  6\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  0\n",
      "5 true:  4\n",
      "5 true:  5\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "0 true:  6\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  2\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "6 true:  1\n",
      "5 true:  2\n",
      "5 true:  0\n",
      "5 true:  4\n",
      "5 true:  3\n",
      "3 true:  6\n",
      "5 true:  5\n",
      "3 true:  2\n",
      "5 true:  2\n",
      "5 true:  3\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "3 true:  4\n",
      "5 true:  6\n",
      "4 true:  1\n",
      "0 true:  5\n",
      "3 true:  1\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "3 true:  1\n",
      "4 true:  1\n",
      "5 true:  6\n",
      "3 true:  1\n",
      "5 true:  1\n",
      "3 true:  3\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  1\n",
      "0 true:  1\n",
      "6 true:  3\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "3 true:  2\n",
      "3 true:  6\n",
      "6 true:  6\n",
      "3 true:  6\n",
      "3 true:  2\n",
      "5 true:  4\n",
      "5 true:  5\n",
      "3 true:  1\n",
      "0 true:  6\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  4\n",
      "5 true:  1\n",
      "5 true:  5\n",
      "3 true:  1\n",
      "3 true:  5\n",
      "5 true:  6\n",
      "3 true:  1\n",
      "3 true:  2\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "0 true:  1\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "0 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "3 true:  3\n",
      "0 true:  2\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "0 true:  5\n",
      "3 true:  1\n",
      "5 true:  4\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "0 true:  4\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "4 true:  5\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "3 true:  3\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "3 true:  1\n",
      "3 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  5\n",
      "5 true:  2\n",
      "3 true:  4\n",
      "3 true:  1\n",
      "3 true:  2\n",
      "6 true:  6\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "3 true:  5\n",
      "5 true:  4\n",
      "0 true:  6\n",
      "3 true:  2\n",
      "5 true:  3\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "0 true:  5\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "3 true:  4\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "0 true:  4\n",
      "5 true:  6\n",
      "5 true:  3\n",
      "0 true:  2\n",
      "5 true:  6\n",
      "5 true:  0\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "4 true:  1\n",
      "5 true:  5\n",
      "5 true:  5\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "3 true:  4\n",
      "5 true:  1\n",
      "3 true:  1\n",
      "0 true:  6\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "3 true:  3\n",
      "5 true:  1\n",
      "5 true:  2\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "3 true:  6\n",
      "5 true:  1\n",
      "5 true:  5\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "0 true:  1\n",
      "0 true:  1\n",
      "5 true:  6\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  3\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  0\n",
      "3 true:  5\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "3 true:  1\n",
      "0 true:  1\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "3 true:  4\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "6 true:  6\n",
      "3 true:  2\n",
      "0 true:  6\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "6 true:  1\n",
      "3 true:  1\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  3\n",
      "5 true:  4\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  4\n",
      "5 true:  5\n",
      "3 true:  4\n",
      "5 true:  3\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "3 true:  6\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "3 true:  1\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "0 true:  5\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  2\n",
      "5 true:  1\n",
      "5 true:  4\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "0 true:  0\n",
      "3 true:  1\n",
      "5 true:  2\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  2\n",
      "5 true:  5\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  1\n",
      "3 true:  6\n",
      "5 true:  2\n",
      "5 true:  3\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  0\n",
      "5 true:  6\n",
      "3 true:  1\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "0 true:  5\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "3 true:  6\n",
      "5 true:  2\n",
      "3 true:  6\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  5\n",
      "3 true:  5\n",
      "5 true:  6\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "5 true:  6\n",
      "5 true:  5\n",
      "5 true:  1\n",
      "5 true:  5\n",
      "5 true:  4\n",
      "3 true:  4\n",
      "5 true:  1\n",
      "5 true:  1\n",
      "5 true:  4\n",
      "5 true:  6\n",
      "5 true:  1\n",
      "3 true:  2\n",
      "6 true:  6\n",
      "0 true:  6\n",
      "5 true:  1\n",
      "5 true:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = []\n",
    "for v, y in zip(val_texts, val_labels):\n",
    "    print(predict_category(v), \"true: \", y)\n",
    "    y_pred.append(predict_category(v))\n",
    "\n",
    "\n",
    "confusion = confusion_matrix(val_labels, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True,\n",
    "xticklabels=[\"Other\", \"Clarity\", \"Comparison\", \"Motivatio \", \"Orginality\", \"replicable\", \"substance\"], yticklabels=[\"pred_Other\", \"Clarity\", \"Comparison\", \"Motivatio \", \"Orginality\", \"replicable\", \"substance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "save_directory = \"Multitext_Classification_colab\" \n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "\n",
    "save_directory = \"Multitext_Classification_2\"\n",
    "loaded_tokenizer = DistilBertTokenizer.from_pretrained(save_directory)\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(save_directory)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
