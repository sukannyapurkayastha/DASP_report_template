{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from dataloading.loaders.openreview_loader import OpenReviewLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-01 23:22:40.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mOpenReview client initialized.\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:49.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36m_get_reviews_from_multiple_papers\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mFetching reviews from multiple papers\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:49.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mget_paper\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mFetching paper with id: zzv4Bf50RW\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mget_paper\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mFetched paper: Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36m_get_reviews\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mGetting reviews for paper: Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: aU4SaZOeh4\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: wKVoAVtxek\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: NLfuL11uwO\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: PUauntqQsB\u001b[0m\n",
      "\u001b[32m2024-12-01 23:22:50.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: Upm4GL7iRr\u001b[0m\n",
      "Segmenting content: 100%|██████████| 5/5 [00:00<00:00, 16.07it/s]\n"
     ]
    }
   ],
   "source": [
    "password = 'U^fz&*rXwXr8pyx'\n",
    "username = 'zhijingshui.yang@stud.tu-darmstadt.de'\n",
    "try:\n",
    "    client = OpenReviewLoader(username=username, password=password)\n",
    "except Exception as e:\n",
    "    print(f\"{e.args[0]['status']}: {str(e.args[0]['message'])}\")\n",
    "    print(e)\n",
    "\n",
    "test_set = client.create_testset(ids=[\"zzv4Bf50RW\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-01 23:27:05.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mget_paper\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mFetching paper with id: zzv4Bf50RW\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mget_paper\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mFetched paper: Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36m_get_reviews\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mGetting reviews for paper: Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: aU4SaZOeh4\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: wKVoAVtxek\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: NLfuL11uwO\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: PUauntqQsB\u001b[0m\n",
      "\u001b[32m2024-12-01 23:27:05.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloading.loaders.openreview_loader\u001b[0m:\u001b[36mprepare_review\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mPreparing review for note: Upm4GL7iRr\u001b[0m\n",
      "Segmenting content: 100%|██████████| 5/5 [00:00<00:00, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           author                                           sentence\n",
      "0   Reviewer eS3u  This work proposes LSTNet, a self-supervised m...\n",
      "1   Reviewer eS3u  Specifically, LSTNet learns to formulate SO(3)...\n",
      "2   Reviewer eS3u  The proposed self-supervised training pipeline...\n",
      "3   Reviewer eS3u  The self- and cross-reconstruction training st...\n",
      "4   Reviewer eS3u  LSTNet demonstrates state-of-the-art performan...\n",
      "5   Reviewer eS3u  The performance of aligned shape pairs under t...\n",
      "6   Reviewer eS3u  The reason why other methods are much better t...\n",
      "7   Reviewer eS3u                               Lack of limitations.\n",
      "8   Reviewer jP4i  1) This paper proposes a self-supervised metho...\n",
      "9   Reviewer jP4i  2）The main idea is to decouple a point cloud f...\n",
      "10  Reviewer jP4i  3) Experiments on the KeypointNet dataset show...\n",
      "11  Reviewer jP4i           1) This paper is generally well-written.\n",
      "12  Reviewer jP4i  2) The idea of factorizing point cloud descrip...\n",
      "13  Reviewer jP4i                  3) Experimental results are good.\n",
      "14  Reviewer jP4i  1) The main weakness of this paper could be al...\n",
      "15  Reviewer jP4i  2) Since the proposed method can estimate dens...\n",
      "16  Reviewer jP4i  3) The running time and GPU memory cost is blu...\n",
      "17  Reviewer jP4i  4) Please compare the proposed method with mor...\n",
      "18  Reviewer jP4i                    Please refer to the weaknesses.\n",
      "19  Reviewer wiS9  This paper introduces LSTNet, which leverages ...\n",
      "20  Reviewer wiS9  1. The idea of cross-reconstruction for genera...\n",
      "21  Reviewer wiS9  2. The overall writing is good and the methodo...\n",
      "22  Reviewer wiS9  1. The novelty of this work seems insufficient...\n",
      "23  Reviewer wiS9  2. Regarding the local shape transform: 2.1. F...\n",
      "24  Reviewer wiS9  2.2 The authors claimed that the local shape t...\n",
      "25  Reviewer wiS9  2.2.1 First, why are the features obtained by ...\n",
      "26  Reviewer wiS9  2.2.2 Second, the so-called local shape transf...\n",
      "27  Reviewer wiS9  3.2 As this paper also targets on corresponden...\n",
      "28  Reviewer wiS9  3.3 In Tab.1, only CPAE proposed in 2021 is us...\n",
      "29  Reviewer wiS9  3.4 The method is claimed to generate SO(3)-in...\n",
      "30  Reviewer wiS9  4. For the SO(3)-equivariant and -invariant me...\n",
      "31  Reviewer wiS9  [1]. Zohaib et al. SC3K: Self-supervised and C...\n",
      "32  Reviewer wiS9  [2]. Dent et al. PPF-FoldNet: Unsupervised Lea...\n",
      "33  Reviewer wiS9                                    See weaknesses.\n",
      "34  Reviewer a6Ps  This paper attempts to register point cloud pr...\n",
      "35  Reviewer a6Ps  Valid motivation. Unlike the abused topic, van...\n",
      "36  Reviewer a6Ps  The SO(3)-invariant network design intrinsical...\n",
      "37  Reviewer a6Ps  The joint usage of a global descriptor and a l...\n",
      "38  Reviewer a6Ps  The self-supervision scheme looks plausible by...\n",
      "39  Reviewer a6Ps  My major concern is with the experimental setu...\n",
      "40  Reviewer a6Ps  In motivation, the authors talk about usage in...\n",
      "41  Reviewer a6Ps  The authors also take groundtruth keypoints an...\n",
      "42  Reviewer a6Ps  Following my points in the \"weaknesses\" sectio...\n",
      "43  Reviewer a6Ps  1. Would SO(3) invariance be sufficient? Do we...\n",
      "44  Reviewer a6Ps  2. Will the network still be functional if the...\n",
      "45  Reviewer a6Ps  3. Will it work out of the 16-category domain?...\n",
      "46  Reviewer a6Ps  4. Would non-gt and/or biased key points and s...\n",
      "47  Reviewer a6Ps  It would be nice if the authors could conduct ...\n",
      "48  Reviewer Frem  This paper presents a method of learning dense...\n",
      "49  Reviewer Frem  1. The paper is in general well organized and ...\n",
      "50  Reviewer Frem  2. The proposed method is straightforward and ...\n",
      "51  Reviewer Frem  1. The main issue of the proposed method lies ...\n",
      "52  Reviewer Frem  2. From Fig. 6 in the supplementary, we can se...\n",
      "53  Reviewer Frem  3. How about the performance of other methods ...\n",
      "54  Reviewer Frem  4. The whole method is mainly built upon the e...\n",
      "55  Reviewer Frem                 Please refer to the Weaknees part.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p = client.get_paper_reviews(\"zzv4Bf50RW\")\n",
    "p.reviews\n",
    "print(p.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 21:02:50.715957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733086970.730716   15876 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733086970.736163   15876 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 21:02:50.753642: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/nana/anaconda3/envs/jitsupeer_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "W0000 00:00:1733086974.279077   15876 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Some layers from the model checkpoint at models/attitude_root/ were not used when initializing TFBertForSequenceClassification: ['dropout_19', 'pre_classifier', 'distilbert']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at models/attitude_root/ and are newly initialized: ['bert']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('models/attitude_root/')\n",
    "\n",
    "# Load the model\n",
    "model = TFBertForSequenceClassification.from_pretrained('models/attitude_root/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    predict_input = tokenizer.encode(text,\n",
    "                                    truncation=True,\n",
    "                                    padding=True,\n",
    "                                    return_tensors=\"tf\")\n",
    "    output = model(predict_input)[0]\n",
    "    prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    "    return prediction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           author                                           sentence  \\\n",
      "0   Reviewer eS3u  This work proposes LSTNet, a self-supervised m...   \n",
      "1   Reviewer eS3u  Specifically, LSTNet learns to formulate SO(3)...   \n",
      "2   Reviewer eS3u  The proposed self-supervised training pipeline...   \n",
      "3   Reviewer eS3u  The self- and cross-reconstruction training st...   \n",
      "4   Reviewer eS3u  LSTNet demonstrates state-of-the-art performan...   \n",
      "5   Reviewer eS3u  The performance of aligned shape pairs under t...   \n",
      "6   Reviewer eS3u  The reason why other methods are much better t...   \n",
      "7   Reviewer eS3u                               Lack of limitations.   \n",
      "8   Reviewer jP4i  1) This paper proposes a self-supervised metho...   \n",
      "9   Reviewer jP4i  2）The main idea is to decouple a point cloud f...   \n",
      "10  Reviewer jP4i  3) Experiments on the KeypointNet dataset show...   \n",
      "11  Reviewer jP4i           1) This paper is generally well-written.   \n",
      "12  Reviewer jP4i  2) The idea of factorizing point cloud descrip...   \n",
      "13  Reviewer jP4i                  3) Experimental results are good.   \n",
      "14  Reviewer jP4i  1) The main weakness of this paper could be al...   \n",
      "15  Reviewer jP4i  2) Since the proposed method can estimate dens...   \n",
      "16  Reviewer jP4i  3) The running time and GPU memory cost is blu...   \n",
      "17  Reviewer jP4i  4) Please compare the proposed method with mor...   \n",
      "18  Reviewer jP4i                    Please refer to the weaknesses.   \n",
      "19  Reviewer wiS9  This paper introduces LSTNet, which leverages ...   \n",
      "20  Reviewer wiS9  1. The idea of cross-reconstruction for genera...   \n",
      "21  Reviewer wiS9  2. The overall writing is good and the methodo...   \n",
      "22  Reviewer wiS9  1. The novelty of this work seems insufficient...   \n",
      "23  Reviewer wiS9  2. Regarding the local shape transform: 2.1. F...   \n",
      "24  Reviewer wiS9  2.2 The authors claimed that the local shape t...   \n",
      "25  Reviewer wiS9  2.2.1 First, why are the features obtained by ...   \n",
      "26  Reviewer wiS9  2.2.2 Second, the so-called local shape transf...   \n",
      "27  Reviewer wiS9  3.2 As this paper also targets on corresponden...   \n",
      "28  Reviewer wiS9  3.3 In Tab.1, only CPAE proposed in 2021 is us...   \n",
      "29  Reviewer wiS9  3.4 The method is claimed to generate SO(3)-in...   \n",
      "30  Reviewer wiS9  4. For the SO(3)-equivariant and -invariant me...   \n",
      "31  Reviewer wiS9  [1]. Zohaib et al. SC3K: Self-supervised and C...   \n",
      "32  Reviewer wiS9  [2]. Dent et al. PPF-FoldNet: Unsupervised Lea...   \n",
      "33  Reviewer wiS9                                    See weaknesses.   \n",
      "34  Reviewer a6Ps  This paper attempts to register point cloud pr...   \n",
      "35  Reviewer a6Ps  Valid motivation. Unlike the abused topic, van...   \n",
      "36  Reviewer a6Ps  The SO(3)-invariant network design intrinsical...   \n",
      "37  Reviewer a6Ps  The joint usage of a global descriptor and a l...   \n",
      "38  Reviewer a6Ps  The self-supervision scheme looks plausible by...   \n",
      "39  Reviewer a6Ps  My major concern is with the experimental setu...   \n",
      "40  Reviewer a6Ps  In motivation, the authors talk about usage in...   \n",
      "41  Reviewer a6Ps  The authors also take groundtruth keypoints an...   \n",
      "42  Reviewer a6Ps  Following my points in the \"weaknesses\" sectio...   \n",
      "43  Reviewer a6Ps  1. Would SO(3) invariance be sufficient? Do we...   \n",
      "44  Reviewer a6Ps  2. Will the network still be functional if the...   \n",
      "45  Reviewer a6Ps  3. Will it work out of the 16-category domain?...   \n",
      "46  Reviewer a6Ps  4. Would non-gt and/or biased key points and s...   \n",
      "47  Reviewer a6Ps  It would be nice if the authors could conduct ...   \n",
      "48  Reviewer Frem  This paper presents a method of learning dense...   \n",
      "49  Reviewer Frem  1. The paper is in general well organized and ...   \n",
      "50  Reviewer Frem  2. The proposed method is straightforward and ...   \n",
      "51  Reviewer Frem  1. The main issue of the proposed method lies ...   \n",
      "52  Reviewer Frem  2. From Fig. 6 in the supplementary, we can se...   \n",
      "53  Reviewer Frem  3. How about the performance of other methods ...   \n",
      "54  Reviewer Frem  4. The whole method is mainly built upon the e...   \n",
      "55  Reviewer Frem                 Please refer to the Weaknees part.   \n",
      "\n",
      "    attitude_root  attitude_root_number  \n",
      "0               6                     6  \n",
      "1               0                     0  \n",
      "2               6                     6  \n",
      "3               6                     6  \n",
      "4               6                     6  \n",
      "5               6                     6  \n",
      "6               6                     6  \n",
      "7               0                     0  \n",
      "8               6                     6  \n",
      "9               6                     6  \n",
      "10              6                     6  \n",
      "11              0                     0  \n",
      "12              0                     0  \n",
      "13              6                     6  \n",
      "14              6                     6  \n",
      "15              6                     6  \n",
      "16              6                     6  \n",
      "17              0                     0  \n",
      "18              6                     6  \n",
      "19              6                     6  \n",
      "20              6                     6  \n",
      "21              0                     0  \n",
      "22              6                     6  \n",
      "23              0                     0  \n",
      "24              0                     0  \n",
      "25              6                     6  \n",
      "26              6                     6  \n",
      "27              6                     6  \n",
      "28              0                     0  \n",
      "29              0                     0  \n",
      "30              0                     0  \n",
      "31              0                     0  \n",
      "32              6                     6  \n",
      "33              0                     0  \n",
      "34              6                     6  \n",
      "35              0                     0  \n",
      "36              0                     0  \n",
      "37              6                     6  \n",
      "38              6                     6  \n",
      "39              6                     6  \n",
      "40              0                     0  \n",
      "41              6                     6  \n",
      "42              6                     6  \n",
      "43              0                     0  \n",
      "44              0                     0  \n",
      "45              6                     6  \n",
      "46              0                     0  \n",
      "47              6                     6  \n",
      "48              6                     6  \n",
      "49              0                     0  \n",
      "50              0                     0  \n",
      "51              6                     6  \n",
      "52              6                     6  \n",
      "53              6                     6  \n",
      "54              0                     0  \n",
      "55              6                     6  \n"
     ]
    }
   ],
   "source": [
    "test_set['attitude_root_number'] = test_set['sentence'].apply(predict_category)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'Other',\n",
    "    1: 'Clarity',\n",
    "    2: 'Meaningful-comparison',\n",
    "    3: 'Motivation-impact',\n",
    "    4: 'Originality',\n",
    "    5: 'Replicability',\n",
    "    6: 'Soundness-correctness',\n",
    "    7: 'Substance',\n",
    "    8: 'None'\n",
    "}\n",
    "\n",
    "test_set['attitude_root'] = test_set['attitude_root_number'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude_root_number</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>[1. The paper is in general well organized and...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>[Valid motivation. Unlike the abused topic, va...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>[Specifically, LSTNet learns to formulate SO(3...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>[1) This paper is generally well-written., 2) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>[2. The overall writing is good and the method...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Reviewer Frem</td>\n",
       "      <td>[This paper presents a method of learning dens...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Reviewer a6Ps</td>\n",
       "      <td>[This paper attempts to register point cloud p...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Reviewer eS3u</td>\n",
       "      <td>[This work proposes LSTNet, a self-supervised ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>Reviewer jP4i</td>\n",
       "      <td>[1) This paper proposes a self-supervised meth...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>Reviewer wiS9</td>\n",
       "      <td>[This paper introduces LSTNet, which leverages...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude_root_number         author  \\\n",
       "0                     0  Reviewer Frem   \n",
       "1                     0  Reviewer a6Ps   \n",
       "2                     0  Reviewer eS3u   \n",
       "3                     0  Reviewer jP4i   \n",
       "4                     0  Reviewer wiS9   \n",
       "5                     6  Reviewer Frem   \n",
       "6                     6  Reviewer a6Ps   \n",
       "7                     6  Reviewer eS3u   \n",
       "8                     6  Reviewer jP4i   \n",
       "9                     6  Reviewer wiS9   \n",
       "\n",
       "                                            comments  count  \n",
       "0  [1. The paper is in general well organized and...      3  \n",
       "1  [Valid motivation. Unlike the abused topic, va...      6  \n",
       "2  [Specifically, LSTNet learns to formulate SO(3...      2  \n",
       "3  [1) This paper is generally well-written., 2) ...      3  \n",
       "4  [2. The overall writing is good and the method...      8  \n",
       "5  [This paper presents a method of learning dens...      5  \n",
       "6  [This paper attempts to register point cloud p...      8  \n",
       "7  [This work proposes LSTNet, a self-supervised ...      6  \n",
       "8  [1) This paper proposes a self-supervised meth...      8  \n",
       "9  [This paper introduces LSTNet, which leverages...      7  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = test_set\n",
    "total_rows = len(df)\n",
    "# Step 1: Group by 'attitude_root_number' and 'author', then aggregate the sentences\n",
    "agg_df = df.groupby(['attitude_root_number', 'author']).agg(\n",
    "    comments=('sentence', list), count=('sentence', 'size')\n",
    ").reset_index()\n",
    "\n",
    "agg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude_root_number</th>\n",
       "      <th>comments</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[Reviewer Frem, [1. The paper is in general w...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[[Reviewer Frem, [This paper presents a method...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude_root_number                                           comments  \\\n",
       "0                     0  [[Reviewer Frem, [1. The paper is in general w...   \n",
       "1                     6  [[Reviewer Frem, [This paper presents a method...   \n",
       "\n",
       "   count  \n",
       "0     22  \n",
       "1     34  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = agg_df.groupby('attitude_root_number').agg(\n",
    "    comments=('comments', lambda x: [[author, comments] for author, comments in zip(agg_df['author'], x)]),\n",
    "    count=('count', 'sum')\n",
    ").reset_index()\n",
    "final_df.iloc[0]['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Reviewer Frem',\n",
       "  ['1. The paper is in general well organized and easy to follow.',\n",
       "   '2. The proposed method is straightforward and shown to be effective on the test data.',\n",
       "   \"4. The whole method is mainly built upon the existing SO(3)-equivariant representation. The main contribution lies in introducing this representation to the specific task. I didn't get too much novel insight in terms of network design.\"]],\n",
       " ['Reviewer a6Ps',\n",
       "  ['Valid motivation. Unlike the abused topic, vanilla point cloud registration, the motivation stands and could potentially benefit practical usages.',\n",
       "   'The SO(3)-invariant network design intrinsically ensures robustness against rotations.',\n",
       "   'In motivation, the authors talk about usage in vision, graphics, and robotics. In vision and robotics, we are interested in fitting real-world scans to templates (e.g. [Scan2CAD, CVPR 2019]), where in most cases, only noisy, partial, and sparse point clouds are provided. The authors do not have experiments or discussions in such cases.',\n",
       "   '1. Would SO(3) invariance be sufficient? Do we need SE(3) or even Sim(3) invariance, if we cannot easily normalize the input due to the noise and sparsity?',\n",
       "   '2. Will the network still be functional if the density distributions are different across input and output?',\n",
       "   '4. Would non-gt and/or biased key points and semantic parts be transferred properly?']],\n",
       " ['Reviewer eS3u',\n",
       "  ['Specifically, LSTNet learns to formulate SO(3)-invariant local shape transform for each point in a dynamic, input-dependent manner. Each point-wise local shape transform can map the SO(3)-equivariant global shape descriptor of the input shape to a local shape descriptor, which is passed to the decoder to reconstruct the shape and pose of the input point cloud.',\n",
       "   'Lack of limitations.']],\n",
       " ['Reviewer jP4i',\n",
       "  ['1) This paper is generally well-written.',\n",
       "   '2) The idea of factorizing point cloud descriptors into SO(3)-equivariant global shape descriptor and dynamic SO(3)-invariant point-wise local shape transforms seems to be novel.',\n",
       "   '4) Please compare the proposed method with more recent papers, e.g., [SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data].']],\n",
       " ['Reviewer wiS9',\n",
       "  ['2. The overall writing is good and the methodology part is well-organized and easy to follow.',\n",
       "   '2. Regarding the local shape transform: 2.1. From 3.1.1, the SO(3)-invariant output is $\\\\mathbf{V}\\\\mathbf{U}^T \\\\in \\\\mathbb{R}^{C \\\\times C}$, while in 3.1.2, the obtained SO(3)-invariant features $\\\\mathbf{V} \\\\in \\\\mathbb{R}^{C^\\\\prime \\\\times 3 \\\\times N}$ have a different shape.',\n",
       "   '2.2 The authors claimed that the local shape transform transforms the global features to local ones. Regarding this, I have two questions.',\n",
       "   '3.3 In Tab.1, only CPAE proposed in 2021 is used as the baseline. Some recent methods, e.g., [1], should also be included. Otherwise the results are not convincing at all (only compared to a single baseline which was proposed years ago). And it seems CPAE is the only baseline method for all the experiments. More baselines are required on both tasks.',\n",
       "   '3.4 The method is claimed to generate SO(3)-invariant correspondences. However, in Tab. 1, even on the synthetic data, the I/SO(3) and SO(3)/SO(3) experiments perform unsimilarly (I would expect to have similar results per category, as it is on synthetic and clean data). Could this be explained?',\n",
       "   '4. For the SO(3)-equivariant and -invariant methods, some works for point cloud registration [2, 3, 4, 5] should also be discussed.',\n",
       "   '[1]. Zohaib et al. SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data, ICCV 2023.',\n",
       "   'See weaknesses.']]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[0]['comments']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jitsupeer_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
